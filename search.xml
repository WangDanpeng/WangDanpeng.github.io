<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>操作系统系列笔记(二) - 存储管理</title>
    <url>/2021/10/25/20211025192219/</url>
    <content><![CDATA[<h2 id="存储管理"><a href="#存储管理" class="headerlink" title="存储管理"></a>存储管理</h2><h3 id="计算机体系结构和内存层次"><a href="#计算机体系结构和内存层次" class="headerlink" title="计算机体系结构和内存层次"></a>计算机体系结构和内存层次</h3><p>内存层次: CPU有高速缓存, 未命中查内存, 内存没有查外存, 访问速度差别很大<br>内存管理目标: 抽象(逻辑地址空间), 保护(独立地址空间), 共享(访问相同内存), 虚拟化(更大的地址空间)<br>操作系统中采用的内存管理方式, 重定位(Relocation), 分段(Segmentation), 分页(Paging), 虚拟存储(Virtual Memory)<br>以上实现高度依赖硬件, 与计算机存储架构紧耦合, MMU(内存管理单元)是处理CPU存储访问请求的硬件, 多数系统采用按需页式虚拟存储</p>
<h3 id="地址空间和地址生成"><a href="#地址空间和地址生成" class="headerlink" title="地址空间和地址生成"></a>地址空间和地址生成</h3><p>物理地址空间定义: 硬件支持的地址空间, 起始地址0, 直到MAXsys, 32位就是0到2的32次幂-1<br>多少位地址总线, 就是物理地址总线的条数<br>逻辑地址空间, 在CPU运行的进程看到的地址, 起始地址0,到MAXprog<br>地址生成时机: 编译时, 加载时, 执行时, 前两种简单但是不灵活, 第三种最灵活</p>
<h3 id="连续内存分配"><a href="#连续内存分配" class="headerlink" title="连续内存分配"></a>连续内存分配</h3><p>目标: 给进程分配一块不小于指定大小的连续物理内存区域<br>内存碎片: 空闲内存不能被利用, 外碎片(较小的剩余不连续内存区域), 内碎片(分配的内存区域未使用完的剩余部分)<br>动态分区分配: 当程序被加载执行时, 分配一个进程, 指定大小可变的分区, 分区的地址是连续的, 操作系统需要维护两个数据结构, 已分配分区和空闲分区<br>动态分区分配有三种策略:</p>
<ol>
<li>最先匹配: 找第一个比申请大的区域, 分配给进程. 优点是简单, 在高地址有大块分区, 但有外部碎片, 分配大块时较慢</li>
<li>最佳分配: 找比申请大小大的最小的一个(即大小最接近的), 空闲分区按大小排序, 合并时复杂一些, 优点可避免大块分区被拆分, 减小外碎片大小, 但有外碎片, 释放分区较慢, 产生无法利用的小碎片 </li>
<li>最差匹配: 找最大区域, 空闲按从大到小排, 合并复杂, 优点避免太多小碎片, 但释放慢, 有外碎片, 破坏了大分区<h4 id="碎片整理"><a href="#碎片整理" class="headerlink" title="碎片整理"></a>碎片整理</h4>紧凑(Compaction): 通过调整进程占用的分区位置, 来减少分区碎片, 移动分配给进程的内存分区, 以合并外部碎片, 条件要求所有应用程序可动态重定位分区, 通常等待状态搬动, 还要考虑搬动开销<br>分区兑换(Swapping In/Out): 通过抢占并回收处于等待状态进程的分区, 以增大可用内存空间, 把等待进程放到对换区</li>
</ol>
<h3 id="非连续内存分配"><a href="#非连续内存分配" class="headerlink" title="非连续内存分配"></a>非连续内存分配</h3><p>有三种, 段式, 页式, 段页式<br>连续分配缺点: 分给程序内存必须连续, 存在内外碎片, 内存分配的动态修改困难, 内存利用率较低<br>非连续内存分配目标: 提高内存利用率和管理灵活性<br>允许一个程序使用非连续物理地址空间, 允许共享代码和数据, 支持动态加载和动态链接</p>
<h3 id="段式存储管理"><a href="#段式存储管理" class="headerlink" title="段式存储管理"></a>段式存储管理</h3><p>段地址空间: 进程的段地址空间由多个段组成, 主代码段, 子模块代码段, 公用库代码段, 堆栈段, 堆数据, 初始化数据段, 符号表等<br>段表示<strong>访问方式</strong>和**存储数据等属性相同的一段地址空间, 对应一个连续的内存块, 若干个段组成进程的逻辑地址空间<br>段访问机制: 逻辑地址由二元组(s, addr)表示, s是段号, addr是段内偏移, 去查进程的段表, 找到段的起始地址和长度, 然后根据偏移, 找到数据</p>
<h3 id="页式存储管理"><a href="#页式存储管理" class="headerlink" title="页式存储管理"></a>页式存储管理</h3><p>把物理地址空间划分为大小相同的基本分配单位, 叫做页帧/帧(Frame), 大小2的n次幂, 常见大小4K<br>把逻辑地址空间也划分为相同大小的基本分配单位, 叫做页面/页(Page), 页和帧的大小必须是相同的<br>页到帧的转换通过页表完成<br>内存物理地址表示, 二元组(f,o), 帧号和偏移<br>不是所有的页都有对应的帧</p>
<h4 id="页表概述"><a href="#页表概述" class="headerlink" title="页表概述"></a>页表概述</h4><p>每个进程都有一个页表, 每个页面对应一个页表项, 随进程运行状态动态变化, 首地址放在页表基址寄存器(Page Table Base Register, PTBR)<br>页表项组成: 帧号, 标志位(存在位, 修改位, 引用位)<br>页式存储性能问题, 访问一个内存单元需要两次内存访问, 先查页表项再访问数据<br>当页表项过多, 页表可能非常大, 解决办法就是缓存(快表)和间接访问(多级页表)<br>快表: 缓存近期访问的页表项, 使用关联存储器实现<br>多级页表: 通过间接引用将页号分成k级, 建立页表树<br>反置页表: 为了减少页表所占用存储空间的一种做法, 让页表项和物理地址空间对应起来, 不和逻辑地址空间对应, 进程数量增加和虚拟地址空间增大都对页表占用没有影响<br>以上三种做法可缓解页表带来的麻烦</p>
<h3 id="段页式存储管理"><a href="#段页式存储管理" class="headerlink" title="段页式存储管理"></a>段页式存储管理</h3><p>段式和页式的结合<br>段式存储分的块比较大, 每块内容是同一个段, 做存储的保护是比较方便的<br>页式存储分了很小的标准大小的块, 在内存利用效率比较有优势<br>实现: 在段式存储管理基础上, 给每个段加一个页表(段号, 页号, 页内偏移)</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(一) - 启动,中断,异常,系统调用</title>
    <url>/2021/10/25/20211025172037/</url>
    <content><![CDATA[<h2 id="操作系统概述"><a href="#操作系统概述" class="headerlink" title="操作系统概述"></a>操作系统概述</h2><h3 id="什么是操作系统"><a href="#什么是操作系统" class="headerlink" title="什么是操作系统"></a>什么是操作系统</h3><p>操作系统是一个控制程序, 一个系统软件, 控制程序执行过程, 给用户提供各种服务, 方便用户使用计算机系统<br>操作系统是一个资源管理器, 应用程序与硬件之间的中间层, 管理软硬件资源, 提供访问软硬件手段, 解决资源访问冲突<br>操作系统软件的组成, Shell, GUI, Kernel</p>
<h3 id="操作系统内核的特征"><a href="#操作系统内核的特征" class="headerlink" title="操作系统内核的特征"></a>操作系统内核的特征</h3><p>并发: 系统中同时存在多个运行的程序, 需要管理和调度<br>共享: 宏观上”同时”访问, 微观上互斥共享<br>虚拟: 利用多道程序设计技术, 让用户感觉不到其他用户<br>异步: 程序是走走停停的; 只要运行环境相同, 运行结果也要相同</p>
<h2 id="启动-中断-异常和系统调用"><a href="#启动-中断-异常和系统调用" class="headerlink" title="启动, 中断, 异常和系统调用"></a>启动, 中断, 异常和系统调用</h2><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>CPU通过总线连接I/O设备和内存<br>内存分为RAM(随机访问存储)和ROM(只读存储), 系统加电后会从ROM读取系统初始化代码<br>CPU完成初始化后处于实模式下, 地址总线只有20位可用, 所以内存地址640KB到1M之间为BIOS启动固件<br>BIOS具备的功能有: 基本输入输出, 系统设置信息, 开机自检, 系统自启动程序<br>BIOS初始化完成以后, 从磁盘读引导扇区, 长度只有512字节, 放到指定地址, 并跳转过去<br>然后开始执行加载程序, 将操作系统代码和数据从硬盘加载到内存, 并跳转到操作系统的起始地址, 交出控制权给内核程序</p>
<h3 id="系统启动流程"><a href="#系统启动流程" class="headerlink" title="系统启动流程"></a>系统启动流程</h3><p>加电后读BIOS, BIOS读主引导记录, 主引导记录读取活动分区, 活动分区读加载程序, 加载程序读内核映像<br><strong>BIOS初始化过程</strong><br>硬件自检(Power On Self Test, POST), 执行系统BIOS进行系统检测, 更新CMOS芯片中的扩展系统配置数据ESCD(Extended System Configuration Data), 按指定启动顺序从软/硬盘或光驱启动, 读进第一个扇区<br>主引导记录MBR(Master Boot Record)格式, 包括: 启动代码(检查分区表正确性, 加载并跳转到磁盘上的引导程序), 硬盘分区表, 结束标志字, 然后跳到活动分区的引导扇区上<br>分区引导扇区格式包括, 跳转指令, 文件卷头, 启动代码, 结束标志<br>加载程序(bootloader), 从文件系统读一个启动配置文件, 依据配置去加载内核</p>
<h3 id="中断-异常和系统调用"><a href="#中断-异常和系统调用" class="headerlink" title="中断, 异常和系统调用"></a>中断, 异常和系统调用</h3><p>计算机运行中, 内核是被信任的, 只有内核可以执行特权指令, 为了方便应用程序<br>中断(Hardware Interrupt), 来自硬件设备的处理请求, 异步<br>异常(Exception), 非法指令或者其他原因导致当前指令执行失败后的处理请求, 同步<br>系统调用(System Call), 应用程序主动向操作系统发出的服务请求, 异步或同步<br>当连接外设时, 需要<strong>中断</strong>做响应, 当应用程序遇到意外时, 交给<strong>异常</strong>做处理, <strong>系统调用</strong>为了应用程序方便的使用内核提供的服务, 又不会对内核安全产生影响</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-常见算法思想 </title>
    <url>/2021/07/30/20210730193440/</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>几种常见的算法思想, 用来指导我们设计具体的算法和编码, 有<br>贪心算法, 分治算法, 回溯算法, 动态规划</p>
<h3 id="贪心算法-greedy-algorithm"><a href="#贪心算法-greedy-algorithm" class="headerlink" title="贪心算法(greedy algorithm)"></a>贪心算法(greedy algorithm)</h3><p>经典应用, 霍夫曼编码, Prim和Kruskal最小生成树算法, Dijkstra单源最短路径算法<br>经典问题, 背包问题, 固定容量下, 让背包里装的物品总价值最大, 贪心算法用法则是计算物品单价, 单价从高到低依次放入包中<br>使用贪心算法解决问题的步骤</p>
<ul>
<li>第一步, 看到这类问题, 首先联想到贪心算法</li>
<li>尝试看下这个问题是否能用贪心算法解决</li>
<li>举例看下贪心算法产生的结果是否是最优解<br>大部分能用贪心算法的问题, 结果都是正确的, 但也有解决不掉的问题, 比如前面的选择会影响后面的选择, 局部最优未必全局最优<br>类似能用贪心算法解决的问题, 分糖果, 钱币找零, 区间覆盖等<br>贪心算法最难的是如何将要解决的问题抽象成贪心算法模型, 后续的编码一般都很简单<br>贪心算法解决问题的正确性虽然很多时候都很高, 但要严谨的证明算法能得到最优解, 并不容易</li>
</ul>
<h3 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a>分治算法</h3><p>分治算法核心思想就是四个字, 分而治之, 将原问题划分为n个规模较小, 并且结构与原问题相似的子问题, 递归的解决这些子问题, 然后再合并其结果, 就得到原问题的解<br>有点类似递归, 分治算法是一种处理问题的思想, 递归是一种编程技巧, 分治算法一般都比较适合用递归来实现<br>分治算法能解决的问题, 一般需要满足下面几个条件</p>
<ul>
<li>原问题与分解成的小问题具有相同的模式</li>
<li>原问题分解成的子问题可以独立求解, 子问题之前没有相关性(和动态规划的明显区别)</li>
<li>具有分解终止条件, 当问题足够小时, 可以直接求解</li>
<li>可以将子问题合并成原问题, 且合并操作复杂度不太高, 否则起不到减小算法总体复杂度的效果<br>分治算法两种典型的应用场景</li>
<li>用来指导编码, 降低问题求解的时间复杂度</li>
<li>解决海量数据处理问题, 比如MapReduce</li>
</ul>
<h3 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h3><p>之前的深度优先搜索算法利用的就是回溯思想, 这个算法思想简单却应用广泛<br>比如正则表达式, 编译原理中的语法分析, 很多经典数学问题比如数独, 八皇后, 0-1背包, 图的着色, 旅行商问题, 全排列等等<br>回溯的处理思想有点类似枚举搜索, 枚举出所有的解, 然后找到满足期望的解, 为了枚举所有可能的解, 避免遗漏和重复, 我们把问题求解的过程分为多个阶段<br>每个阶段面对一个岔路口, 先随意选一条路走, 当发现这条路走不通, 就退回上一个岔路口, 选另一种走法继续走<br>示例: 八皇后问题(todo), 0-1背包(todo)<br>大部分情况下, 回溯算法都可以用来解决广义的搜索问题, 即从一组可能的解中, 选择一个满足要求的解<br>回溯算法非常适合用递归来实现, 在实现的过程中, 剪枝操作是提高回溯效率的一种技巧</p>
<h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p><a href="http://www.wangdanpeng.com/2021/07/30/20210730193020/">单开一篇文章</a></p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-动态规划</title>
    <url>/2021/07/30/20210730193020/</url>
    <content><![CDATA[<h2 id="动态规划-Dynamic-Programming"><a href="#动态规划-Dynamic-Programming" class="headerlink" title="动态规划(Dynamic Programming)"></a>动态规划(Dynamic Programming)</h2><p>动态规划比较适合求解最优问题, 比如最大值最小值, 可以非常显著的降低时间复杂度<br>有点难, 求解过程不符合常规思维方式, 先看两个例子</p>
<h3 id="0-1背包问题"><a href="#0-1背包问题" class="headerlink" title="0-1背包问题"></a>0-1背包问题</h3><p>一组不同重量, 不可分割的物品, 选择一些装入背包, 在背包限重前提下, 背包里能装下的<strong>物品重量最大值</strong><br>回溯算法时间复杂度高, 指数级别, 回溯递归求解过程中, 有些子问题的求解是重复的, 此时可引入递归中的备忘录来解决, 避免冗余计算, 此时执行效率已经和动态规划差不多了<br>而动态规划是这么做, 求解过程分为n个阶段, 每个阶段决策一个物品是否放到背包里<br>每次决策后, 背包的重量会有多种情况, 会达到多种不同的状态, 我们把每一层重复的状态合并, 记录不同的状态, 就可以基于上一层状态集合, 推导下一层状态集合<br>用一个二维数组记录, 横向是物品个数, 纵向是背包重量, 数组值是boolean类型, 根据物品重量依次填进去<br>最后一层, 最接近末尾的数, 就是得到的解, 代码todo</p>
<p>动态规划解题思路, 把问题分解为多个阶段, 每个阶段对应一个决策, 记录每个阶段可达的状态集合, 通过当前阶段状态集合, 推导下一个阶段的状态集合, 动态地往前推进<br>这也是动态规划名字的由来, 但需要额外申请一个n<em> w+1的二维数组, 空间换时间, 可以优化到只用w+1的一位数组解决<br>回溯算法时间复杂度O(2^n), 动态规划时间复杂度O(n</em>w)物品个数乘可以承载总重量</p>
<h3 id="0-1背包问题升级版"><a href="#0-1背包问题升级版" class="headerlink" title="0-1背包问题升级版"></a>0-1背包问题升级版</h3><p>一组不同重量, 不同价值, 不可分割的物品, 在满足背包最大重量限制前提下, 可装入的<strong>总价值</strong>最大是多少<br>还是把求解过程分为n个阶段, 每个阶段决策一个物品是否放入背包, 每个阶段决策完后, 背包中的物品总重量及总价值会有多种情况<br>用二维数组来记录每层可到达的不同状态, 横向物品个数, 纵向背包重量, 数组里存储的当前状态对应的最大总价值, 每层中重复的状态合并, 只记录价值最大的状态, 并基于此推导下一层状态<br>时间复杂度和空间复杂度同上</p>
<h3 id="动态规划解决的问题"><a href="#动态规划解决的问题" class="headerlink" title="动态规划解决的问题"></a>动态规划解决的问题</h3><p>大部分动态规划能解决的问题, 都可以通过回溯算法来解决, 只不过回溯算法效率比较低<br>什么样的问题适合用动态规划来解决, 一个模型三个特征<br>动态规划适合解决的问题模型为 多阶段决策最优解模型<br>我们一般是用动态规划来解决最优解问题, 而解决过程需要经历多个决策阶段, 每个阶段都对应一组状态,<br>然后我们寻找一组决策序列, 经过这组决策序列, 能够产生最终期望求解的最优值<br>三个特征, 最优子结构, 无后效性, 重复子问题<br>最优子结构, 问题的最优解包含子问题的最优解, 可以通过子问题的最优解推导出问题的最优解, 即后面阶段的状态可以通过前面阶段的状态推导出来<br>无后效性, 一是推导状态时, 只关心前面阶段的状态值, 不关心这个值怎么来的, 二是某个阶段状态一旦确定就不受后续决策影响<br>重复子问题, 不同的决策序列, 到达某个相同的阶段时, 可能会产生重复的状态</p>
<h3 id="动态规划解题思路"><a href="#动态规划解题思路" class="headerlink" title="动态规划解题思路"></a>动态规划解题思路</h3><p>动态规划解题的一般思路有两种, 状态转移表法和状态转移方程法</p>
<ol>
<li>状态转移表法<br>回溯算法实现-定义状态-画递归树-找重复子问题-画状态转移表-根据递推关系填表-将填表过程翻译成代码<br>先画一个状态表, 一般是二维的, 用二维数组, 每个状态包含三个变量, 行列和数组值,  我们根据决策的先后过程, 从前往后填充状态表中的每个状态<br>并将递推填表的过程, 翻译成代码, 就是动态规划代码了<br>如果问题的状态比较复杂, 需要很多变量来表示, 那对应的状态表就需要是高维的, 就不适合用状态转移表法来解决了</li>
<li>状态转移方程法<br>找最优子结构-写状态转移方程-将状态转移方程翻译成代码<br>有点类似递归的解题思路, 需要分析某个问题如何通过子问题来递归求解, 也就是所谓的最优子结构, 根据最优子结构写出递归公式, 也就是所谓的状态转移方程<br>两种代码实现方法, 一种是递归加备忘录, 一种是迭代递推<br>状态转移方程是解决动态规划的关键<br>有的问题适合用第一种思路, 有的问题适合用第二种思路, 需要结合题目分析</li>
</ol>
<h3 id="四种算法思想比较分析"><a href="#四种算法思想比较分析" class="headerlink" title="四种算法思想比较分析"></a>四种算法思想比较分析</h3><p>贪心, 回溯, 动态规划可以归为一类, 解决问题的模型都可以抽象成多阶段决策最优解模型, 而分治算法不行<br>回溯算法是个万金油, 基本上能用动态规划和贪心解决的问题, 都可以用回溯算法, 不过时间复杂度非常高, 只能用来解决小规模数据问题<br>动态规划高效但不能解决所有问题, 需要满足三个特征<br>贪心算法实际上是动态规划的一种特殊情况, 解决问题更高效, 代码也更简洁, 能解决的问题也更有限, 需要满足三个条件, 最优子结构, 无后效性和贪心选择性<br>(通过局部最优的选择能产生全局最优选择)<br>拿到问题先不思考计算机如何实现, 单纯考虑人脑会如何去解决, 然后总结规律, 再套用学过的算法</p>
<h3 id="拓展-拼写纠错"><a href="#拓展-拼写纠错" class="headerlink" title="拓展-拼写纠错"></a>拓展-拼写纠错</h3><p>拼写纠错功能, 量化两个字符串的相似度,  需要用到非常著名的量化方法, 编辑距离<br>编辑距离指, 将一个字符串转化成另一个字符串, 需要的最少编辑操作次数, 比如增加/删除/替换一个字符, 编辑距离越大, 说明两个字符串相似度越小,<br>两个完全相同的字符串, 编辑距离是0<br>根据所包含的编辑操作种类不同, 编辑距离有多种不同的计算方式, 比较著名的有莱文斯坦距离(todo)和最长公共子串长度(todo)<br>莱文斯坦距离允许增加, 删除, 替换字符三个编辑操作, 最长公共子串长度只允许增加, 删除两个编辑操作<br>莱文斯坦距离表示两个字符串差异的大小, 最长公共子串的大小表示两个字符串相似程度的大小<br>具体细节略</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>Kylin-4.0beta版部署</title>
    <url>/2021/05/18/20210518173009/</url>
    <content><![CDATA[<h3 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h3><ul>
<li>Spark唯一构建引擎</li>
<li>引入parquet, 正在踢出HBase</li>
<li>可存储到HDFS</li>
</ul>
<h3 id="1-准备机器"><a href="#1-准备机器" class="headerlink" title="1. 准备机器"></a>1. 准备机器</h3><ul>
<li>准备三台机器, 系统CentOS7, 切记, 后续安装CDH版本为6.3.2, 高版本系统不支持</li>
<li>改hosts, ssh, 免密登录</li>
<li>改用户可打开文件数量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">* vi /etc/security/limits.conf</span><br><span class="line">*    soft    nofile   32728</span><br><span class="line">*    hard    nofile   1024999</span><br><span class="line">*    soft    nproc    65535</span><br><span class="line">*    hard    noroc    unlimited</span><br><span class="line">*    soft    memlock    unlimited</span><br><span class="line">*    hard    memlock    unlimited</span><br><span class="line">* sysctl -p</span><br></pre></td></tr></table></figure>
<ul>
<li>禁用透明大页面压缩</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>
<p>并将上面的两条命令写入开机自启动/etc/rc.local。</p>
<ul>
<li>设置swap空间(所有节点)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo "vm.swappiness = 0" &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure>
<h3 id="2-准备数据库"><a href="#2-准备数据库" class="headerlink" title="2. 准备数据库"></a>2. 准备数据库</h3><ul>
<li>主节点安装Mysql</li>
<li>创建用户,数据库, 后续使用, 安装什么服务就建对应的数据库, 或者到后续配置前创建</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- cloudera-manager</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> scm <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'scm'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> scm.* <span class="keyword">TO</span> <span class="string">'scm'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'scm'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- active_monitor</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> active_monitor <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'active_monitor'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> active_monitor.* <span class="keyword">TO</span> <span class="string">'active_monitor'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'active_monitor'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- amon</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> amon <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'amon'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> amon.* <span class="keyword">TO</span> <span class="string">'amon'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'amon'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- hive</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> hive <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'hive'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> hive.* <span class="keyword">TO</span> <span class="string">'hive'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'hive'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- hue</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> hue <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'hue'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> hue.* <span class="keyword">TO</span> <span class="string">'hue'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'hue'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- oozie</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> oozie <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'oozie'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> oozie.* <span class="keyword">TO</span> <span class="string">'oozie'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'oozie'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- 刷新mysql的权限列表 </span></span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>主节点放置Mysql驱动包</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz</span><br></pre></td></tr></table></figure>
<h3 id="3-安装依赖"><a href="#3-安装依赖" class="headerlink" title="3. 安装依赖"></a>3. 安装依赖</h3><ul>
<li>安装jdk, 配置Java home</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install java-1.8.0-openjdk-devel.x86_64</span><br><span class="line">ll /etc/alternatives/java</span><br></pre></td></tr></table></figure>
<ul>
<li>安装依赖</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y bind-utils psmisc libxslt cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs httpd mod_ssl openssl-devel /lib/lsb/init-functions libpq.so.5python27postgresql-devel*postgresql-odbc.x86_64python2-develchkconfig zlib sqlite  redhat-lsb postgresql*   openssl  telnet pcre-devel gcc gcc-c++ MySQL-python</span><br></pre></td></tr></table></figure>
<ul>
<li>更新pip</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install --upgrade pip</span><br><span class="line">pip install --upgrade setuptools</span><br><span class="line">pip2 install psycopg2</span><br></pre></td></tr></table></figure>
<h3 id="4-部署CDH"><a href="#4-部署CDH" class="headerlink" title="4. 部署CDH"></a>4. 部署CDH</h3><p>CDH版本6.3.2, 官网停止下载了, 我还留了一份安装包, <a href="https://download.csdn.net/download/u012355401/18809481" target="_blank" rel="noopener">csdn下载地址</a></p>
<h4 id="安装CM"><a href="#安装CM" class="headerlink" title="安装CM"></a>安装CM</h4><ul>
<li>解压, 主节点安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/cloudera-manager/cm6.3.1/RPMS/x86_64/</span><br><span class="line">rpm -ivh cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br><span class="line">rpm -ivh cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br><span class="line">rpm -ivh cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br></pre></td></tr></table></figure>
<ul>
<li>其他节点</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/cloudera-manager/cm6.3.1/RPMS/x86_64/</span><br><span class="line">rpm -ivh cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br><span class="line">rpm -ivh cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br></pre></td></tr></table></figure>
<ul>
<li>所有节点修改agent配置, 指向master</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/etc/cloudera-scm-agent/config.ini server_host=主机名</span><br></pre></td></tr></table></figure>
<ul>
<li>初始化数据库, 测试Mysql连接</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm Kylin@2021!</span><br><span class="line">All done, your SCM database is configured correctly! 成功</span><br></pre></td></tr></table></figure>
<ul>
<li>启动cm server</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 主节点启动server</span></span><br><span class="line">systemctl restart cloudera-scm-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看server运行状态</span></span><br><span class="line">service cloudera-scm-server status</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看server日志</span></span><br><span class="line">tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点启动agent</span></span><br><span class="line">systemctl restart cloudera-scm-agent  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看agent运行状态</span></span><br><span class="line">service cloudera-scm-agent  status</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看agent日志</span></span><br><span class="line">tail -f /var/log/cloudera-scm-agent/cloudera-scm-agent.log</span><br></pre></td></tr></table></figure>
<ul>
<li>启动完毕, 浏览器访问master ip:7180, 默认密码admin/admin</li>
</ul>
<h4 id="安装CDH"><a href="#安装CDH" class="headerlink" title="安装CDH"></a>安装CDH</h4><ul>
<li>开始离线安装CDH,准备parcel包</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 部署离线parcel源</span></span><br><span class="line">mkdir -p /var/www/html/cdh6_parcel</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将parcel包放在httpd的目录下</span></span><br><span class="line">cp cdh/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel /var/www/html/cdh6_parcel/</span><br><span class="line">cp cdh/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel.sha1 /var/www/html/cdh6_parcel/CDH-6.3.1</span><br><span class="line">cp cdh/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel.sha1 /var/www/html/cdh6_parcel/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel.sha</span><br><span class="line">cp cdh/manifest.json /var/www/html/cdh6_parcel/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动httpd服务</span></span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure>
<p>浏览器访问master ip/cdh6_parcel</p>
<ul>
<li>返回CM, 选择免费版下一步下一步, 选主机, 更多选项, 添加源继续, 等解压, 检查集群, 忽略,下一步, 选择安装的组件, 使用之前创建好的账号配置数据库, 配置默认下一步</li>
<li>CDH部署完成</li>
</ul>
<h3 id="5-部署Kylin"><a href="#5-部署Kylin" class="headerlink" title="5. 部署Kylin"></a>5. 部署Kylin</h3><p>以上都顺利的话, 按照官方步骤执行, 即可启动成功<br><a href="https://cwiki.apache.org/confluence/display/KYLIN/Deploy+Kylin+4+on+CDH+6" target="_blank" rel="noopener">Deploy Kylin4 on CDH6</a></p>
]]></content>
      <categories>
        <category>Kylin</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Kylin</tag>
      </tags>
  </entry>
  <entry>
    <title>Kylin-4.0beta版搭建报错指南</title>
    <url>/2021/05/10/20210510191429/</url>
    <content><![CDATA[<p>大部分问题是jar包版本冲突, 导致各种类找不到<br>根本问题是kylin4.0测试版, 依赖spark2.4.6和cdh6.3.2<br>spark2.4.6依赖hadoop2.7和hive1.x<br>cdh6.3.2自带hadoop3.0和hive2.x<br>或者可以试试EMR5.31, 自带spark2.4.6, 可能冲突小一些</p>
<h3 id="NoSuchFieldError-INSTANCE"><a href="#NoSuchFieldError-INSTANCE" class="headerlink" title="NoSuchFieldError: INSTANCE"></a>NoSuchFieldError: INSTANCE</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- java.lang.NoSuchFieldError: INSTANCE</span><br><span class="line">- java.lang.NoClassDefFoundError: Could not initialize class org.apache.http.conn.ssl.SSLConnectionSocketFactory</span><br></pre></td></tr></table></figure>
<p>http包冲突, INSTANCE字段在低版本包不存在<br>cdh6.3.2和spark2.4.6使用的都是httpcore-4.4.x以上版本, kylin4.0启动web页面的tomcat中的kylin.war包里打着一个httpcore-4.2.2.jar<br><strong>解决办法:</strong> 解压war包替换httpcore包版本, 重新打war包放回tomcat里</p>
<h3 id="Spark相关ClassNotFound"><a href="#Spark相关ClassNotFound" class="headerlink" title="Spark相关ClassNotFound"></a>Spark相关ClassNotFound</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- java.lang.ClassNotFoundException: parquet.DefaultSource</span><br><span class="line">- java.lang.ClassNotFoundException: Failed to find data source: parquet.</span><br><span class="line">- yarn找不到</span><br></pre></td></tr></table></figure>
<p>kylin目录下的spark相关jar包没被加载进classpath<br><strong>解决办法:</strong> 修改kylin.sh启动脚本, 手动把spark依赖加进去</p>
<h3 id="7337端口拒接访问"><a href="#7337端口拒接访问" class="headerlink" title="7337端口拒接访问"></a>7337端口拒接访问</h3><p>kylin默认启动了spark的shuffle service<br><strong>解决办法:</strong> 要么去查看yarn的7337端口是不是没起来, 要么直接修改kylin配置, 关闭shuffle service</p>
<h3 id="java-lang-NoSuchFieldError-HIVE-STATS-JDBC-TIMEOUT"><a href="#java-lang-NoSuchFieldError-HIVE-STATS-JDBC-TIMEOUT" class="headerlink" title="java.lang.NoSuchFieldError: HIVE_STATS_JDBC_TIMEOUT"></a>java.lang.NoSuchFieldError: HIVE_STATS_JDBC_TIMEOUT</h3><p>hive版本问题, 该字段在hive1.x中存在, hive2.x被删除<br>spark2.4.6依赖的hive1.x, cdh6.3.2依赖的hive2.x<br>网上有各种办法, 试了对我都不起作用, 下面是我的解决办法<br><strong>解决办法:</strong> 下载spark2.4.6源码, 删除源码中<strong>HIVE_STATS_JDBC_TIMEOUT</strong>和<strong>HIVE_STATS_RETRIES_WAIT</strong>字段, 然后重新编译spark, 使用编译好的spark-hive包替换spark/jars中的spark-hive包<br>理论依据: <a href="https://issues.apache.org/jira/browse/SPARK-18112" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/SPARK-18112</a><br>编译命令<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./build/mvn -Pyarn -Phadoop-2.7 -Dhadoop.version=2.7.5 -Phive -Phive-thriftserver -DskipTests clean package</span><br></pre></td></tr></table></figure></p>
<h3 id="Class-org-apache-hive-hcatalog-data-JsonSerDe-not-found"><a href="#Class-org-apache-hive-hcatalog-data-JsonSerDe-not-found" class="headerlink" title="Class org.apache.hive.hcatalog.data.JsonSerDe not found"></a>Class org.apache.hive.hcatalog.data.JsonSerDe not found</h3><p>创建json格式的外部表报的相关错误<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Class org.apache.hive.hcatalog.data.JsonSerDe not found</span><br><span class="line">- java.lang.ClassNotFoundException: org.apache.hadoop.hive.serde2.Deserializer</span><br><span class="line">- java.lang.ClassCastException: org.apache.hive.hcatalog.data.JsonSerDe cannot be cast to org.apache.hadoop.hive.serde2.Deserializer</span><br><span class="line">- cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD</span><br></pre></td></tr></table></figure></p>
<p><strong>解决办法:</strong> 一开始hive-hcatalog-core包没找到, 加到cdh的hive目录下,  后续还是有问题, 更换了json表的序列化类, 换成了org.apache.hadoop.hive.serde2.JsonSerDe</p>
<h3 id="未解决"><a href="#未解决" class="headerlink" title="未解决"></a>未解决</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Error occurred when check resource. Ignore it and try to submit this job.</span><br><span class="line">- java.lang.UnsupportedOperationException: empty.max</span><br></pre></td></tr></table></figure>
<h3 id="我忘了"><a href="#我忘了" class="headerlink" title="我忘了"></a>我忘了</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- java.lang.NoSuchMethodException: org.apache.hadoop.hive.ql.metadata.Hive.alterTable(java.lang.String, org.apache.hadoop.hive.ql.metadata.Table)</span><br><span class="line">- java.lang.NoSuchMethodError: org.apache.parquet.bytes.BytesInput.toInputStream()Lorg/apache/parquet/bytes/ByteBufferInputStream;</span><br><span class="line">- java.lang.ClassCastException: org.apache.hadoop.hive.ql.metadata.Partition cannot be cast to org.apache.hadoop.hive.ql.metadata.PartitiontectUtils$$anonfun$getPaths$1.apply(ResourceDetectUtils.scala:43)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kylin</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Kylin</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive-创建外部分区表</title>
    <url>/2021/05/06/20210506154231/</url>
    <content><![CDATA[<h2 id="Hive外部分区表"><a href="#Hive外部分区表" class="headerlink" title="Hive外部分区表"></a>Hive外部分区表</h2><h3 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create external table xxx(</span><br><span class="line">xxx int,</span><br><span class="line">xxx string,</span><br><span class="line">xxx array&lt;bigint&gt;,</span><br><span class="line">xxx struct&lt;aaa:string,bbb:string&gt;</span><br><span class="line">)</span><br><span class="line">partitioned by(pk string) # 分区</span><br><span class="line">row format delimited fields terminated by &apos;,&apos; # 按逗号分隔, text存储时使用</span><br><span class="line">row format serde &apos;org.apache.hadoop.hive.serde2.JsonSerDe&apos; # json格式的话加上这条, stored选textfile</span><br><span class="line">stored as parquet # 五种类型可选, textfile, sequencefile, rcfile, orcfile, parquet</span><br><span class="line">location &apos;数据地址&apos;</span><br></pre></td></tr></table></figure>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修复分区</span><br><span class="line">msck repair table xxx;</span><br><span class="line"># 添加/删除分区</span><br><span class="line">alter table xxx add partition(pk=&apos;xxx&apos;) location &apos;xxxx&apos;;</span><br><span class="line">alter table xxx drop partition(pk=&apos;xxx&apos;);</span><br><span class="line"># 查看分区</span><br><span class="line">show partitions xxx;</span><br><span class="line"># 查看分区结构</span><br><span class="line">desc formatted xxx;</span><br><span class="line"># 查看建表语句</span><br><span class="line">show create table xxxx;</span><br><span class="line"># 查看表字段</span><br><span class="line">describe table;</span><br></pre></td></tr></table></figure>
<h3 id="创建view"><a href="#创建view" class="headerlink" title="创建view"></a>创建view</h3><p>kylin只能导入扁平化hive表, 不支持hive复杂数据类型, 导入进去不显示<br>可通过创建view拍平复杂字段<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create view if not exists xxx</span><br><span class="line">partitioned on (pk)</span><br><span class="line">as</span><br><span class="line">select aaa, bbb, ccc from yyy</span><br><span class="line">lateral view inline(properties) pp_table; # properties是struct结构字段, pp_table是lateral view创建的一张虚拟表</span><br></pre></td></tr></table></figure></p>
<h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><p>SerDe是Serialize/Deserilize的简称, 用于序列化和反序列化<br>用户在建表时可以用自定义的SerDe或者Hive自带的SerDe<br>例如json文件, 在Hive0.12以上版本使用<strong>org.apache.hive.hcatalog.data.JsonSerDe</strong><br>在Hive3.0开始被添加到Hive Serde中, <strong>org.apache.hadoop.hive.serde2.JsonSerDe</strong><br>预计在Hive4.0中可直接支持为独立的文件格式, 即stored as jsonfile</p>
]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-字符串匹配</title>
    <url>/2021/03/11/20210311164500/</url>
    <content><![CDATA[<h2 id="字符串匹配"><a href="#字符串匹配" class="headerlink" title="字符串匹配"></a>字符串匹配</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>字符串匹配都不陌生, 例如Java中的indexOf(), Python中的find(), 他们底层就是依赖以下的字符串匹配算法<br>我们从字符串A中查找字符串B, 则A就是<strong>主串</strong>, B就是<strong>模式串</strong><br>字符串匹配算法很多, BF和RK比较简单, BM和KMP比较难但更高效, 这些都是单模式串匹配, Trie树和AC自动机可以多模式串匹配</p>
<h3 id="BF算法-Brute-Force"><a href="#BF算法-Brute-Force" class="headerlink" title="BF算法(Brute Force)"></a>BF算法(Brute Force)</h3><p>中文叫暴力匹配算法, 也叫朴素匹配算法, 简单好懂但性能不高<br>例如主串A长度n, 模式串B长度m<br>核心就是在主串中, 检查起始位置分别是0, 1, 2 … n-m, 且长度为m的全部n-m+1个子串, 看有没有跟模式串匹配的<br>时间复杂度最坏情况是每次对比m个字符, 对比n-m+1次, 为O(n*m), 看上去时间复杂度很高, 但实际开发中却是一个比较常用的字符串匹配算法<br>两点原因</p>
<ul>
<li>大部分情况下, 模式串和主串的长度都不会太长, 且子串不匹配时不需要对比m个字符, 所以实际执行效率还可以</li>
<li>朴素字符串匹配算法思想简单, 代码实现也简单, 不容易出错, 符合KISS(Keep it Simple and Stupid)设计原则, 在满足性能要求的前提下, 简单是首选</li>
</ul>
<h3 id="RK算法-Rabin-Karp"><a href="#RK算法-Rabin-Karp" class="headerlink" title="RK算法(Rabin-Karp)"></a>RK算法(Rabin-Karp)</h3><p>名字由来是两位发明者Rabin和Karp, 这个算法也不难, 是上面BF算法的升级版<br>算法思路是, 通过哈希算法对主串中的n-m+1个子串分别求哈希值, 然后逐个与模式串的哈希值比较大小, 因为哈希值是一个数字, 所以模式串和子串比较的效率就提高了<br>具体实现起来重点在哈希算法的设计, 假设要匹配的字符串的字符集中只包含k个字符, 我们就可以用一个k进制数来表示一个字符串, 再把这个k进制数转成十进制数, 作为子串的哈希值<br>再细处不讲了, 用到了自己查<br>这种哈希算法有一个特点, 在主串中, 相邻两个子串的哈希值的计算公式有交集, 使用前一个子串的哈希值可以很快计算出下一个子串的哈希值<br>时间复杂度, 计算子串哈希值部分, 扫描一遍主串即可, 所以O(n), 模式串与子串比较的时间复杂度O(1), 一共比较n-m+1个, 所以匹配部分时间复杂度也是O(n), RK算法的整体时间复杂度为O(n)<br>当模式串很长时, 以上哈希算法结果可能会超过整型数据范围, 则可以适当允许散列冲突的出现, 极端情况时间复杂度会退化成O(n*m), 但一般基本不会出现</p>
<h3 id="BM算法-Boyer-Moore"><a href="#BM算法-Boyer-Moore" class="headerlink" title="BM算法(Boyer-Moore)"></a>BM算法(Boyer-Moore)</h3><p>它是一种非常高效的字符串匹配算法, 但原理复杂, 比较难懂, 在一些文本编辑器中应用较多<br>核心思想: BF和RK算法都是遇到不匹配的字符时向后滑动一位继续对比, BM是根据自己的规则, 一次向后滑动好几位, 所以效率就提高了<br>即当模式串和主串某个字符不匹配时, 能够跳过一些肯定不会匹配的情况, 将模式串往后滑动几位<br>具体包含两部分:</p>
<ol>
<li><strong>坏字符规则(bad character rule)</strong><br>在匹配过程中从模式串的末尾往前倒着匹配, 当发现某个字符没法匹配时, 把这个主串中的字符叫做坏字符<br>然后拿坏字符在模式串中查找, 若模式串中不存在这个字符, 则可以直接将模式串滑动到这个字符后一位开始比较<br>若坏字符在模式串中存在, 则把模式串滑动到坏字符和模式串的最后出现坏字符的位置对齐, 然后开始比较<br>利用以上操作, BM算法在最好情况下的时间复杂度非常低, 可以降到O(n/m), 但只靠坏字符规则处理不了全部情况, 所以还需要好后缀规则(更复杂)</li>
<li><strong>好后缀规则(good suffix shift)</strong><br>在匹配过程中可能后三个字符是匹配的, 到第四个字符不匹配了, 那么后三个字符就是好后缀记做u<br>拿u在模式串中查找, 如果找到了相匹配的u<em>, 就把模式串滑动到u与u</em>对齐<br>如果没有相匹配的u*, 但模式串的前缀有可能和u的部分有重合, 则滑动到重合部分对齐<br>以上就是两个最重要的规则, 在匹配中遇到字符不匹配时, 分别计算以上两个规则向后滑动的位数, 取两个数中最大的<br>代码实现(todo)</li>
</ol>
<h3 id="KMP算法-Knuth-Morris-Pratt"><a href="#KMP算法-Knuth-Morris-Pratt" class="headerlink" title="KMP算法(Knuth Morris Pratt)"></a>KMP算法(Knuth Morris Pratt)</h3><p>最知名的字符串匹配算法, 出了名的不好懂, 根据三位作者的名字来命名的(D.E.Knuth, J.H.Morris V.R.Pratt)<br>核心思想和BM非常相近, 在模式串与主串匹配的过程中, 当遇到不可匹配的字符时, 找到一些规律将模式串往后多滑动几位, 跳过肯定不会匹配的情况<br>不能匹配的那个字符依旧叫坏字符, 已经匹配的前面那段字符串叫作好前缀, 当遇到坏字符, 向后滑动时, 其实就是拿<strong>主串中的好前缀的后缀子串</strong>和<strong>模式串的好前缀的前缀子串</strong>比较,而主串的好前缀和模式串的好前缀是等价的, 说白了就是拿好前缀本身, 用它自己的后缀子串和前缀子串比较, 查找最长的那个相等的子串, 则这个子串, 在前缀里叫最长可匹配前缀子串, 在后缀里叫最长可匹配后缀子串<br>而好前缀其实可以不涉及到主串, 单用模式串就能解决, 所以可以进行预处理, 在匹配过程中直接调用<br>此处提前构造一个数组叫next, 也叫失效函数, 用来存储模式串中每个好前缀的符合上面条件的最长的可匹配前缀子串的最后一个字符的下标<br>所以next数组下标就等于每个前缀最后一个字符的下标, 也就是好前缀的长度减一, 数组的值就是上面这个最长可匹配前缀子串结尾字符下标<br>而KMP最复杂的部分, 就是next数组的预处理, 不过next数组里前一个元素和后一个元素是有联系的, 可以快速推导出来, 具体看<a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/string/kmp.scala#L42" target="_blank" rel="noopener">代码示例及注释</a><br>空间复杂度O(m), m为模式串长度, 时间复杂度O(n+m)</p>
<h3 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h3><p>一个专门处理字符串匹配的树形数据结构, 用来解决在一组字符串集合中快速查找某个字符串的问题<br>Trie树的本质, 就是利用字符串之间的公共前缀, 将重复的前缀合并在一起, 构造成一颗多叉树, 根节点不存信息, 红色节点表示一个字符串的结尾<br>Trie数主要有两个操作, 把字符串集构造成Trie树和在Trie树中查询一个字符串<br>存储的话, 简单点可以用每个节点一个数组, 因为是多叉树, 可能有很多子节点, 对应到数组里的不同元素<br>但Trie树比较耗内存, 用的是空间换时间的思路, 但确实非常高效, 而对于浪费内存的问题, 可以用有序数组, 跳表, 散列表, 红黑树等代替数组, 牺牲一点查询效率<br>Trie树不适合精确匹配查找, 更适合查找前缀匹配的字符串, 比如各种自动补全, 比如输入法的联想输入, IDE的自动补全, 浏览器搜索的自动补全等</p>
<h3 id="AC自动机-Aho-Corasick"><a href="#AC自动机-Aho-Corasick" class="headerlink" title="AC自动机(Aho-Corasick)"></a>AC自动机(Aho-Corasick)</h3><p>AC自动机实际上就是在Trie树上加了类似KMP算法里的next数组, 把next数组构建在了树上, 即失败指针<br>AC自动机可用于实现高效的敏感词过滤系统, 时间复杂度可近似于O(n), 性能非常高<br>AC自动机的构建包含两个操作</p>
<ul>
<li>把多个模式串构建成Trie树</li>
<li>在Trie树上构建失败指针(具体原理和next数组十分相似)<br>简单了解, 具体实现看代码示例(todo)</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>BF算法, 简单易懂, 场景简单的情况下推荐使用</li>
<li>RK算法, 适用于字符集范围不大, 模式串不太长的情况</li>
<li>BM算法, 实现较复杂, 性能好, 编辑器中字符串查找应用较多, 据说最高效最常用</li>
<li>KMP算法, 最知名, 也很复杂, 和BM算法类似, 更稳定</li>
<li>Trie树, 因为树状结构, 适用于公共前缀较多场景, 比如自动补全, 浏览器预测输入等</li>
<li>AC自动机, 能做到大量文本中多模式精确匹配, 适用于敏感词过滤等</li>
</ul>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-图</title>
    <url>/2021/03/04/20210304165625/</url>
    <content><![CDATA[<h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>图是一种非线性表数据结构, 比树更加复杂<br>涉及图的算法有很多, 比如图的搜索, 最短路径, 最小生成树, 二分图等</p>
<h3 id="图的基本概念"><a href="#图的基本概念" class="headerlink" title="图的基本概念"></a>图的基本概念</h3><p>图中的元素叫做<strong>顶点</strong>, 一个顶点可以与任意其他顶点建立连接关系, 这种建立的关系, 叫做<strong>边</strong><br>跟顶点相连接的边的条数, 叫做顶点的<strong>度</strong><br>图的边可以有方向, 边有方向的叫做<strong>有向图</strong>, 边没有方向的叫做<strong>无向图</strong><br>有向图中, 把度分为<strong>入度</strong>和<strong>出度</strong>, 入度表示有多少条边指向这个顶点, 出度表示有多少条边是以这个顶点为起点指向别的顶点<br>另一种图, <strong>带权图</strong>, 每条边都有一个权重</p>
<h3 id="图的存储"><a href="#图的存储" class="headerlink" title="图的存储"></a>图的存储</h3><ol>
<li>邻接矩阵存储方法<br>图最直观的一种存储方式就是邻接矩阵<br>底层依赖一个二维数组, 对于无向图, 若顶点i到j之前有边, 则A[i][j]和A[j][i]都标为1, 对于有向图, 若顶点i到j之前有指向j的边, 则A[i][j]标为1, 带权图中数组存储相应的权重即可<br>用邻接矩阵来表示一个图, 虽然简单直观, 但是比较浪费存储空间, 如果存储的是稀疏图(顶点非常多), 而每个顶点的边并不多, 则大部分空间都被浪费了<br>优点是存储方式简单, 获取两个顶点的关系时非常高效, 其次是方便计算, 可以将很多图的运算转换成矩阵之间的计算</li>
<li>邻接表存储法<br>邻接表有点像散列表, 每个顶点对应一条链表, 链表中存储的是与这个顶点相连接的其他顶点<br>邻接表存储起来比较节省空间, 但使用起来就比较耗时间, 要查询是否存在一条顶点a到b的边, 就要遍历顶点a的链表<br>为了提高查找效率, 这里的链表也可换成其他更高效的数据结构, 比如平衡二叉查找树, 跳表, 散列表等</li>
</ol>
<h3 id="深度优先和广度优先"><a href="#深度优先和广度优先" class="headerlink" title="深度优先和广度优先"></a>深度优先和广度优先</h3><p>深度优先搜索算法和广度优先搜索算法都是基于图这个数据结构的, 因为图的表达能力强, 大部分涉及搜索的场景, 都可以抽象成图<br>图上的搜索算法, 最直接的理解就是在图中找出从一个顶点出发到另一个顶点的路径<br>其中最简单最暴力的两种搜索就是, <strong>深度优先搜索</strong>和<strong>广度优先搜索</strong></p>
<ol>
<li>广度优先搜索(BFS)<br>其实就是一种地毯式层层推进的搜索策略, 先查找离起始顶点最近的, 然后是次近的, 依次往外搜索<br>广度优先搜索需要借助队列来实现<br>广度优先搜索找出来的是最短路径<br>代码示例(todo)</li>
<li>深度优先搜索(DFS)<br>类似走迷宫, 在分叉口随意选择一个节点, 直到走不通再回退<br>深度优先搜索用的是一种比较著名的算法思想, 回溯思想, 借助栈来实现<br>深度优先搜索找出来的不是最短路径<br>代码示例(todo)</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-堆和堆排序</title>
    <url>/2021/03/02/20210302192117/</url>
    <content><![CDATA[<h2 id="堆和堆排序"><a href="#堆和堆排序" class="headerlink" title="堆和堆排序"></a>堆和堆排序</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>堆, 是一种特殊的树<br>经典的应用场景, 堆排序, 原地的时间复杂度为O(nlogn)的排序算法<br>堆的两点定义:</p>
<ul>
<li>堆是一个完全二叉树</li>
<li>堆中每一个节点的值都必须大于等于/小于等于其子树中每个节点的值</li>
</ul>
<p>每个节点的值都大于等于子树中每个节点值的堆叫做大顶堆, 反之叫做小顶堆</p>
<h3 id="实现一个堆"><a href="#实现一个堆" class="headerlink" title="实现一个堆"></a>实现一个堆</h3><p>之前说过完全二叉树适合用数组存储, 所以堆也用数组存储<br>堆的核心操作有<strong>插入元素</strong>和<strong>删除堆顶元素</strong>, 以大顶堆为例</p>
<ol>
<li>插入元素(todo)<br>把新插入的元素放到堆的最后, 并进行调整使其重新满足堆的特性的过程, 叫<strong>堆化(heapify)</strong><br>堆化有两种, 从下往上和从上往下<br>堆化非常简单, 就是顺着节点所在路径, 向上或者向下, 对比, 然后交换</li>
<li>删除堆顶元素(todo)<br>为保证删除完还是一个完全二叉树, 把最后一个节点放到堆顶,<br>然后利用同样的父子节点对比法, 对不满足父子节点大小关系的互换两个节点, 直到父子节点满足大小关系为止, 这就是从上往下的堆化</li>
</ol>
<p>一个包含n个节点的完全二叉树, 树的高度不会超过logn, 堆化的过程是顺着节点所在路径比较交换, 所以堆化的时间复杂度跟树的高度成正比, 也就是O(logn)<br>插入数据和删除堆顶元素的主要逻辑就是堆化, 所以时间复杂度也是O(logn)</p>
<h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><p>借助堆这种数据结构实现的排序算法, 叫做堆排序<br>时间复杂度非常稳定, 是O(nlogn), 并且是原地排序<br>堆排序的过程大致分为两个大步骤, <strong>建堆</strong>和<strong>排序</strong></p>
<ol>
<li>建堆<br>建堆有两种思路:<br>第一种, 借助插入元素的思路, 从下标2开始依次插入到堆中, 从前往后处理数据, 每个数据从下往上堆化, 代码示例(todo)<br>第二种, 和第一种相反, 从后往前处理数组, 每个数据从上往下堆化, 代码示例(todo)</li>
<li>排序<br>建堆结束后, 数组中的数据已经是按照大顶堆的特性来组织的, 第一个元素就是堆顶, 也是最大的元素<br>然后采用类似删除堆顶元素的操作, 把堆顶元素和最后一个元素交换, 再堆化剩下n-1个元素, 然后重复交换, 堆化, 交换, 堆化…<br>直到最后堆中只剩下一个元素, 排序工作就完成了, 代码示例(todo)</li>
</ol>
<p>整个排序过程中, 只需要极个别临时存储空间, 所以堆排序是原地排序算法<br>堆排序包括建堆和排序两个操作, 建堆过程时间复杂度O(n), 排序过程时间复杂度O(nlogn), 所以堆排序整体时间复杂度是O(nlogn)<br>堆排序不是稳定的排序算法, 因为排序过程中存在最后节点和堆顶节点交换操作, 可能会改变相同值的顺序</p>
<h3 id="堆排序和快排"><a href="#堆排序和快排" class="headerlink" title="堆排序和快排"></a>堆排序和快排</h3><p>为什么快排比堆排序性能好</p>
<ol>
<li>堆排序数据访问方式是跳着访问, 对cpu缓存不友好, 快排数据是顺序访问</li>
<li>对于同样数据, 堆排序的数据交换次数比快排多, 建堆会打乱数据原有相对顺序</li>
</ol>
<h3 id="堆的应用"><a href="#堆的应用" class="headerlink" title="堆的应用"></a>堆的应用</h3><ol>
<li><strong>优先级队列</strong><br>在优先级队列中, 优先级最高的最先出队, 用堆来实现是最直接, 最高效的<br>往优先级队列插入元素等于往堆中插入一个元素, 从优先级队列取出优先级最高元素, 等于取出堆顶元素<br>优先级队列应用场景非常多, 比如赫夫曼编码, 图的最短路径, 最小生成树算法等</li>
<li><strong>求Top K</strong><br>可以维护一个大小为k的小顶堆, 遍历数据, 依次和堆顶元素比较, 如果比堆顶元素大, 就把堆顶元素删除, 将新元素插入堆中<br>如果比堆顶元素小, 就不作处理继续遍历, 等数据遍历完, 堆中就是前k大的数据</li>
<li><strong>求中位数</strong><br>对于静态数据, 中位数是固定的, 可以先排序, 第n/2个数据就是中位数, 但对于动态数据集合, 每次排序效率就很低<br>所以借助堆这种数据结构, 不用排序就可以非常高效的实现求中位数操作<br>我们维护两个堆, 前半部分数据存储一个大顶堆, 后半部分数据存储一个小顶堆, 且小顶堆中的数据都大于大顶堆中的数据<br>这样, 大顶堆的堆顶元素就是我们要的中位数<br>每当新添加数据, 如果数据小于等于大顶堆的堆顶, 就插入到大顶堆, 反之插入到小顶堆, 且从这个堆向另一个堆移动数据, 维护两个堆的数据个数的平衡<br>同理, 此方法可计算各个百分位数据, 比如80百分位数, 99百分位数等</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-红黑树</title>
    <url>/2021/02/24/20210224155253/</url>
    <content><![CDATA[<h2 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h2><p>一般讲到平衡二叉查找树, 都会拿红黑树作为例子, 工程中, 很多用到平衡二叉查找树的地方都会用到红黑树<br>但凡用到动态插入, 删除, 查找数据的场景, 都可以用到它, 不过自己实现起来难度有点高</p>
<h3 id="什么是平衡二叉查找树"><a href="#什么是平衡二叉查找树" class="headerlink" title="什么是平衡二叉查找树"></a>什么是平衡二叉查找树</h3><p>平衡二叉树定义: 二叉树中任意一个节点的左右子树的高度相差不能大于1.<br>完全二叉树, 满二叉树, 都是平衡二叉树</p>
<p>平衡二叉查找树不仅满足上面定义, 还满足二叉查找树的特点<br>最先被发明的平衡二叉查找树是AVL树</p>
<p>但很多平衡二叉查找树并没有严格符合上面的定义, 比如红黑树<br>设计初衷是解决, 普通二叉查找树在频繁的插入, 删除等动态更新的情况下, 出现时间复杂度退化的问题<br>平衡二叉查找树就是让整棵树左右看起来比较平衡, 不要出现左子树高右子树矮的情况, 这样能让整棵树的高度相对低一些, 相应的插入删除查找操作效率高一些.</p>
<h3 id="定义一棵红黑树"><a href="#定义一棵红黑树" class="headerlink" title="定义一棵红黑树"></a>定义一棵红黑树</h3><p>红黑树(Red-Black Tree), 简称R-B Tree, 是一种不严格的平衡二叉查找树<br>红黑树的节点, 一类被标记为黑色, 一类被标记为红色, 且要满足</p>
<ul>
<li>根节点是黑色的</li>
<li>每个叶子节点都是黑色的空节点, 即叶子节点不存储数据</li>
<li>任何相邻节点都不能同时为红色, 即红色节点是被黑色节点隔开的</li>
<li>每个节点, 从该节点到达其可到达叶子节点的所有路径, 都包含相同数目的黑色节点</li>
</ul>
<h3 id="为什么用红黑树"><a href="#为什么用红黑树" class="headerlink" title="为什么用红黑树"></a>为什么用红黑树</h3><p>为什么用红黑树不用其他平衡二叉查找树<br>Treap, Splay Tree无法避免极端情况下时间复杂度的退化<br>AVL树查找效率非常高, 但为了维护这种高度平衡, 每次插入删除都要调整, 比较复杂耗时, 对于有频繁插入删除操作的数据集合, 使用AVL树代价有点高<br>红黑树只做到了近似平衡, 在维护平衡成本上比AVL树要低, 且插入删除查找操作性能都比较稳定, 对于工程应用要面对各种异常情况, 所以更倾向于这种性能稳定的</p>
<h3 id="实现一棵红黑树-不是"><a href="#实现一棵红黑树-不是" class="headerlink" title="实现一棵红黑树 (不是"></a>实现一棵红黑树 (不是</h3><p>大可不必, 左右旋背个滚瓜烂熟过几天就忘<br>红黑树的叶子节点都是黑色的空节点, 是为了方便代码实现, 方便套用平衡公式<br>红黑树平衡过程类似魔方复原, 有几个公式, 在插入删除节点过程中, 会破坏红黑树定义的第三四条, 所以使用平衡公式来恢复<br>插入操作平衡公式有三个, 删除操作平衡公式有七个, 插入操作的平衡调整比较简单, 但删除操作就比较复杂<br>详细实现步骤, 用到以后再去搜, 对照着实现即可</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-二叉树</title>
    <url>/2021/01/28/20210128151430/</url>
    <content><![CDATA[<h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>树, 非线性表结构<br>树有三个概念:<br><strong>高度</strong>从下向上数, 起点是0<br><strong>深度</strong>从上向下数, 起点是0<br><strong>层数</strong>从上向下数, 起点是1</p>
<h3 id="二叉树-1"><a href="#二叉树-1" class="headerlink" title="二叉树"></a>二叉树</h3><p>每个节点最多两个叉<br>有两种特殊二叉树:<br><strong>满二叉树</strong>, 除了叶子节点, 每个节点都有左右两个子节点<br><strong>完全二叉树</strong>, 叶子节点都在最底下两层, 最后一层叶子节点都靠左排列, 且除了最后一层, 其它层节点个数都达到最大<br>满二叉树是完全二叉树的一种特殊情况</p>
<h3 id="存储二叉树"><a href="#存储二叉树" class="headerlink" title="存储二叉树"></a>存储二叉树</h3><ol>
<li>基于指针的二叉链式存储法<br>每个节点三个字段, 一个存数据, 另外两个存左右子节点的指针, 这种方式比较常用, 大部分二叉树代码都是通过这种结构来实现的</li>
<li>基于数组的顺序存储法<br>把根节点存储在i=1的位置, 左子节点存在2i的位置, 右子节点存储在2i+1的位置, 以此类推<br>此种存储方式, 是完全二叉树的话, 只浪费一个下标0的存储位置, 非完全二叉树的话, 会浪费更多的数组存储空间<blockquote>
<p>所以一个树是完全二叉树的话, 用数组存储是最节省内存的一种方式, 也是为什么完全二叉树被单拎出来说明的原因.<br>堆其实就是一种完全二叉树, 最常用的存储方式就是数组</p>
</blockquote>
</li>
</ol>
<h3 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h3><p>如何打印所有节点, 经典方法有三种:<br><strong>前序遍历</strong>, 对于树中的任意节点来说, 先打印这个节点, 再打印左子树, 最后打印右子树 (todo)<br><strong>中序遍历</strong>, 对于树中的任意节点来说, 先打印左子树, 再打印本身, 最后打印右子树 (todo)<br><strong>后序遍历</strong>, 对于树中的任意节点来说, 先打印左子树, 再打印右子树, 最后打印它本身 (todo)<br>实际上二叉树的三种遍历, 就是一个递归的过程<br>遍历的时间复杂度是O(n)<br>不常用的遍历, 按层遍历 (todo)</p>
<h3 id="二叉查找树"><a href="#二叉查找树" class="headerlink" title="二叉查找树"></a>二叉查找树</h3><p>也叫二叉搜索树<br>特点, 支持动态数据集合的快速插入删除, 查找操作<br>二叉查找树要求, 在树的任意一个节点, 其左子树中的每个节点的值, 都要小于这个节点的值, 而右子树节点的值, 都大于这个节点的值</p>
<ol>
<li>查找操作<br>先取根节点, 等于就返回, 比根节点小就在左子树递归查找, 比根节点大就在右子树递归查找</li>
<li>插入操作<br>新插入的数据一般在叶子节点上, 类似查找操作, 从根节点开始比较, 如果要插入数据比节点大, 并且节点的右子树为空, 则直接插到右子节点位置, 如果不为空, 再递归遍历右子树找位置, 如果数据比节点小, 同理遍历左子树查找位置</li>
<li>删除操作<br>相对复杂, 分为三种情况<br>第一种, 要删除节点没有子节点, 直接将父节点指针置为null<br>第二种, 要删除节点有一个子节点, 更新父节点指针指向要删除节点的子节点<br>第三种, 要删除的节点有两个子节点, 需要找到右子树中的最小节点, 替换到要删除的节点上, 然后删除掉这个最小节点</li>
<li>其他操作<br>二叉查找树还支持快速的查找最大节点和最小节点, 前驱节点和后继节点<br>重要特性, 中序遍历二叉查找树, 可以输出有序的数据序列, 时间复杂度O(n), 非常高效</li>
</ol>
<h4 id="支持重复数据的二叉查找树"><a href="#支持重复数据的二叉查找树" class="headerlink" title="支持重复数据的二叉查找树"></a>支持重复数据的二叉查找树</h4><ul>
<li>第一种, 二叉查找树中每个节点不只存一个数据, 借助链表和支持动态扩容的数组等数据结构, 把值相同的数据存在同一个节点上</li>
<li>第二种, 每个节点仍然只存储一个数据, 插入时, 遇到值相同的节点, 就插入到这个节点的右子树, 也就是把这个数当作大于这个节点处理<br>查找数据时, 遇到值相同的节点不停下, 继续在右子树查找, 直到遇到叶子节点, 就可以把所有值相等的节点找出来<br>删除操作同理</li>
</ul>
<h4 id="二叉查找树的时间复杂度"><a href="#二叉查找树的时间复杂度" class="headerlink" title="二叉查找树的时间复杂度"></a>二叉查找树的时间复杂度</h4><p>不同形态的二叉查找树时间复杂度不同, 时间复杂度和树的高度成正比, 也就是O(height)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-哈希算法</title>
    <url>/2020/12/16/20201216153146/</url>
    <content><![CDATA[<h2 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>将任意长度的二进制值串映射为固定长度的二进制值串的映射规则就是哈希算法<br>得到的二进制值串就是哈希值</p>
<h3 id="优秀的哈希算法包括"><a href="#优秀的哈希算法包括" class="headerlink" title="优秀的哈希算法包括"></a>优秀的哈希算法包括</h3><ul>
<li>从哈希值不能反推出原始数据</li>
<li>对输入数据非常敏感, 哪怕一点小修改, 结果也大不相同</li>
<li>散列冲突的概率要很小, 对不同原始数据, 哈希值相同的概率非常小</li>
<li>执行效率要高效, 针对较长的文本, 也能快速计算出哈希值</li>
</ul>
<h3 id="鸽巢原理"><a href="#鸽巢原理" class="headerlink" title="鸽巢原理"></a>鸽巢原理</h3><p>为什么哈希算法无法做到零冲突<br>因为哈希值的长度是固定的, 那么就表示数据是有限的, 而要哈希的数据是无限的, 就必然会有数据存在哈希值相同的情况</p>
<h3 id="哈希算法的应用"><a href="#哈希算法的应用" class="headerlink" title="哈希算法的应用"></a>哈希算法的应用</h3><ol>
<li>安全加密<br>MD5, SHA, DES, AES等<br>虽然加密后不容易反推出原始数据, 但是存在字典攻击, 黑客通过庞大的原文对密文的字典表, 很容易猜中用户的常用密码<br>针对字典攻击, 又可以使用加盐的方式来防御, 比如对原始密码加入再加入复杂的字符串后哈希, 来增加破解难度<br>安全和攻击是一种博弈关系, 不存在绝对的安全, 所有安全措施只是增加攻击成本而已</li>
<li>唯一标识<br>针对较大的文件或者图片, 取部分字节通过哈希算法生成唯一标识, 再存储到散列表中, 可以快速判断图片是否存在</li>
<li>数据校验<br>使用BT下载时, 基于p2p协议会从多个电脑上并行下载, 一部电影会分为多个文件块<br>可以使用种子文件中保存的每个文件块的哈希值来判断, 每个文件块是否被人修改或者缺失</li>
<li>散列函数<br>散列表的散列函数也是哈希算法的一种应用<br>不过相对其他, 散列函数对冲突要求低很多, 且对于能否反向解密也不关心, 而更加关心散列后的值是否分布均匀</li>
<li>负载均衡<br>负载均衡的算法有轮询, 随机, 加权轮询等, 如果要实现同一个客户端, 在一次会话中的所有请求都路由到同一个服务器的话, 可以借助哈希算法<br>通过哈希算法, 对客户端ip地址或者会话id计算哈希值, 将取得的哈希值与服务器列表的大小取模运算, 最终得到的值就是应该被路由到的服务器编号</li>
<li>数据分片<br>分布式计算中, 对数据根据key哈希, 再根据机器数取模, key相同的数据就可以分配到同一台机器上处理</li>
<li>分布式存储<br>分布式存储中常用的一致性哈希算法</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-散列表(Hash表)</title>
    <url>/2020/12/07/20201207185658/</url>
    <content><![CDATA[<h2 id="散列表-Hash表"><a href="#散列表-Hash表" class="headerlink" title="散列表(Hash表)"></a>散列表(Hash表)</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>散列表依赖的是数组支持按下标随机访问数据的特性<br>所以散列表是数组的一种扩展, 由数组演化而来, 如果没有数组就没有散列表<br>时间复杂度O(1), 通过散列函数把元素的key映射为下标, 将数据存储在数组中对应下标的位置<br>当按key查询元素时, 用同样的散列函数, 将key转化为下标, 从对应的数组下标位置取数据</p>
<h3 id="设计散列表"><a href="#设计散列表" class="headerlink" title="设计散列表"></a>设计散列表</h3><p>要可以应对各种异常情况的工业级</p>
<ol>
<li>散列函数的设计不能太复杂<br>散列函数设计的好坏直接决定散列表的性能<br>散列函数生成的值要尽可能随机且均匀分布<br>散列函数计算结果是非负整数, 因为数组下标从0开始<br>如果key1 = key2, 那么hash(key1)=hash(key2)</li>
<li>选择解决冲突的办法<br>再好的散列函数也无法避免散列冲突, 所以常用的解决冲突方法有两类<br>(1)开放寻址法<br>核心思想就是, 如果出现了散列冲突, 就重新探测一个空闲位置, 那么如何探测<br>线性探测, 当前位置被占用, 就依次向后查找, 直到找到为止<br>二次探测, 类似线性探测, 不过步长每次移原来的二次方<br>双重散列, 使用一组散列函数, 一个位置被占用, 再使用第二个散列函数, 直到找到空闲位置<br>但问题是, 当散列表中空闲位置越少, 冲突概率就越大, 为保证效率, 一般会保证散列表中有一定比例的空闲位置, 用装载因子(填入元素个数/散列表长度)来表示<br>当数据量小, 装载因子小的时候适合<br>(2)链表法<br>更常用的解决冲突办法, 而且简单<br>数组每个下标里对应一条链表, 插入元素时, 通过散列函数, 确定链表, 将数据插入对应的链表中<br>时间复杂度和链表的长度成正比, O(k)<br>适合存储大对象, 大数据量的散列表, 支持更多的优化策略, 比如链表过长时用红黑树代替链表</li>
<li>定义转载因子阈值, 设计动态扩容策略<br>避免低效扩容<br>当装载因子达到阈值, 申请新的空间, 每当有新数据插入, 将新数据插入到新散列表, 并从老散列表拿一个数据插入新散列表, 就可以逐渐全部转移且感受不到特别慢的扩容过程<br>当查询时, 先查新散列表, 没找到再查旧散列表</li>
</ol>
<h3 id="Java中的HashMap"><a href="#Java中的HashMap" class="headerlink" title="Java中的HashMap"></a>Java中的HashMap</h3><p>初始大小16<br>装载因子0.75, 每次扩容至两倍<br>冲突解决方法为链表法, 当链表长度超过8转换为红黑树<br>散列函数<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> h = key.hashCode()； </span><br><span class="line">    <span class="keyword">return</span> (h ^ (h &gt;&gt;&gt; <span class="number">16</span>)) &amp; (capicity -<span class="number">1</span>); <span class="comment">//capicity表示散列表的大小</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="散列表碰撞攻击"><a href="#散列表碰撞攻击" class="headerlink" title="散列表碰撞攻击"></a>散列表碰撞攻击</h3><p>通过精心构造的数据使得所有数据经过hash函数以后都散列到一个槽里, 如果使用的基于链表的冲突解决方案, 散列表就会退化为链表,<br>数据里极大时会导致查询消耗大量cpu和线程资源, 造成系统无法响应其他请求</p>
<h3 id="散列表和链表常用组合场景"><a href="#散列表和链表常用组合场景" class="headerlink" title="散列表和链表常用组合场景"></a>散列表和链表常用组合场景</h3><ul>
<li>LRU缓存淘汰算法<br>使用双向链表存储数据, 链表中每个结点包含数据(data), 前驱指针(prev), 后继指针(next), 和hnext<br>使用链表法解决的散列表, 包含两条链, 一条双向链表, 一条散列表的拉链<br>可实现O(1)时间复杂度内完成插入删除查找操作</li>
<li>java LinkeHashMap<br>支持按照插入顺序遍历数据, 和按照访问顺序遍历数据<br>链表结合散列表, 原理和LRU一样, Linked指的是双向链表</li>
</ul>
<p>两者结合, 散列表提供快速的插入删除查找, 链表提供有序</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>工业级散列表应该具有哪些特性<br>支持快速查询, 插入, 删除操作<br>内存占用合理, 不浪费过多的内存空间<br>性能稳定, 极端情况下散列表的性能也不会退化到无法接受的情况</p>
<h3 id="课后思考"><a href="#课后思考" class="headerlink" title="课后思考"></a>课后思考</h3><p>10w条url访问日志, 按照访问次数排序 (todo)<br>两个10w条字符串的数组, 快速找出两个数组中相同的字符串 (todo)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>散列表</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-跳表</title>
    <url>/2020/12/02/20201202170715/</url>
    <content><![CDATA[<h2 id="跳表-Skip-List"><a href="#跳表-Skip-List" class="headerlink" title="跳表(Skip List)"></a>跳表(Skip List)</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>基于链表稍加改造的一种各方面性能都比较优秀的动态数据结构, 可支持快速插入, 删除, 查找操作, 甚至可以代替红黑树<br>基于原链表每两个结点向上一级抽索引, 构建出一级索引层, 可构建多级索引, 这种链表加多级索引的结构, 就是跳表<br>redis中的有序集合(sorted set)就是采用跳表实现</p>
<p>跳表中查询任意数据的时间复杂度都是O(logn), 但空间复杂度O(n), 每三到五个元素抽一个索引可以减少索引存储空间占用<br>但实际开发中不必太在意索引占用的额外空间, 因为当原始链表中存储的为对象时, 索引中存储的指针和对象相比, 占用空间可以忽略</p>
<h3 id="插入删除"><a href="#插入删除" class="headerlink" title="插入删除"></a>插入删除</h3><p>跳表还支持动态的插入和删除操作, 时间复杂度也是O(logn)<br>但插入元素同时, 需要维护索引的平衡, 采用随机函数的方式, 将此结点同时插入到第一层到第k层索引中<br>删除操作, 同样需要删除掉索引中的结点</p>
<h3 id="代码实现-todo"><a href="#代码实现-todo" class="headerlink" title="代码实现 (todo)"></a>代码实现 (todo)</h3><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>跳表采用空间换时间的设计思路, 通过多级索引提高查询效率, 实现了基于链表的二分查找<br>跳表虽然本身不简单, 但相对红黑树的实现还是简单不少, 有时为了代码简单易读, 相比红黑树会使用跳表<br>跳表更加灵活, 通过改变索引构建策略, 可以有效平衡执行效率和内存消耗</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>跳表</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-二分查找</title>
    <url>/2020/12/02/20201202152632/</url>
    <content><![CDATA[<h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>二分查找, 也叫折半查找, 是一种简单的快速查找算法<br>二分查找针对的是一个有序的数据集合, 查找思想类似分治, 每次都通过跟区间的中间元素对比, 将待查找的区间缩小为之前的一半, 直到找到要查找的元素, 或者区间被缩小为0<br>时间复杂度O(logn), 对数时间复杂度</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>二分查找的递归与非递归实现<br>最简单的情况是有序数组中不存在重复元素<br>循环实现 (todo)<br>递归实现 (todo)<br>容易出错的三个地方</p>
<ol>
<li>循环退出条件, low&lt;=high</li>
<li>min的取值, low和high比较大的话, 相加可能会溢出</li>
<li>low和high的更新, low=mid或high=mid可能会死循环</li>
</ol>
<h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><ol>
<li>依赖顺序表结构, 既数组, 因为依赖按下标随机访问元素</li>
<li>针对有序数据, 如果无序需要先排序, 如果插入删除操作频繁, 则需频繁排序, 所以不适用二分查找</li>
<li>数据量适中, 数据量太小直接用遍历更为方便, 数据量太大时, 因为需要存储在数组, 需要连续内存空间, 内存可能放不下</li>
</ol>
<h3 id="进阶版"><a href="#进阶版" class="headerlink" title="进阶版"></a>进阶版</h3><ul>
<li>查找第一个值等于给定值的元素 (todo)</li>
<li>查找最后一个值等于给定值的元素 (todo)</li>
<li>查找第一个大于等于个定制的元素 (todo)</li>
<li>查找最后一个小于等于给定值的元素 (todo)</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>等值查找使用散列表或者二叉查找树更多, 二分查找更适合用在近似查找问题</p>
<h3 id="课后练习"><a href="#课后练习" class="headerlink" title="课后练习"></a>课后练习</h3><p>求一个数的平方根, 精确到小数点后6位 (todo)<br>一个循环有序数组[4,5,6,1,2,3]中查找某个值 (todo)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-排序</title>
    <url>/2020/12/01/20201201164903/</url>
    <content><![CDATA[<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>排序算法有很多, 最经典最常用的有<br>冒泡排序, 插入排序, 选择排序, 时间复杂度 O(n平方)<br>快速排序, 归并排序, 时间复杂度O(nlogn)<br>桶排序, 计数排序, 基数排序, 时间复杂度O(n)</p>
<h3 id="分析排序算法"><a href="#分析排序算法" class="headerlink" title="分析排序算法"></a>分析排序算法</h3><ul>
<li>执行效率</li>
</ul>
<ol>
<li>最好情况, 最坏情况, 平时情况时间复杂度</li>
<li>时间复杂度的系数, 常数, 低阶</li>
<li>元素比较次数和移动次数</li>
</ol>
<ul>
<li>内存消耗<br>可以通过空间复杂度来衡量</li>
<li>稳定性<br>稳定排序算法可以保持数值相同的两个对象, 在排序之后的前后顺序不变<br>真实开发中排序场景往往比较复杂, 有些问题借助稳定排序算法可以非常简洁的解决</li>
</ul>
<h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a><a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/sort/bubble.scala" target="_blank" rel="noopener">冒泡排序</a></h3><p>冒泡过程只涉及相邻数据的交换操作, 所以空间复杂度为O(1), 是一个原地排序算法<br>且当相邻的两个元素大小相等时不交换, 相同大小的数据在排序前后不会改变顺序, 所以冒泡排序是稳定的排序算法<br>最好的情况数据有序, 时间复杂度O(n), 最坏的情况数据倒序, 时间复杂度O(n平方), 平均时间复杂度为O(n平方)</p>
<h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a><a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/sort/insertion.scala" target="_blank" rel="noopener">插入排序</a></h3><p>将数组中的元素分为已排序区和未排序区, 取未排序区元素在已排序区找到合适的位置插入, 并保证已排序区数据一直有序, 直至未排序区为空<br>插入排序运行也不需要额外的存储空间, 所以空间复杂度是O(1), 是一个原地排序算法<br>排序时, 对于值相同的元素可以选择将后面出现的元素插入到前面出现的元素的后面, 所以是稳定的排序算法<br>最好的情况数据有序, 时间复杂度O(n), 最坏的情况数据倒序, 时间复杂度O(n平方), 平均时间复杂度为O(n平方)</p>
<h3 id="选择排序-todo"><a href="#选择排序-todo" class="headerlink" title="选择排序 (todo)"></a>选择排序 (todo)</h3><p>选择排序类似插入排序, 分已排序区和未排序区, 但每次会从未排序区找到最小元素, 交换位置放到已排序区末尾<br>选择排序一样空间复杂度为O(1), 是一种原地排序算法<br>最好最坏和平均时间复杂度都是O(n平方)<br>因为存在交换位置, 所以选择排序不是一种稳定的排序算法, </p>
<blockquote>
<p>以上三种时间复杂度较高, 适合小规模数据排序<br>选择排序不是稳定排序算法, 所以稍逊色于冒泡排序和插入排序, 而冒泡排序的数据交换要比插入排序的数据移动复杂, 所以这三种排序, 插入排序更为常用</p>
</blockquote>
<h3 id="归并排序-todo"><a href="#归并排序-todo" class="headerlink" title="归并排序 (todo)"></a>归并排序 (todo)</h3><p>核心思想, 先把数组从中间分成两部分, 然后对前后两部分排序, 再将排好序的两部分合并, 就得到有序的完整数组<br>归并排序使用的分治思想, 分治是一种解决问题的处理思想, 递归是一种编程技巧<br>用递归代码来实现归并排序<br>归并排序合并过程中, 值相同的元素可以自己掌握顺序, 所以是一个稳定的排序算法<br>时间复杂度为O(nlogn), 且执行效率与原始数组有序度无关, 最好最坏平均情况都是O(nlogn)<br>但不是原地排序算法, 空间复杂度为O(n)</p>
<h3 id="快速排序-todo"><a href="#快速排序-todo" class="headerlink" title="快速排序 (todo)"></a>快速排序 (todo)</h3><p>也采用分治思想<br>假如要排序的数组, 最左下标为’左’, 最右下标为’右’, 选中间任意一个点为分区点, 下标’中’<br>遍历从左到右, 将小于’中’的放到左边, 大于’中’的放到右边, 数组就被分成了三部分, ‘左’到’中-1’的都是小于’中’下标的元素的, ‘中+1’到’右’都是大于’中’下标元素的<br>根据分治思想, 用递归继续排序’左’到’中-1’和’中+1’到’右’, 直到区间缩小为1, 则所有数据有序, 具体实现方法看源码<br>原地, 不稳定排序算法, 分区过程中有交换操作, 所以相同元素顺序会变<br>时间复杂度O(nlogn), 但分区极其不均匀的情况会退化为O(n平方), 平均O(nlogn)<br>常用选取分区点的算法</p>
<ol>
<li>三数取中法, 从头尾中取三个数, 对比大小取中间值作为分区点</li>
<li>随机法, 随机选择一个元素做为分区点</li>
</ol>
<blockquote>
<p>以上, 快排和归并很相似, 区别是归并排序是从下向上处理, 先处理子问题再合并, 快排是由上到下, 先分区, 再处理子问题<br>归并时间复杂度稳定但空间复杂度高, 快排空间复杂度低, 且通过合理选择分区点可以避免时间复杂度退化为O(n平方), 所以快排应用更广泛</p>
</blockquote>
<h3 id="桶排序-todo"><a href="#桶排序-todo" class="headerlink" title="桶排序 (todo)"></a>桶排序 (todo)</h3><p>核心思想把要排序的数据分到几个有序的桶里, 每个桶里的数据再单独排序, 之后按顺序依次取出<br>桶排序对排序数据要求苛刻, 要能很容易划分成m个桶, 且桶之间有大小顺序, 其次各个桶之间的数据分布均匀<br>桶排序比较适合用在外部排序中, 即数据存储在外部磁盘, 数据量大, 内存有限<br>比如10G订单数据, 内存100MB排序问题, 可用桶排序划分订单数据, 每个桶生成一个文件, 如果桶间数据不均匀, 找到较大的文件, 继续分桶, 直到所有文件都能读入内存</p>
<h3 id="计数排序-todo"><a href="#计数排序-todo" class="headerlink" title="计数排序 (todo)"></a>计数排序 (todo)</h3><p>计数排序是桶排序的一种特殊情况<br>当数据范围不大时, 最大值为k, 就分k个桶, 省去桶内排序时间, 如果k要比排序的元素个数大得多, 则不适合用计数排序<br>和桶排序非常相似, 只是桶的大小粒度不一样<br>实现细节稍微复杂, 见代码<br>计数排序只能给非负整数排序, 如有其它类型, 则想办法在不改变相对大小前提下转化为非负整数</p>
<h3 id="基数排序-todo"><a href="#基数排序-todo" class="headerlink" title="基数排序 (todo)"></a>基数排序 (todo)</h3><p>基数排序对数据有要求, 需要可以分割出独立的位来比较, 且位之间有递进的关系, 从后向前一位一位进行线性排序<br>另外, 每一位的数据范围不能太大, 要可以用线性排序算法来排序, 否则时间复杂度就大于O(n)了<br>针对长度不一样的, 可以在前面或后面补0<br>比较两个数只需要比较高位, 高位相同再比较低位</p>
<blockquote>
<p>以上三种都是线性时间复杂度的排序算法, 它们对要排序的数据有要求, 所以应用不是很广泛, 但如果数据特征匹配, 会非常高效, 时间复杂度可达O(n), 都是稳定非原地排序</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上都是理论知识, 生产环境中使用的排序函数通常都不是基于一种排序算法, 比如数据量小用归并排序, 数据量大用快排, 快排到区间内元素较少时改用插入排序<br>为了尽可能提高性能, 通常会做很多优化</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-递归</title>
    <url>/2020/11/26/20201126191531/</url>
    <content><![CDATA[<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h2><h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p>递归是一种应用非常广泛的, 高效简洁的编程技巧, 很多数据结构和算法的编码实现都要用到递归</p>
<h3 id="递归需要满足的三个条件"><a href="#递归需要满足的三个条件" class="headerlink" title="递归需要满足的三个条件"></a>递归需要满足的三个条件</h3><ol>
<li>一个问题的解可以分解为几个子问题的解</li>
<li>原问题和分解后的子问题求解思路完全一致</li>
<li>存在递归终止条件</li>
</ol>
<h3 id="写递归代码的关键"><a href="#写递归代码的关键" class="headerlink" title="写递归代码的关键"></a>写递归代码的关键</h3><p>写递归代码的关键就是找如何将大问题分解成小问题的规律, 并且基于此写出<strong>递推公式</strong>, 然后推敲<strong>终止条件</strong>, 最后将递推公式和终止条件翻译成代码<br>只要遇到递归, 就把他抽象成一个递推公式, 不用想一层层的调用关系, 不要试图用人脑去分析递归的每一个步骤</p>
<h3 id="递归常见问题"><a href="#递归常见问题" class="headerlink" title="递归常见问题"></a>递归常见问题</h3><ol>
<li><p>堆栈溢出<br>如果递归求解的数据规模很大, 调用层次很深, 一直将临时变量压入内存栈, 就会有堆栈溢出的风险<br>解决办法就是限制最大的调用深度</p>
</li>
<li><p>重复计算<br>为了避免重复计算, 可以通过一个比如散列表来保存已经求解过的f(n), 当调用到f(n)时, 查找是否已经求解过, 如果是则直接取值, 可避免重复计算</p>
</li>
<li><p>其他还有函数调用耗时高, 空间复杂度高等问题, 在编写代码时, 要控制好这些副作用</p>
</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-队列</title>
    <url>/2020/11/25/20201125170035/</url>
    <content><![CDATA[<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><h3 id="基本特性"><a href="#基本特性" class="headerlink" title="基本特性"></a>基本特性</h3><p>先进者先出, 这就是典型的队列<br>和栈很相似, 队列的基本操作也是两个, 入队和出队<br>和栈一样也是一种操作受限的线性表数据结构</p>
<h3 id="实现一个队列"><a href="#实现一个队列" class="headerlink" title="实现一个队列"></a>实现一个队列</h3><p>用数组实现的队列叫顺序队列 (todo)<br>用链表实现的队列叫链式队列 (todo)</p>
<h3 id="队列的应用"><a href="#队列的应用" class="headerlink" title="队列的应用"></a>队列的应用</h3><ol>
<li>阻塞队列<br>队列为空时取数据被阻塞, 队列满时, 插入数据被阻塞, 即生产者消费者模型</li>
<li>并发队列<br>多线程的情况下, 线程安全的队列叫并发队列, 基于数组的循环队列, 利用CAS原子操作, 可实现非常高效的并发队列, 因此循环队列比链式队列应用更加广泛</li>
</ol>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>队列可以应用在任何有限资源池中, 用于排队请求</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-栈</title>
    <url>/2020/11/25/20201125150101/</url>
    <content><![CDATA[<h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><h3 id="基本特性"><a href="#基本特性" class="headerlink" title="基本特性"></a>基本特性</h3><p>后进者先出, 先进者后出, 这就是典型的栈结构<br>栈是一种操作受限的线性表, 只允许在一端插入和删除数据<br>栈是一种特定的数据结构,是对特定场景的抽象<br>当某个数据集合只涉及在一端插入和删除数据, 并且满足后进先出, 先进后出的特性, 我们就应该首选栈这种数据结构</p>
<h3 id="实现一个栈"><a href="#实现一个栈" class="headerlink" title="实现一个栈"></a>实现一个栈</h3><p>栈主要包含两个操作, 入栈和出栈<br><a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/struct/stack/ArrayStack.scala" target="_blank" rel="noopener">用数组实现的栈叫顺序栈</a><br>用链表实现的栈叫链式栈 (todo)<br>两种实现的空间复杂度和时间复杂度都为O(1)</p>
<h3 id="栈的应用"><a href="#栈的应用" class="headerlink" title="栈的应用"></a>栈的应用</h3><ol>
<li>函数调用栈<br>操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈</li>
<li>表达式求值<br>一个保存操作数的栈，一个保存运算符的栈。从左向右遍历表达式，当遇到数字，就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较<br>如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取两个操作数，然后进行计算，再把计算完的结果压入操作数栈</li>
<li>检测括号匹配<br>扫描到左括号入栈, 扫描到右括号从栈顶取一个元素匹配</li>
<li>浏览器前进后退功能<br>两个栈实现, 首次浏览页面压入后退栈, 点击后退按钮将后退栈元素出栈压入前进栈</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub-整个活, 好看的GitHub自我介绍</title>
    <url>/2020/11/19/20201119190543/</url>
    <content><![CDATA[<p>突然发现, 在GitHub创建和用户名同名的仓库会有彩蛋, 呐<br><img src="http://www.wangdanpeng.com/img/20201119190543-1.png" alt="彩蛋"><br>意思说这是一个特殊的库, 它的README.md文件的内容将会显示到你的主页上<br>那么咱们就可以用markdown在这里写一些带格式的自我介绍(尽情发挥脑洞)</p>
<p>另外呢, 还有这么一个项目 <a href="https://github.com/anuraghazra/github-readme-stats/blob/master/docs/readme_cn.md" target="_blank" rel="noopener">github-readme-stats</a><br>可以动态获取你的账户的统计信息, 具体内容看它的介绍, 主题也可以选择<br>另外搭配<code>&lt;img&gt;</code>标签, 可以控制展示的位置, 比如以下让他靠右<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">align</span>=<span class="string">"right"</span> <span class="attr">src</span>=<span class="string">"https://github-readme-stats.vercel.app/api?username=WangDanPeng&amp;show_icons=true"</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>那么最终效果就如下了<br><img src="http://www.wangdanpeng.com/img/20201119190543-2.png" alt="效果图"><br>赞👍</p>
]]></content>
      <categories>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-在本地使用多个git账号</title>
    <url>/2020/11/18/20201118183648/</url>
    <content><![CDATA[<p>如何设置在本地使用多个Git账号, 比如一个公司的gitlab账号和一个本人的github账号</p>
<p>1 分别给每个账号生成ssh密钥<br>默认的生成路径在~/.ssh/id_rea, 记得指定文件名改地址防止覆盖当前的, 例如~/.ssh/id_rsa_gh<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;xxx@gmail.com&quot;</span><br></pre></td></tr></table></figure></p>
<p>2 把生成好的key, 对应创建到github和公司的gitlab里</p>
<p>3 让ssh识别新密钥, 添加到ssh agent<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-add ~/.ssh/id_rsa_gh</span><br></pre></td></tr></table></figure></p>
<p>4 配置config<br><code>~/.ssh/config</code>文件, 没有就创建一个, 添加以下内容<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#公司的</span><br><span class="line">Host gitlab.com</span><br><span class="line">HostName gitlab.com</span><br><span class="line">User xxx@公司邮箱.com</span><br><span class="line">IdentityFile ~/.ssh/id_rsa_work</span><br><span class="line"></span><br><span class="line">#个人的</span><br><span class="line">Host github.com</span><br><span class="line">HostName github.com</span><br><span class="line">User xxx@gmail.com</span><br><span class="line">IdentityFile ~/.ssh/id_rsa_gh</span><br></pre></td></tr></table></figure></p>
<p>测试一下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com(github.com是你的host)</span><br></pre></td></tr></table></figure></p>
<p>5 删掉曾经设置过的全局变量 ~/.gitconfig<br>对单个项目设置用户名和邮箱<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config user.name &quot;xxx&quot;</span><br><span class="line">git config user.email &quot;xxx@gmail.com&quot;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-live2d插件给你的博客加一只可爱的看板娘</title>
    <url>/2020/09/12/20200912164541/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>放一只简简单单的看板娘, 没有什么互动, 安安静静的陪着你读博客.<br>插件github地址 -&gt; <a href="https://github.com/EYHN/hexo-helper-live2d/blob/master/README.zh-CN.md" target="_blank" rel="noopener">hexo-helper-live2d</a><br>我的博客效果图 -&gt; <a href="http://www.wangdanpeng.com/2020/09/12/20200912164541/">Mr.Wang_Blog</a></p>
<h2 id="模块安装"><a href="#模块安装" class="headerlink" title="模块安装"></a>模块安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-helper-live2d</span><br></pre></td></tr></table></figure>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>以<code>live2d-widget-model-miku</code>模型为例</p>
<ol>
<li>在博客根目录下创建一个<code>live2d_models</code>文件夹.</li>
<li>使用<code>npm install live2d-widget-model-miku</code>下载模型, 并将模型目录<code>live2d-widget-model-miku</code>从<code>node_modules</code>里复制到<code>live2d_models</code>下.</li>
<li>进入<code>live2d-widget-model-miku</code>, 把<code>assets</code>里的内容复制到外一层.</li>
<li>添加如下配置文件, 并修改use的模型名称为<code>live2d-widget-model-miku</code>, 部署即可看到效果.</li>
</ol>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>向博客根目录的<code>_config.yml</code>配置文件添加配置, 可以自己微调<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">live2d:</span><br><span class="line">  enable: true</span><br><span class="line">  scriptFrom: local</span><br><span class="line">  pluginRootPath: live2dw/</span><br><span class="line">  pluginJsPath: lib/</span><br><span class="line">  pluginModelPath: assets/</span><br><span class="line">  tagMode: false</span><br><span class="line">  debug: false</span><br><span class="line">  model:</span><br><span class="line">    use: live2d-widget-model-wanko # 使用的模型名称</span><br><span class="line">  display:</span><br><span class="line">    position: right # 在页面里的位置</span><br><span class="line">    hOffset: 0 # 水平偏移量, 自己微调</span><br><span class="line">    vOffset: -20 # 垂直偏移量, 自己微调</span><br><span class="line">    width: 150 </span><br><span class="line">    height: 300</span><br><span class="line">  mobile:</span><br><span class="line">    show: true</span><br><span class="line">  react:</span><br><span class="line">    opacity: 0.7 # 透明度</span><br></pre></td></tr></table></figure></p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>现有的模型包及预览<br><code>live2d-widget-model-chitose</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-chitose.png" alt="chitose"><br><code>live2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru)</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-haur01.png" alt="haru01"><br><code>live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru)</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-haru02.png" alt="haru02"><br><code>live2d-widget-model-haruto</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-haruto.png" alt="haruto"><br><code>live2d-widget-model-hibiki</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-hibiki.png" alt="hibiki"><br><code>live2d-widget-model-hijiki</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-hijiki.png" alt="hijiki"><br><code>live2d-widget-model-izumi</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-izumi.png" alt="izumi"><br><code>live2d-widget-model-koharu</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-koharu.png" alt="koharu"><br><code>live2d-widget-model-miku</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-miku.png" alt="miku"><br><code>live2d-widget-model-ni-j</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-ni-j.png" alt="nij"><br><code>live2d-widget-model-nico</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-nico.png" alt="nico"><br><code>live2d-widget-model-nietzsche</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-nietzsche.png" alt="nietzsche"><br><code>live2d-widget-model-nipsilon</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-nipsilon.png" alt="nipsilon"><br><code>live2d-widget-model-nito</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-nito.png" alt="nito"><br><code>live2d-widget-model-shizuku</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-shizuku.png" alt="shizuku"><br><code>live2d-widget-model-tororo</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-tororo.png" alt="tororo"><br><code>live2d-widget-model-tsumiki</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-tsumiki.png" alt="tsumiki"><br><code>live2d-widget-model-unitychan</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-unitychan.png" alt="unitychan"><br><code>live2d-widget-model-wanko</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-wanko.png" alt="wanko"><br><code>live2d-widget-model-z16</code><br><img src="http://www.wangdanpeng.com/img/live2d/live2d-z16.png" alt="z16"></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-链表</title>
    <url>/2020/09/03/20200903153417/</url>
    <content><![CDATA[<h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><p>比数组稍微复杂一点的数据结构</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>不需要连续的内存空间, 通过指针将一组零散的内存块串联起来使用.<br>链表结构五花八门, 三种最常见的链表结构, <strong>单链表</strong>, <strong>双向链表</strong>, <strong>循环链表</strong>.</p>
<h3 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h3><p>被串联的内存块称为结点, 每个结点存有<strong>数据</strong>和记录<strong>下一个结点的地址</strong>, 叫做后继指针next<br>第一个结点叫头结点, 最后一个结点叫尾结点, 尾结点指向一个空地址null.</p>
<p>链表也支持数据的查找, 插入和删除操作<br>链表的插入和删除操作只需要考虑相邻接点的指针改变, 所以时间复杂度为O(1).<br>但想要随机访问第k个元素, 就需要一个一个结点遍历, 需要O(n)的时间复杂度.</p>
<h3 id="循环链表和双向链表"><a href="#循环链表和双向链表" class="headerlink" title="循环链表和双向链表"></a>循环链表和双向链表</h3><p>循环链表是一种特殊的单链表, <strong>尾结点指向链表的头结点</strong>.<br>优点是从链尾到链头比较方便, 当要处理的数据有环形结构时, 就适合采用循环链表, 比如约瑟夫问题(todo)</p>
<p>双向链表支持两个方向, 每个结点不只有一个<strong>后继指针next</strong>, 还有一个<strong>前驱指针prev</strong>.<br>双向链表需要额外的空间存储后继结点和前驱结点地址, 如果存储同样多的数据, 双向链表比单链表占用更多的内存空间.<br>双向链表可以O(1)的时间复杂度找到前驱结点, 因此某些情况下, 双向链表的插入删除等操作比单链表更简单高效.</p>
<p>常见的删除操作有两种:</p>
<ol>
<li>删除结点中值等于给定值的结点</li>
<li>删除给顶指针指向的结点<br>对于第一种, 单链表和双向链表的时间复杂度都是O(n), 但对于第二种, 双向链表的时间复杂度为O(1),<br>同理, 在链表的某个指定结点前插入一个结点时, 双向链表的时间复杂度也是O(1).<br>另外, 对于有序链表, 双向链表的按值查询效率也高一些.</li>
</ol>
<p><strong>双向链表尽管比较费内存, 但比单链表应用更广泛, 比如java中的LinkedHashMap容器, 就用到了双向链表, 即空间换时间策略.</strong></p>
<h3 id="和数组的比较"><a href="#和数组的比较" class="headerlink" title="和数组的比较"></a>和数组的比较</h3><p>插入, 删除, 随机访问的时间复杂度正好相反.<br>数组简单易用, 可借助cpu缓存机制预读数组中的数据, 访问效率更高, 缺点是大小固定, 不能动态扩容.</p>
<h3 id="写链表代码技巧"><a href="#写链表代码技巧" class="headerlink" title="写链表代码技巧"></a>写链表代码技巧</h3><ol>
<li>理解指针或引用含义<br> 将某个变量赋值给指针, 实际上是将这个变量的地址赋值给指针.</li>
<li>警惕指针丢失和内存泄漏<br> 插入节点时, 一定要注意操作顺序.</li>
<li>利用哨兵简化实现难度<br> 针对链表的插入删除操作, 需要对插入头结点和删除尾结点特殊处理, 所以可插入一个不带数据的哨兵结点, 这种链表被称为带头链表.</li>
<li>重点留意边界条件处理<br> 比如链表为空, 只有一个结点, 有两个结点, 处理头结点和尾结点时.</li>
<li>举例画图, 辅助思考<br> 画图法和举例法, 帮助理清思路</li>
<li>多写多练<br> <a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/struct/link/ReverseSingleLink.scala" target="_blank" rel="noopener">单链表反转</a><br> 链表中环的检测 (todo)<br> 两个有序的链表合并 (todo)<br> 删除链表倒数第n个结点 (todo)<br> 求链表的中间结点 (todo)<br> <a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/struct/link/LRU.scala" target="_blank" rel="noopener">基于链表实现LRU缓存淘汰算法</a><br> 单链表字符串, 判断是一个回文串 (todo)</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-数组</title>
    <url>/2020/09/01/20200901160919/</url>
    <content><![CDATA[<h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>基础数据结构</p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>数组是一种<strong>线性表</strong>数据结构, 使用一组<strong>连续内存空间</strong>, 存贮一组具有<strong>相同类型的数据</strong>.<br>提炼两组关键词:<br>  <strong><em>1. 线性表</em></strong><br>线性表只有前后两个方向, 同样线性表还有链表, 队列, 栈.<br>非线性表有二叉树, 堆, 图等, 数据并不是前后关系.<br> <strong><em>2. 连续内存空间和相同类型的数据</em></strong><br>因为这两个限制, 数组拥有了随机访问的特性, 但也有利有弊, 插入和删除操作变得低效.</p>
<p>数组插入操作平均时间复杂度O(n), 当数据无序时, 可将插入位置元素直接搬到末尾来优化执行速度.<br>数组删除操作平均时间复杂度O(n), 当不追求数据连续性时, 可先记录已删除数据, 当数据没有空间时, 再出发真正的删除, 类似jvm的标记清除垃圾回收算法.</p>
<h3 id="链表和数组的区别"><a href="#链表和数组的区别" class="headerlink" title="链表和数组的区别"></a>链表和数组的区别</h3><p>链表插入删除时间复杂度O(1), 数组根据下标随机访问时间复杂度O(1).</p>
<h3 id="选容器还是数组"><a href="#选容器还是数组" class="headerlink" title="选容器还是数组"></a>选容器还是数组</h3><p>关于编程语言中包装好的容器, 比如java中的ArrayList, 该如何选择<br>数组可存储基础数据类型, 且性能更好, 但容器更方便易用, 所以<br>业务开发中可使用容器, 省时省力; 底层开发时, 如需要性能优化到极致, 可使用数组.</p>
<h3 id="为什么数组下标从0开始"><a href="#为什么数组下标从0开始" class="headerlink" title="为什么数组下标从0开始"></a>为什么数组下标从0开始</h3><p>下标也是在内存上的偏移量, 寻址的时候可以直接首地址+偏移量*type_size, 如果下标从1开始, 则需要多做一次减法运算, 对于数组这种最基础的数据结构, 为了性能, 选择从0开始编号. (也可能不是, 无从求证)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>工具-破解pdf密码</title>
    <url>/2019/05/14/%E5%B7%A5%E5%85%B7-%E7%A0%B4%E8%A7%A3pdf%E5%AF%86%E7%A0%81/</url>
    <content><![CDATA[<p>今天偶得一份久仰的学习资料.pdf, 一打开却发现要输入密码, 试来试去密码都不对, 寻遍google找到了一个神器~</p>
<h2 id="pdfcrack"><a href="#pdfcrack" class="headerlink" title="pdfcrack"></a>pdfcrack</h2><p>官方网站 -&gt; <a href="http://pdfcrack.sourceforge.net/" target="_blank" rel="noopener">pdfcrack</a>, 目前版本0.17</p>
<h3 id="第一步-Download"><a href="#第一步-Download" class="headerlink" title="第一步 Download"></a>第一步 Download</h3><p>下载下来以后是一个压缩包, 解压以后一堆c语言文件<br><img src="http://www.wangdanpeng.com/img/20190514193611-1.png" alt="1"></p>
<h3 id="第二步-编译"><a href="#第二步-编译" class="headerlink" title="第二步 编译"></a>第二步 编译</h3><p>在解压后的文件夹里执行<strong>make</strong>, 成功后得出上图中红色的<strong>pdfcrack</strong>可执行文件</p>
<h3 id="第三步-暴力破解"><a href="#第三步-暴力破解" class="headerlink" title="第三步 暴力破解"></a>第三步 暴力破解</h3><p>执行pdfcrack 后跟pdf路径, 如图中的测试文件123.pdf, 几秒钟后得到密码<strong>168</strong><br><img src="http://www.wangdanpeng.com/img/20190514193611-2.png" alt="2"></p>
<p>最后, 想偷懒的可以直接下载我编译好的执行文件 -&gt; <a href="http://www.wangdanpeng.com/jars/pdfcrack">传送门</a></p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>pdf</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala-抓取项目代码中全部代码注释</title>
    <url>/2019/05/13/Scala-%E6%8A%93%E5%8F%96%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E4%B8%AD%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/</url>
    <content><![CDATA[<p>日前某站代码泄露, 大佬们贴出很多代码中有趣的注释, 于是突发奇想, 写了一个没有用的小程序…</p>
<p>(ps: 某站代码我没看, 你们可, 别瞎说…)</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"><span class="keyword">import</span> java.util.regex.<span class="type">Pattern</span></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">File</span>, <span class="type">PrintWriter</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Bi</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getFile</span></span>(file:<span class="type">File</span>): <span class="type">Array</span>[<span class="type">File</span>] =&#123;</span><br><span class="line">    <span class="keyword">val</span> files = file.listFiles()</span><br><span class="line">                    .filter(! _.isDirectory)</span><br><span class="line">                    <span class="comment">// 指定要读取什么文件</span></span><br><span class="line">                    .filter(t =&gt; t.toString.endsWith(<span class="string">".go"</span>))</span><br><span class="line">    files ++ file.listFiles()</span><br><span class="line">                  .filter(f =&gt; f.isDirectory</span><br><span class="line">                    <span class="comment">// 指定排除掉什么文件夹</span></span><br><span class="line">                    &amp;&amp; f.getName != <span class="string">"vendor"</span>)</span><br><span class="line">                  .flatMap(getFile)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">check</span></span>(s: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> pattern = <span class="string">"[\u4e00-\u9fa5]+"</span></span><br><span class="line">    <span class="keyword">val</span> p = <span class="type">Pattern</span>.compile(pattern)</span><br><span class="line">    <span class="keyword">val</span> result = p.matcher(s)</span><br><span class="line">    <span class="keyword">if</span> (result.find()) <span class="literal">true</span> <span class="keyword">else</span> <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> path = <span class="keyword">new</span> <span class="type">File</span>(<span class="string">"目标文件夹路径"</span>)</span><br><span class="line">    <span class="keyword">val</span> writer = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="keyword">new</span> <span class="type">File</span>(<span class="string">"输出文件路径"</span>))</span><br><span class="line"></span><br><span class="line">    getFile(path).foreach&#123; file =&gt;</span><br><span class="line">      <span class="keyword">var</span> flag = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> text=<span class="type">Source</span>.fromFile(file)</span><br><span class="line">      <span class="keyword">for</span>(line &lt;- text.getLines)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">if</span> (line.trim.startsWith(<span class="string">"//"</span>) &amp;&amp; check(line)) &#123;</span><br><span class="line">          flag = <span class="literal">true</span></span><br><span class="line">          writer.println(<span class="string">s"-----<span class="subst">$line</span>"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (flag) &#123;</span><br><span class="line">        <span class="comment">// 打印以上注释出自哪个文件</span></span><br><span class="line">        writer.println(file.getPath)</span><br><span class="line">      &#125;</span><br><span class="line">      text.close</span><br><span class="line">    &#125;</span><br><span class="line">    writer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>VS Code-常用插件</title>
    <url>/2019/05/11/VS-Code-%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>久闻vs code比sublime text要好用, 感觉sublime text已经够好用了, 一直懒得换, 今天下载vs code试用了一下, 感觉嗯~ 真香~</p>
<p>初次使用先安装了一些常用插件, 以后如有进阶插件再持续更新</p>
<h2 id="0-插件安装方法"><a href="#0-插件安装方法" class="headerlink" title="0. 插件安装方法"></a>0. 插件安装方法</h2><p>不得不说, vs code插件安装比sublime text要更优雅, 左侧工具栏直接提供了插件安装选项(最下面的方块块), 直接搜索插件名, 可以查看各个插件的使用说明, 安装次数等等信息, 顿时好感爆棚</p>
<h2 id="1-vim"><a href="#1-vim" class="headerlink" title="1. vim"></a>1. vim</h2><p>平时和服务器打交道多, 习惯vim操作一切, 编辑器当然也是必须vim模式走起, 直接搜<strong>vim</strong>, 目前版本1.8.0, 690w人次安装</p>
<h2 id="2-图标"><a href="#2-图标" class="headerlink" title="2. 图标"></a>2. 图标</h2><p>由于平时打开的文件夹和文件比较多, 习惯装一个图标插件, 能美化图标的显示, 这里选择的是<strong>vscode-icons</strong>, 版本8.6.0, 1500w人次安装</p>
<h2 id="3-json格式化工具"><a href="#3-json格式化工具" class="headerlink" title="3. json格式化工具"></a>3. json格式化工具</h2><p>平时处理json格式数据也比较多, 经常需要格式化, 每次打开格式化网站也很麻烦, 不如插件来的实在, 这里选择的<strong>JSON Tools</strong>, 版本1.0.2, 26w人次安装, 后续有更好用的再换</p>
<h2 id="4-Markdown工具"><a href="#4-Markdown工具" class="headerlink" title="4. Markdown工具"></a>4. Markdown工具</h2><p>vs code原本就支持写markdown的实时预览, 只要把文件保存成<strong>.md</strong>后缀, 在右上角就会有一个分屏带放大镜的图标, 点击就可以, 不过黑色主题下预览也是黑色, 有些格式看起来不舒服, 所以我选择<strong>Markdown Preview Enhanced</strong>, 版本0.3.13, 110w人次安装</p>
<p>同时, 想要规范自己写的md格式, 可以一起安装一个<strong>markdownlint</strong>, 根据他的数条规则发起检查, 格式不规范的地方就会划绿色波浪线, 助你写出完美md, 版本0.26.0, 437w人次安装</p>
<h2 id="5-颜色主题"><a href="#5-颜色主题" class="headerlink" title="5. 颜色主题"></a>5. 颜色主题</h2><p>直接<strong>cmd + shift + p</strong>在输入框输入<strong>color theme</strong>, 就有多种自带主题供你选择, 不过我又另外多安装了一个<strong>One Dark Pro</strong>主题, 可以搜索看一下适不适合你, 版本2.22.1, 1000w人次安装</p>
<h2 id="6-编程语言插件"><a href="#6-编程语言插件" class="headerlink" title="6. 编程语言插件"></a>6. 编程语言插件</h2><p>这个就不过多介绍, 对应安装自己常用的语言, 比如我的<strong>Scala</strong>和<strong>Python</strong></p>
<h2 id="7-最后的骚操作"><a href="#7-最后的骚操作" class="headerlink" title="7. 最后的骚操作"></a>7. 最后的骚操作</h2><p>最骚的来了, vs code居然有简体中文包…<br>直接搜索<strong>Chinese</strong>就可以, 版本1.33.2, 560w人次安装</p>
]]></content>
      <categories>
        <category>VS Code</category>
      </categories>
      <tags>
        <tag>VS Code</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-RDD简单介绍</title>
    <url>/2018/11/28/20181128141747/</url>
    <content><![CDATA[<p>结合Spark官网, 对Spark RDD的一些简单介绍和总结.</p>
<p>RDD是Spark提供的主要抽象, 全称弹性分布式数据集, 它是跨集群节点来分区的元素集合, 可以并行操作, 可以保留在内存, 还可以自动从节点故障中恢复.</p>
<h2 id="创建RDD"><a href="#创建RDD" class="headerlink" title="创建RDD"></a>创建RDD</h2><p>创建RDD有两种方法</p>
<p><strong>并行化现有集合</strong><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val data = Array(1, 2, 3, 4, 5)</span><br><span class="line">val rdd = sc.parallelize(data)</span><br><span class="line">val rdd2 = sc.parallelize(data, 10)</span><br></pre></td></tr></table></figure></p>
<p>并行集合的一个重要参数就是将数据集切分的分区数. Spark执行任务时, 为每一个分区产生一个task, 分区数也就是任务执行时的并行度, 所以可以通过第二个参数来手动设置分区数.</p>
<p><strong>引用外部存储系统中的数据集</strong><br>Spark可以从Hadoop支持的任何存储系统创建RDD, 包括本地文件系统, HDFS, HBase等等.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val rdd = sc.textFile(&quot;data.text&quot;)</span><br></pre></td></tr></table></figure></p>
<p>关于读取文件的注意事项</p>
<ul>
<li>如果使用的是本地文件系统路径, 要确保该文件已发送到所有worker节点上的相同路径下.</li>
<li>文件的URI支持使用通配符, 如textFile(“/my/directory/*.txt”)</li>
<li>该方法同样有第二个可选参数来控制分区数, 默认Spark为文件的每个块创建一个分区(HDFS中默认一块128MB), 你只能创建比现有块更多的分区, 不能更少.</li>
</ul>
<h2 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h2><p>RDD的操作分两种类型: transformation(转换, 从现有数据集创建新的数据集)和action(行动, 在数据集上运行计算后将值返回给driver端).<br>Spark中所有的转换都是懒惰的, 所以转换操作并不会触发Spark job的提交, 只有触发action时, 才会提交job运算结果.</p>
<p>常见的转换操作</p>
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>map</strong>(func)</td>
<td style="text-align:left">将RDD中每个元素一一转换成新元素返回新数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>filter</strong>(func)</td>
<td style="text-align:left">返回func为true的元素形成的新数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>flatMap</strong>(func)</td>
<td style="text-align:left">将RDD中的每个元素进行一对多转换形成新的数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>union</strong>(otherDataset)</td>
<td style="text-align:left">将两个集合中的数据进行合并, 返回两个集合的并集, 不去重</td>
</tr>
<tr>
<td style="text-align:left"><strong>join</strong>(otherDataset, [numPartitions])</td>
<td style="text-align:left">当调用类型(K, V)和(K, W)的数据集时, 返回(K, (V, W))对的数据集以及每个键的所有元素对</td>
</tr>
<tr>
<td style="text-align:left"><strong>groupByKey</strong>([numPartitions])</td>
<td style="text-align:left">在(K, V)对的数据集上调用, 返回(K, Iterable<v>)对的数据集;默认输出的并行度取决于父RDD的分区数, 也可以使用numPartitions参数指定</v></td>
</tr>
<tr>
<td style="text-align:left"><strong>reduceByKey</strong>(func, [numPartitions])</td>
<td style="text-align:left">当调用(K, V)对的数据集时, 返回(K, V)对数据集, 使用给定的reduce函数func聚合每个键的值, 同样可以通过numPartitions参数指定任务数量</td>
</tr>
<tr>
<td style="text-align:left"><strong>sortByKey</strong>([ascending], [numpartitions])</td>
<td style="text-align:left">返回按Key升序或降序的(K, V)对的数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>repartition</strong>(numPartitions)</td>
<td style="text-align:left">随机重新调整RDD中的数据以创建更平衡的分区</td>
</tr>
</tbody>
</table>
<p>常见行动操作</p>
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>reduce</strong>(func)</td>
<td style="text-align:left">使用func来聚合数据集的元素</td>
</tr>
<tr>
<td style="text-align:left"><strong>collect</strong>()</td>
<td style="text-align:left">在driver端将数据集所有元素作为数组返回, 注意当结果集很大时十分消耗内存</td>
</tr>
<tr>
<td style="text-align:left"><strong>count</strong>()</td>
<td style="text-align:left">返回数据集中的元素数</td>
</tr>
<tr>
<td style="text-align:left"><strong>first</strong>()</td>
<td style="text-align:left">返回数据集中的第一个元素</td>
</tr>
<tr>
<td style="text-align:left"><strong>take</strong>(n)</td>
<td style="text-align:left">返回数据集中的前n个元素的数组</td>
</tr>
<tr>
<td style="text-align:left"><strong>saveAsTextFile</strong>(path)</td>
<td style="text-align:left">将数据集的元素作为文本文件写入Hadoop支持的文件系统的指定目录中</td>
</tr>
<tr>
<td style="text-align:left"><strong>foreach</strong>(func)</td>
<td style="text-align:left">在每个元素上运行func</td>
</tr>
</tbody>
</table>
<h2 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h2><p>在Spark中, 单个任务在单个分区上运行, 为了组织执行单个reduce任务的所有数据, 就必须从所有分区中读取所有键的所有值, 然后将各个值组合在一起以计算每个键的结果, 这就是Shuffle.</p>
<p>一般触发shuffle的操作包括重新分区, 如repartition和coalesce; ByKey操作, 如groupByKey和reduceByKey;连接操作, 如join和cogroup.</p>
<p>shuffle操作消耗巨大, 因为它涉及到磁盘I/O, 数据序列化和网络I/O.为了组织shuffle的数据, Spark生成多组map任务以组织数据, 以及一组reduce任务来聚合数据.map任务的结果会保留在内存中, 直到内存放不下, Spark会将这些数据溢出到磁盘, 从而导致磁盘I/O的额外开销和垃圾回收的增加.<br>Shuffle还会在磁盘上生成大量中间文件, 从Spark1.3开始, 这些文件直到相关RDD不再使用才会被垃圾回收, 这样做是为了在重新计算时, 不需要重新创建shuffle文件.spark.local.dir可配置临时存储目录.</p>
<h2 id="RDD持久性"><a href="#RDD持久性" class="headerlink" title="RDD持久性"></a>RDD持久性</h2><p>Spark中最重要的功能之一就是跨操作在内存中持久化数据集.当你缓存RDD时, 每个节点都会将它计算的分区数据存储在内存中, 并在该数据集的其他操作中重用它们, 这使得后续操作执行更快.缓存是迭代算法和快速交互式使用的关键工具.</p>
<p>你可以使用persist()或cache()方法标记要缓存的RDD.第一次计算它时, 会将RDD保留在节点内存中.</p>
<p>此外, 每个持久化的RDD都可以使用不同的存储级别进行存储.例如, 存在内存里, 存在磁盘上, 序列化为Java对象等.persist()通过传递StorageLevel对象来设置级别, cache()方法默认实用StorageLevel.MEMORY_ONLY.<br>全部存储级别有</p>
<table>
<thead>
<tr>
<th style="text-align:left">存储级别</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">“MEMORY_ONLY”</td>
<td style="text-align:left">默认级别,将RDD存储为JVM中的反序列化Java对象, 如果内存不够将不会被缓存</td>
</tr>
<tr>
<td style="text-align:left">“MEMORY_AND_DISK”</td>
<td style="text-align:left">将RDD存储为JVM中的反序列化Java对象, 如果内存不够将溢出到磁盘</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_ONLY_SER(Java和Scala)</td>
<td style="text-align:left">将RDD存储为序列化Java对象, 这通常比反序列化对象更节省空间, 但是读取CPU密集程度更高</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_AND_DISK_SER(Java和Scala)</td>
<td style="text-align:left">与MEMORY_ONLY_SER类似, 但将不适合在内存的分区溢出到磁盘.</td>
</tr>
<tr>
<td style="text-align:left">DISK_ONLY</td>
<td style="text-align:left">仅将RDD存储在磁盘上</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_ONLY_2,MEMORY_AND_DISK_2等</td>
<td style="text-align:left">与以上级别相同, 但在集群的两个节点上复制</td>
</tr>
<tr>
<td style="text-align:left">OFF_HEAP(实验性)</td>
<td style="text-align:left">与MEMORY_ONLY_SER类似, 但将数据存储在堆外内存, 这需要启用堆外内存</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>RDD</tag>
        <tag>文档</tag>
      </tags>
  </entry>
  <entry>
    <title>算法题-海盗分赃</title>
    <url>/2018/11/27/20181127102854/</url>
    <content><![CDATA[<blockquote>
<p><strong>6个海盗要分赃300金币。规则是由资格最老的海盗提出各人分到的数量，然后全体投票。如方案得到至少半数同意票，则按该方案执行，否则提出方案的海盗被杀死，再由剩下人中资格最老的继续提出方案。海盗都很聪明，在能生存的前提下会追求获利最大化。问最后分赃结果是怎样的?</strong></p>
</blockquote>
<p>这道题详细的解题步骤一搜就有, 我只说一下我自己的理解.</p>
<h2 id="两个人"><a href="#两个人" class="headerlink" title="两个人?"></a>两个人?</h2><p>首先还是需要简化这道题, 假如只有两个人, 应该怎么分<br><img src="http://www.wangdanpeng.com/img/20181127102854-1.png" alt="two"><br>因为只要投票得到半数就可通过, 只有两个人时, 老大不管怎么分, 只要自己同意, 就可以通过, 所以他一定会分给自己300金, 一毛都不给老二.</p>
<h2 id="三个人"><a href="#三个人" class="headerlink" title="三个人?"></a>三个人?</h2><p>那么假如有三个人呢?, 想要投票通过, 就必须有两个人同意才行, 那么现在来分析一下这三个人里有谁是利益相关的<br>老大和老二 -&gt; 只要老大死了, 老二能得到全部的300金<br>老二和老三 -&gt; 老二可以承诺给老三多少钱一起搞死老大, 但是老大如果死了, 老二做主, 自己可能一毛也拿不到<br>老大和老三 -&gt; 老大和老三联手, 老三一定能拿到钱<br><img src="http://www.wangdanpeng.com/img/20181127102854-2.png" alt="three"><br>这种情况下, 老大即使给老三1金, 老三也是愿意支持老大的, 最后结果就是老大299金, 老二0, 老三1金</p>
<h2 id="六个人"><a href="#六个人" class="headerlink" title="六个人?"></a>六个人?</h2><p>从上面三个人可以得出结论, 相邻的两个人是死敌关系, 想要半数票通过, 一定不能收买相邻的人, 那么老大只需要收买老三和老五, 他们就一定会同意, 最后老大298, 老二0, 老三1金, 老四0, 老五1金, 老六0</p>
]]></content>
      <categories>
        <category>算法题</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Sublime Text3 更换主题及插件安装</title>
    <url>/2018/11/09/20181109210424/</url>
    <content><![CDATA[<p>毫无疑问, Sublime Text是Mac电脑上为数不多十分好用的文本编辑器之一, 日常使用的频率也是非常的高, 所以配置一个好看又好用的Sublime Text就十分的有必要.</p>
<h2 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h2><p>关于主题, 个人也是非常喜欢 <a href="https://github.com/ihodev/sublime-boxy" target="_blank" rel="noopener">sublime-boxy</a>, 安装步骤也非常简单</p>
<ol>
<li>在Sublime中按下<code>Cmd + shift + p</code>, 弹出一个输入框</li>
<li>在框中输入 <code>install package</code> 敲回车, 稍等一下会又弹出一个插件管理的输入框</li>
<li>在框中输入 <code>Boxy Theme</code>, 选择第一个安装, 稍等一会就安装完毕</li>
<li>安装完成以后可能会自动弹出要求你安装 <code>A File Icon</code>(比较好看的左侧文件图标), 同意安装就好, 如果没有自动安装就回到第三步手动安装一下</li>
<li>装好以后重启Sublime默认是一个浅色主题, 不喜欢可以自己改配置文件, 直接按下<code>Cmd + ,</code>弹出配置文件, 左侧为默认配置文件, 右侧为用户自定义配置文件, 想改什么就往右侧加, 可选主题参考<a href="https://github.com/ihodev/sublime-boxy/wiki/Get-It#activation" target="_blank" rel="noopener">官方说明</a>, 把相应配置加到配置文件再重启即可生效</li>
</ol>
<h2 id="Vim设置"><a href="#Vim设置" class="headerlink" title="Vim设置"></a>Vim设置</h2><p> 另外我个人喜欢使用vim模式, 感觉比较舒服, 顺带附上vim模式的开启方法, 非常简单如下</p>
<p> 同上在Sublime中按下<code>Cmd + ,</code>弹出配置文件, 在右侧有一个<code>ignored_packages</code>配置, 其中默认有<code>Vintage</code>, 把它删掉, 留下一个空的括号, 重启生效, 就可以使用vim了<br> 想要关闭的话同理再把<code>Vintage</code>加回去</p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title>SBT-修改资源库地址</title>
    <url>/2017/04/06/20170406210224/</url>
    <content><![CDATA[<p>做大数据开发, 用scala的都会用到sbt来打包依赖, 但是sbt默认配置里连接的国外地址, 根本就下不下来依赖包, 而且还有的地址是https的, 连接都被拒绝了, 所以我们就来修改sbt默认的配置.</p>
<p>首先, 我的系统是mac, 不管是用idea装的scala插件里带的sbt, 还是用Homebrew安装的sbt, 都会在用户目录下有个.sbt文件夹, 执行<code>ll -a</code>即可看到.</p>
<h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>进入.sbt文件夹, 创建一个名叫repositories的文件, 默认应该是没有的, 并加入以下内容, 来覆盖默认配置<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[repositories]</span><br><span class="line">  local</span><br><span class="line">  aliyun: http://maven.aliyun.com/nexus/content/groups/public/</span><br><span class="line">  maven-central: http://repo1.maven.org/maven2/</span><br><span class="line">  sbt-maven-releases: http://repo.scala-sbt.org/scalasbt/maven-releases/, bootOnly</span><br><span class="line">  sbt-maven-snapshots: http://repo.scala-sbt.org/scalasbt/maven-snapshots/, bootOnly</span><br><span class="line">  typesafe-ivy-releases: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line">  sbt-ivy-snapshots: http://repo.scala-sbt.org/scalasbt/ivy-snapshots/, [organization]/[module]/[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br></pre></td></tr></table></figure></p>
<p>可见其中加入了阿里云的maven地址, 之前用过开源中国的, 后来他们干不下去了, 这次阿里云接盘, 应该不会轻易的狗带.</p>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>理论上添加以上配置后即可覆盖原来的默认配置, 然而我的sbt好像死活就是不行, 所以我还有第二个比较hacker的方法, 既然默认配置覆盖不掉, 那我就把默认配置改了.</p>
<p>我的sbt是用Homebrew安装的, 默认安装位置在 <code>/usr/local/Cellar/sbt</code>, 此处有一个bin文件夹和一个conf文件夹, 我们要破坏的jar包就是bin下的sbt-launch.jar文件.<br>tar解压sbt-launch.jar文件可以得到以下文件结构:<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">total 72</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  5 12  2016 META-INF</span><br><span class="line">-rwxr-xr-x   1 wdp  staff    59B  8 17  2015 module.properties</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  5 12  2016 org</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  1  3 19:58 sbt</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.10.0</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.10.1</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.11.0</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.11.1</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.11.2</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   675B  5 12  2016 sbt.boot.properties0.11.3</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   959B  5 12  2016 sbt.boot.properties0.13.0</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   690B  5 12  2016 sbt.boot.properties0.7</span><br><span class="line">drwxr-xr-x  61 wdp  staff   2.0K  5 12  2016 scala</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  5 12  2016 xsbt</span><br><span class="line">drwxr-xr-x  24 wdp  staff   816B  5 12  2016 xsbti</span><br></pre></td></tr></table></figure></p>
<p>默认的配置文件就在sbt文件夹下的sbt.boot.properties文件, 对此文件内的内容进行替换, 如下:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[scala]</span><br><span class="line">  version: $&#123;sbt.scala.version-auto&#125;</span><br><span class="line"></span><br><span class="line">[app]</span><br><span class="line">  org: $&#123;sbt.organization-org.scala-sbt&#125;</span><br><span class="line">  name: sbt</span><br><span class="line">  version: $&#123;sbt.version-read(sbt.version)[1.0.0-M4]&#125;</span><br><span class="line">  class: $&#123;sbt.main.class-sbt.xMain&#125;</span><br><span class="line">  components: xsbti,extra</span><br><span class="line">  cross-versioned: $&#123;sbt.cross.versioned-false&#125;</span><br><span class="line">  resources: $&#123;sbt.extraClasspath-&#125;</span><br><span class="line"></span><br><span class="line">[repositories]</span><br><span class="line">  local</span><br><span class="line">  aliyun: http://maven.aliyun.com/nexus/content/groups/public</span><br><span class="line">  maven-central: http://repo1.maven.org/maven2/</span><br><span class="line">  sbt-maven-releases: http://repo.scala-sbt.org/scalasbt/maven-releases/, bootOnly</span><br><span class="line">  sbt-maven-snapshots: http://repo.scala-sbt.org/scalasbt/maven-snapshots/, bootOnly</span><br><span class="line">  typesafe-ivy-releases: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line">  sbt-ivy-snapshots: http://repo.scala-sbt.org/scalasbt/ivy-snapshots/, [organization]/[module]/[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line"></span><br><span class="line">[boot]</span><br><span class="line">  directory: $&#123;sbt.boot.directory-$&#123;sbt.global.base-$&#123;user.home&#125;/.sbt&#125;/boot/&#125;</span><br><span class="line"></span><br><span class="line">[ivy]</span><br><span class="line">  ivy-home: $&#123;sbt.ivy.home-$&#123;user.home&#125;/.ivy2/&#125;</span><br><span class="line">  checksums: $&#123;sbt.checksums-sha1,md5&#125;</span><br><span class="line">  override-build-repos: $&#123;sbt.override.build.repos-false&#125;</span><br><span class="line">  repository-config: $&#123;sbt.repository.config-$&#123;sbt.global.base-$&#123;user.home&#125;/.sbt&#125;/repositories&#125;</span><br></pre></td></tr></table></figure></p>
<p>修改完成, 再执行<code>jar -cfM ./sbt-launch.jar .</code>打成jar包, 把bin目录下的原始jar包替换掉即可, 这次保证妥妥的.</p>
<p>附上我改好的jar包下载地址, 送给懒得自己动手的人们, 传送门 -&gt; <a href="http://www.wangdanpeng.com/jars/sbt-launch.jar">sbt-launch.jar</a></p>
]]></content>
      <categories>
        <category>SBT</category>
      </categories>
      <tags>
        <tag>SBT</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-接入畅言评论</title>
    <url>/2017/03/29/20170329230400/</url>
    <content><![CDATA[<p>众所周知, 多说评论要关闭了, 不管它处于什么原因和什么考虑, 总之我们要考虑换下家了, 看来看去感觉搜狐畅言的评论模块看着还算舒服, 决定接入畅言的评论系统. 可以见下方, 我正在使用的就是.</p>
<h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>第一步肯定是注册畅言没啥说的, 官网地址-&gt; <a href="http://changyan.kuaizhan.com/" target="_blank" rel="noopener">畅言</a>, 需要注意的是畅言需要绑定你的域名, 还要审核备案信息, 否则只能试用15天的, 审核备案很快, 我当时用的一个多小时就过了.</p>
<h3 id="替换模板文件"><a href="#替换模板文件" class="headerlink" title="替换模板文件"></a>替换模板文件</h3><p>在畅言的后台有如下安装畅言的代码:<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--PC版--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"SOHUCS"</span> <span class="attr">sid</span>=<span class="string">"请将此处替换为配置SourceID的语句"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://changyan.sohu.com/upload/changyan.js"</span> &gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="built_in">window</span>.changyan.api.config(&#123;</span></span><br><span class="line"><span class="actionscript">appid: <span class="string">'你的appid'</span>,</span></span><br><span class="line"><span class="actionscript">conf: <span class="string">'你的appkey'</span></span></span><br><span class="line"><span class="undefined">&#125;);</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>此处appid和appkey可以在你的畅言后台总览中得到, 这里的sid比较重要, 多说两句.</p>
<p>sid是用来区分各个文章的, 如果不设置, 就会所有文章共享全部的评论, 比较讨厌. 所以sid其实就是设置一个文章的唯一标示, 有的人使用文章title, 但是有可能你想修改title时, 以前的评论就会丢失, 所以安全起见, 我选用了另一个文章参数做sid, 哪个参数呢, “page.permalink”.<br>关于文章有哪些参数可以见 -&gt; <a href="https://hexo.io/zh-cn/docs/front-matter.html" target="_blank" rel="noopener">官方文档</a>, 简单的可以把permalink参数设置成写文章时的年月日时分秒, 一般来说是不会重复的, 你也不会在同一秒写两篇文章. 好, 那么开始来配置我的模板.</p>
<p>我用的hexo的next模板, 评论模板文件在项目目录下的<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">themes/next/layout/_partials/comments.swig</span><br></pre></td></tr></table></figure></p>
<p>把comments.swig文件备个份, 万一以后还用呢, 然后新建一个同名文件, 写入如下内容:<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% if page.comments %&#125;</span><br><span class="line"> <span class="tag">&lt;<span class="name">section</span> <span class="attr">id</span>=<span class="string">"comments"</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--PC版--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"SOHUCS"</span> <span class="attr">sid</span>=<span class="string">"&#123;&#123; page.permalink &#125;&#125;"</span> &gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://changyan.sohu.com/upload/changyan.js"</span> &gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="built_in">window</span>.changyan.api.config(&#123;</span></span><br><span class="line"><span class="actionscript">appid: <span class="string">'你的appid'</span>,</span></span><br><span class="line"><span class="actionscript">conf: <span class="string">'你的appkey'</span></span></span><br><span class="line"><span class="undefined">&#125;);</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure></p>
<p>if条件判断是否设置comments参数, 想开评论的文章就添加comments参数并设为true, 不想开的页面就设为false.<br>为把permalink参数输出到这里, hexo的各个模板的标签使用方式好像不太一样, 具体的已自己使用的模板为准, 我就见过是用&lt;%= page.permalink %&gt;方式输出的.</p>
<h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>到此就已经配置完成了, 你可以推代码进行验证了.</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-记不住的命令整理</title>
    <url>/2017/03/18/20170318053142/</url>
    <content><![CDATA[<p>git作为代码管理工具基本上每天都在使用中, 然而有时候总有一些难记的命令让我每次用都需要去百度, 干脆把它们整理出来, 以后再遇到直接看自己博客就好啦, hah</p>
<p>1.忽略已经add进暂存区的文件<br>有时候一不留神会把一些并不想提交的东西一起add到暂存区, 一下两下想不起来该用什么命令, 网上搜的有的还不对, 下面给出正解:<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把文件从暂存区移除</span></span><br><span class="line">git reset HEAD xxx</span><br></pre></td></tr></table></figure></p>
<p>2.放弃一些本地的修改<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 放弃一个文件修改</span></span><br><span class="line">git checkout xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 放弃当前文件夹所有文件的修改</span></span><br><span class="line">git checkout .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会退到某个版本</span></span><br><span class="line">git reset --hard xxx版本号</span><br></pre></td></tr></table></figure></p>
<p>3.切换分支保存代码<br>有时写了一部分代码但是突然需要切换分支或者其他操作, 需要把当前修改暂存一下, 那就下面用到的命令<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 暂存信息</span></span><br><span class="line">git stash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取存入的信息</span></span><br><span class="line">git stash pop</span><br></pre></td></tr></table></figure></p>
<p>4.commit message写错<br>如果尚未push到远端, 只需要<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git commit --amend</span><br></pre></td></tr></table></figure></p>
<p>5.删除远端分支<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git push --delete 分支名</span><br></pre></td></tr></table></figure></p>
<p>6.重命名本地分支<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git branch -m 旧分支名 新分支名</span><br></pre></td></tr></table></figure></p>
<p>最近收藏的就这几条命令了, 以后再有记不住的随时更新, 另附上我初学git的启蒙文档 <a href="http://git.oschina.net/progit/" target="_blank" rel="noopener">Pro Git(中文版)</a>.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-抓取音乐网站下载链接</title>
    <url>/2017/03/18/20170318014719/</url>
    <content><![CDATA[<p>当年SongTaste网站还没关闭, 在上面找到过很多我喜欢的音乐, 当时已经被多米收购, 下载音乐超级麻烦, 后来看到网上有说扒下载链接的, 我也自己试了一下用Java开发了一个Windows小窗口, 输入音乐网址就会返回下载链接.</p>
<p>参考链接<a href="http://www.cnblogs.com/weixliu/p/3985551.html" target="_blank" rel="noopener">SongTaste网站真实URL获取</a></p>
<p>研究发现直接获取下载地址的一些关键参数在页面里都有, 只需要正则提取出来即可. 然后拼出一个请求, 发送之后就会返回下载链接, 还是很简单的, 虽然现在SongTaste已经闭站了, 就当是分享了一个小爬虫, github传送门 -&gt; <a href="https://github.com/WangDanpeng/SongTaste" target="_blank" rel="noopener">SongTaste</a></p>
<p>简简单单的一个小程序, 然而貌似是我第一次真正把编程应用到实际生活中, 当时还用这个小工具下载了不少歌, 还是很有趣的(￣▽￣)”</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-断点调试</title>
    <url>/2017/03/12/20170312193459/</url>
    <content><![CDATA[<p>我是用idea + spark-shell断点调试spark源码的, 可以一行代码一行代码的追执行过程, 很是方便, 学习Spark源码必备.</p>
<h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p>首先肯定是要把Spark的源码准备好, 并且导入到idea里, 从哪下Spark源码和怎么导入到idea里我就不详细解释了.<br>另外启动Spark需要Hadoop和Hive的支持, 首先要把这两个服务搭好启动起来, 关于这部分本篇文章暂且不讲, 请自行百度.</p>
<h4 id="设置idea的debug配置"><a href="#设置idea的debug配置" class="headerlink" title="设置idea的debug配置"></a>设置idea的debug配置</h4><p><img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95%281%29.png" alt="此处输入图片的描述"><br>点击Edit Configuration去添加调试.<br><img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%94%B5%E8%B0%83%E8%AF%95%282%29.png" alt="此处输入图片的描述"><br>然后点击左上角的加号, 在列表中选择Remote选项<br><img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95%283%29.png" alt="此处输入图片的描述"><br>创建出来的这些东西什么设置都不用动, 可以把Name改一个自己好记的, 比如我的local Spark, 划红线的部分就是一会要使用的.</p>
<h4 id="启动spark-shell"><a href="#启动spark-shell" class="headerlink" title="启动spark-shell"></a>启动spark-shell</h4><p>进入Spark的bin目录下执行以下命令<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./spark-shell -h</span><br></pre></td></tr></table></figure></p>
<p>可以看到spark-shell启动时可以指定个各种参数, 其中我们要用到的有以下两个:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--master MASTER_URL         spark://host:port, mesos://host:port, yarn, or local.</span><br><span class="line"></span><br><span class="line">--driver-java-options       Extra Java options to pass to the driver.</span><br></pre></td></tr></table></figure>
<p>master参数, 指定启动方式, 我们起本地模式, 所以用local.<br>driver-java-options参数, driver端的一些java参数, 就是刚才划红线的部分.</p>
<p>那么启动命令拼起来就是这样的:<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./spark-shell --master local --driver-java-options -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005</span><br></pre></td></tr></table></figure></p>
<p>敲回车启动以后可以看到这么一句话<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Listening for transport dt_socket at address: 5005</span><br></pre></td></tr></table></figure></p>
<p>表示已经开始监听5005端口, 接下来去启动idea.</p>
<h4 id="启动idea"><a href="#启动idea" class="headerlink" title="启动idea"></a>启动idea</h4><p><img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95%284%29.png" alt="此处输入图片的描述"><br>再回到图一的位置, 选择上刚才创建的local Spark, 然后点击旁边的debug按钮, 就正式进入debug模式了, 现在就可以随心所欲的打断点调试Spark了.</p>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-从wordCount到job调度过程</title>
    <url>/2017/03/05/20170305231525/</url>
    <content><![CDATA[<p>以wordCount为例, 研究学习spark(版本2.1.0)的整个job调度过程,整理总结如下:</p>
<h3 id="WordCount"><a href="#WordCount" class="headerlink" title="WordCount"></a>WordCount</h3><p>首先, 一个简单的wordCount程序<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rawFile = sc.textFile(<span class="string">"README.md"</span>)</span><br><span class="line"><span class="keyword">val</span> words = rawFile.flatMap(w =&gt; w.split(<span class="string">" "</span>))</span><br><span class="line"><span class="keyword">val</span> wordNum = words.map(w =&gt; (w, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> wordCount = wordNum.reduceByKey(_ + _)</span><br><span class="line">wordCount.collect</span><br></pre></td></tr></table></figure></p>
<p>我是用idea + spark-shell断点调试spark源码的, 可以一行代码一行代码的追执行过程,  调试方法可见我的另一篇文章 <a href="http://www.wangdanpeng.com/2017/03/12/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95/">Spark-断点调试</a>.</p>
<h4 id="第一行"><a href="#第一行" class="headerlink" title="第一行"></a>第一行</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rawFile = sc.textFile(<span class="string">"README.md"</span>)</span><br></pre></td></tr></table></figure>
<p>调用的SparkContext的textFile方法, 看源码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">textFile</span></span>(</span><br><span class="line">    path: <span class="type">String</span>,</span><br><span class="line">    minPartitions: <span class="type">Int</span> = defaultMinPartitions): <span class="type">RDD</span>[<span class="type">String</span>] = withScope &#123;</span><br><span class="line">  assertNotStopped()</span><br><span class="line">  hadoopFile(path, classOf[<span class="type">TextInputFormat</span>], classOf[<span class="type">LongWritable</span>], classOf[<span class="type">Text</span>],</span><br><span class="line">    minPartitions).map(pair =&gt; pair._2.toString).setName(path)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看出此处先是hadoopFile方法读取hdfs上的一个README.md文件, 并生成了一个HadoopRDD, 随后又调用map方法, 生成了一个MapPartitionsRDD.</p>
<p>执行结果:<br><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">scala&gt; val rawFile = sc.textFile(<span class="string">"README.md"</span>)</span><br><span class="line">rawFile: org.apache.spark.rdd.RDD[String] = README.md MapPartitionsRDD[3] at textFile at &lt;console&gt;:24</span><br></pre></td></tr></table></figure></p>
<h4 id="第二行"><a href="#第二行" class="headerlink" title="第二行"></a>第二行</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> words = rawFile.flatMap(w =&gt; w.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure>
<p>此处调用了MapPartitionsRDD继承自RDD类的flatMap方法, 源码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.flatMap(cleanF))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>flatMap方法可以将RDD中的每一个元素进行一对多转换, 所以此处使用flatMap方法将读入的内容按空格分割, 每个单词成为一个元素, 转变完仍为MapPartitionsRDD.</p>
<h4 id="第三行"><a href="#第三行" class="headerlink" title="第三行"></a>第三行</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> wordNum = words.map(w =&gt; (w, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>此处调用了MapPartitionsRDD继承自RDD类的map方法, 见源码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.map(cleanF))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>map方法将RDD中类型为T的元素一对一映射为类型为U的元素, 所以此处我们要统计的单个单词被转换为了(w, 1)形式的键值对, 进过此步转换仍为MapPartitionsRDD.</p>
<h4 id="第四行"><a href="#第四行" class="headerlink" title="第四行"></a>第四行</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> wordCount = wordNum.reduceByKey(_ + _)</span><br></pre></td></tr></table></figure>
<p>这次调用的reduceByKey方法不在RDD类里, 而在PairRDDFunctions类, 这里发生了一个隐式转换, 将MapPartitionsRDD转换成了PairRDDFunctions, 方法源码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)] = self.withScope &#123;</span><br><span class="line">  reduceByKey(defaultPartitioner(self), func)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>reduceByKey按key把相同单词加到一起, 得出每个单词出现的频率.</p>
<h4 id="第五行"><a href="#第五行" class="headerlink" title="第五行"></a>第五行</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">wordCount.collect</span><br></pre></td></tr></table></figure>
<p>到第四行为止, 所有任务并没有执行, 只到第五步, 调用RDD的collect方法, 会调用sc.runJob, 源码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> results = sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.toArray)</span><br><span class="line">  <span class="type">Array</span>.concat(results: _*)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>从这里开始生成Job并提交到Spark集群中运行, 至此才引出我们研究的重点, Job的整个调度过程.</p>
<p>此处调用的是SparkContext的runJob方法, 在SparkContext中重载了很多runJob方法, 通过一连串的runJob间调用, 设置了RDD, function, 分区数, 匿名函数转换等, 最后到了最重要的DAGScheduler.runJob.</p>
<h3 id="Jobd调度流程"><a href="#Jobd调度流程" class="headerlink" title="Jobd调度流程"></a>Jobd调度流程</h3><h4 id="1-DAGScheduler提交Job"><a href="#1-DAGScheduler提交Job" class="headerlink" title="1. DAGScheduler提交Job"></a>1. DAGScheduler提交Job</h4><p>DAGScheduler最重要的任务之一就是分析依赖关系划分Stage, 而发起job调度入口有两个, 一个是submitJob:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  <span class="comment">// Check to make sure we are not launching a task on a partition that does not exist.</span></span><br><span class="line">  <span class="keyword">val</span> maxPartitions = rdd.partitions.length</span><br><span class="line">  partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; <span class="number">0</span>).foreach &#123; p =&gt;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</span><br><span class="line">      <span class="string">"Attempting to access a non-existent partition: "</span> + p + <span class="string">". "</span> +</span><br><span class="line">        <span class="string">"Total number of partitions: "</span> + maxPartitions)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</span><br><span class="line">  <span class="keyword">if</span> (partitions.size == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Return immediately if the job is running 0 tasks</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  assert(partitions.size &gt; <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</span><br><span class="line">  <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">  eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">    <span class="type">SerializationUtils</span>.clone(properties)))</span><br><span class="line">  waiter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>它返回一个JobWaiter对象, 可以用在异步调用中.<br>另一个入口就是runJob:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</span><br><span class="line">  <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br><span class="line">  <span class="comment">// Note: Do not call Await.ready(future) because that calls `scala.concurrent.blocking`,</span></span><br><span class="line">  <span class="comment">// which causes concurrent SQL executions to fail if a fork-join pool is used. Note that</span></span><br><span class="line">  <span class="comment">// due to idiosyncrasies in Scala, `awaitPermission` is not actually used anywhere so it's</span></span><br><span class="line">  <span class="comment">// safe to pass in null here. For more detail, see SPARK-13747.</span></span><br><span class="line">  <span class="keyword">val</span> awaitPermission = <span class="literal">null</span>.asInstanceOf[scala.concurrent.<span class="type">CanAwait</span>]</span><br><span class="line">  waiter.completionFuture.ready(<span class="type">Duration</span>.<span class="type">Inf</span>)(awaitPermission)</span><br><span class="line">  waiter.completionFuture.value.get <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Success</span>(_) =&gt;</span><br><span class="line">      logInfo(<span class="string">"Job %d finished: %s, took %f s"</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Failure</span>(exception) =&gt;</span><br><span class="line">      logInfo(<span class="string">"Job %d failed: %s, took %f s"</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">      <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.</span></span><br><span class="line">      <span class="keyword">val</span> callerStackTrace = <span class="type">Thread</span>.currentThread().getStackTrace.tail</span><br><span class="line">      exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)</span><br><span class="line">      <span class="keyword">throw</span> exception</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>runJob在内部调用submitJob, 阻塞等待直到Job完成或失败.<br>从submitJob方法里可以看到, 在此处向eventProcessLoop里发送了一个JobSubmitted的消息.<br>那么eventProcessLoop是什么呢<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="keyword">val</span> eventProcessLoop = <span class="keyword">new</span> <span class="type">DAGSchedulerEventProcessLoop</span>(<span class="keyword">this</span>)</span><br></pre></td></tr></table></figure></p>
<p>这就是DAGScheduler自己维护的一个消息队列, 处理各种类型的消息, 当收到JobSubmitted消息时会调用handleJobSubmitted方法, 在这个方法里开始重要的第二步, 分析继承关系拆分Stages.</p>
<h4 id="2-拆分提交Stages"><a href="#2-拆分提交Stages" class="headerlink" title="2. 拆分提交Stages"></a>2. 拆分提交Stages</h4><p>在handleJobSubmitted方法中, 首先会根据这个RDD的信息计算出这个Job的所有Stages.<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">      finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">      callSite: <span class="type">CallSite</span>,</span><br><span class="line">      listener: <span class="type">JobListener</span>,</span><br><span class="line">      properties: <span class="type">Properties</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></span><br><span class="line">      <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></span><br><span class="line">      finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">        logWarning(<span class="string">"Creating new stage failed due to exception - job: "</span> + jobId, e)</span><br><span class="line">        listener.jobFailed(e)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</span><br><span class="line">    clearCacheLocs()</span><br><span class="line">    logInfo(<span class="string">"Got job %s (%s) with %d output partitions"</span>.format(</span><br><span class="line">      job.jobId, callSite.shortForm, partitions.length))</span><br><span class="line">    logInfo(<span class="string">"Final stage: "</span> + finalStage + <span class="string">" ("</span> + finalStage.name + <span class="string">")"</span>)</span><br><span class="line">    logInfo(<span class="string">"Parents of final stage: "</span> + finalStage.parents)</span><br><span class="line">    logInfo(<span class="string">"Missing parents: "</span> + getMissingParentStages(finalStage))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</span><br><span class="line">    jobIdToActiveJob(jobId) = job</span><br><span class="line">    activeJobs += job</span><br><span class="line">    finalStage.setActiveJob(job)</span><br><span class="line">    <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</span><br><span class="line">    <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</span><br><span class="line">    listenerBus.post(</span><br><span class="line">      <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</span><br><span class="line">    submitStage(finalStage)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到createResultStage方法, 生成了一个ResultStage, 代码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Create a ResultStage associated with the provided jobId.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createResultStage</span></span>(</span><br><span class="line">      rdd: <span class="type">RDD</span>[_],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">      jobId: <span class="type">Int</span>,</span><br><span class="line">      callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> parents = getOrCreateParentStages(rdd, jobId)</span><br><span class="line">    <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">    <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parents, jobId, callSite)</span><br><span class="line">    stageIdToStage(id) = stage</span><br><span class="line">    updateJobIdStageIdMaps(jobId, stage)</span><br><span class="line">    stage</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>其中getOrCreateParentStages方法根据依赖关系拆分了Stage, 返回了一个List[Stage]又传入了ResultStage中, 拆分Stage部分的代码我就不贴出来了, 感兴趣可以自行阅读.<br>handleJobSubmitted方法中得到finalStage后, 进行了一系列操作, 构建ActiveJob, 启动Job, 最后提交了Stage, 准备开始生成真正下发执行的Task任务.</p>
<p>那么看submitStage方法:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Submits stage, but first recursively submits any missing parents. */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">    <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">      logDebug(<span class="string">"submitStage("</span> + stage + <span class="string">")"</span>)</span><br><span class="line">      <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">        <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">        logDebug(<span class="string">"missing: "</span> + missing)</span><br><span class="line">        <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">          logInfo(<span class="string">"Submitting "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">"), which has no missing parents"</span>)</span><br><span class="line">          submitMissingTasks(stage, jobId.get)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">            submitStage(parent)</span><br><span class="line">          &#125;</span><br><span class="line">          waitingStages += stage</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      abortStage(stage, <span class="string">"No active job for stage "</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>递归提交Stage, 有parent的先提交parent, 没有parent的才开始生成Task.</p>
<h4 id="3-创建提交Task"><a href="#3-创建提交Task" class="headerlink" title="3. 创建提交Task"></a>3. 创建提交Task</h4><p>创建提交Task调用的是submitStage方法里的submitMissingTasks方法, 这个方法代码比较长, 我就不全部贴出来了.<br>Stage分ShuffleMapStage和ResultStage, Task也分为ShuffleMapTask和ResultTask两种, 方法里导出都是模式匹配分别处理这两种Stage, 关键生成Task的代码如下:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">      stage <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">          partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(id)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</span><br><span class="line">              taskBinary, part, locs, stage.latestInfo.taskMetrics, properties, <span class="type">Option</span>(jobId),</span><br><span class="line">              <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">          partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(p)</span><br><span class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</span><br><span class="line">              taskBinary, part, locs, id, properties, stage.latestInfo.taskMetrics,</span><br><span class="line">              <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId)</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">        abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>"</span>, <span class="type">Some</span>(e))</span><br><span class="line">        runningStages -= stage</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>生成Task之后通过TaskScheduler把Task提交.<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">        tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))</span><br></pre></td></tr></table></figure></p>
<p>submitTasks方法的实现在TaskSchedulerimpl.scala, 这里首先创建了一个TaskSetManager来辅助调度, 然后调用了SchedulerBackend的reviveOffers方法去申请资源.</p>
<h4 id="4-分配executors"><a href="#4-分配executors" class="headerlink" title="4. 分配executors"></a>4. 分配executors</h4><p>这里reviveOffers方法的实现跳到了CoarseGrainedSchedulerBackend.scala文件:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>() &#123;</span><br><span class="line">    driverEndpoint.send(<span class="type">ReviveOffers</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>此处发送了一条ReviveOffers消息, 被自身接收到然后继续处理:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ReviveOffers</span> =&gt;</span><br><span class="line">        makeOffers()</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>makeOffers方法很重要, 这里调用了resourceOffers方法去获取当前可用的资源信息, 而当前正在执行的多个TaskSet会根据这些资源信息将当前可执行的Task和这个Task要运行在哪个executor上包装到一个TaskDescription中返回回来, 再调用launchTasks正式把Task推倒executor端去执行.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>(executorId: <span class="type">String</span>) &#123;</span><br><span class="line">      <span class="comment">// Filter out executors under killing</span></span><br><span class="line">      <span class="keyword">if</span> (executorIsAlive(executorId)) &#123;</span><br><span class="line">        <span class="keyword">val</span> executorData = executorDataMap(executorId)</span><br><span class="line">        <span class="keyword">val</span> workOffers = <span class="type">IndexedSeq</span>(</span><br><span class="line">          <span class="keyword">new</span> <span class="type">WorkerOffer</span>(executorId, executorData.executorHost, executorData.freeCores))</span><br><span class="line">        launchTasks(scheduler.resourceOffers(workOffers))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Launch tasks returned by a set of resource offers</span></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchTasks</span></span>(tasks: <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]]) &#123;</span><br><span class="line">      <span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;</span><br><span class="line">        <span class="keyword">val</span> serializedTask = ser.serialize(task)</span><br><span class="line">        <span class="keyword">if</span> (serializedTask.limit &gt;= maxRpcMessageSize) &#123;</span><br><span class="line">          scheduler.taskIdToTaskSetManager.get(task.taskId).foreach &#123; taskSetMgr =&gt;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">var</span> msg = <span class="string">"Serialized task %s:%d was %d bytes, which exceeds max allowed: "</span> +</span><br><span class="line">                <span class="string">"spark.rpc.message.maxSize (%d bytes). Consider increasing "</span> +</span><br><span class="line">                <span class="string">"spark.rpc.message.maxSize or using broadcast variables for large values."</span></span><br><span class="line">              msg = msg.format(task.taskId, task.index, serializedTask.limit, maxRpcMessageSize)</span><br><span class="line">              taskSetMgr.abort(msg)</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; logError(<span class="string">"Exception in error callback"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> executorData = executorDataMap(task.executorId)</span><br><span class="line">          executorData.freeCores -= scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line"></span><br><span class="line">          logDebug(<span class="string">s"Launching task <span class="subst">$&#123;task.taskId&#125;</span> on executor id: <span class="subst">$&#123;task.executorId&#125;</span> hostname: "</span> +</span><br><span class="line">            <span class="string">s"<span class="subst">$&#123;executorData.executorHost&#125;</span>."</span>)</span><br><span class="line"></span><br><span class="line">          executorData.executorEndpoint.send(<span class="type">LaunchTask</span>(<span class="keyword">new</span> <span class="type">SerializableBuffer</span>(serializedTask)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>在launchTasks方法中才把executors资源真的分配给Task并把分配掉的资源扣除, 然后把Task序列化后发送往executor端.</p>
<h4 id="5-executor执行Task"><a href="#5-executor执行Task" class="headerlink" title="5. executor执行Task"></a>5. executor执行Task</h4><p>接下来程序就运行到了CoarseGrainedExecutorBackend.scala的receive方法, 这里接收到driver端发来的LaunchTask消息开始触发执行, 关键代码:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">LaunchTask</span>(data) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;</span><br><span class="line">        exitExecutor(<span class="number">1</span>, <span class="string">"Received LaunchTask command but executor was null"</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> taskDesc = ser.deserialize[<span class="type">TaskDescription</span>](data.value)</span><br><span class="line">        logInfo(<span class="string">"Got assigned task "</span> + taskDesc.taskId)</span><br><span class="line">        executor.launchTask(<span class="keyword">this</span>, taskId = taskDesc.taskId, attemptNumber = taskDesc.attemptNumber,</span><br><span class="line">          taskDesc.name, taskDesc.serializedTask)</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>这里首先把Task反序列化, 然后交给Executor.scala的launchTask方法:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">launchTask</span></span>(</span><br><span class="line">      context: <span class="type">ExecutorBackend</span>,</span><br><span class="line">      taskId: <span class="type">Long</span>,</span><br><span class="line">      attemptNumber: <span class="type">Int</span>,</span><br><span class="line">      taskName: <span class="type">String</span>,</span><br><span class="line">      serializedTask: <span class="type">ByteBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tr = <span class="keyword">new</span> <span class="type">TaskRunner</span>(context, taskId = taskId, attemptNumber = attemptNumber, taskName,</span><br><span class="line">      serializedTask)</span><br><span class="line">    runningTasks.put(taskId, tr)</span><br><span class="line">    threadPool.execute(tr)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>这里new了一个TaskRunner, 继续执行TaskRunner的run方法, run方法代码很长就不贴了, 这里就是具体执行Task的实现, 可以自己去看源码.</p>
<h4 id="6-执行结果返回"><a href="#6-执行结果返回" class="headerlink" title="6. 执行结果返回"></a>6. 执行结果返回</h4><p>当run方法执行完以后, 把结果数据序列化返回, 如果数据过大, 就把数据写磁盘返回数据的位置, 通过statusUpdate方法回传给<br>CoarseGrainedExecutorBackend.scala, executorBackend再发送了一条StatusUpdate消息把结果返回给了CoarseGrainedSchedulerBackend.scala<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">StatusUpdate</span>(executorId, taskId, state, data) =&gt;</span><br><span class="line">        scheduler.statusUpdate(taskId, state, data.value)</span><br><span class="line">        <span class="keyword">if</span> (<span class="type">TaskState</span>.isFinished(state)) &#123;</span><br><span class="line">          executorDataMap.get(executorId) <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="type">Some</span>(executorInfo) =&gt;</span><br><span class="line">              executorInfo.freeCores += scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line">              makeOffers(executorId)</span><br><span class="line">            <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">              <span class="comment">// Ignoring the update since we don't know about the executor.</span></span><br><span class="line">              logWarning(<span class="string">s"Ignored task status update (<span class="subst">$taskId</span> state <span class="subst">$state</span>) "</span> +</span><br><span class="line">                <span class="string">s"from unknown executor with ID <span class="subst">$executorId</span>"</span>)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>driver端收到消息后, 先把结果传给了TaskScheduler, 然后释放了executor资源.<br>接下来到TaskScheduler之后调用比较绕, 首先把Task清理掉, 然后使用TaskResultGetter来处理结果:<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="type">TaskState</span>.isFinished(state)) &#123;</span><br><span class="line">              cleanupTaskState(tid)</span><br><span class="line">              taskSet.removeRunningTask(tid)</span><br><span class="line">              <span class="keyword">if</span> (state == <span class="type">TaskState</span>.<span class="type">FINISHED</span>) &#123;</span><br><span class="line">                taskResultGetter.enqueueSuccessfulTask(taskSet, tid, serializedData)</span><br><span class="line">              &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="type">Set</span>(<span class="type">TaskState</span>.<span class="type">FAILED</span>, <span class="type">TaskState</span>.<span class="type">KILLED</span>, <span class="type">TaskState</span>.<span class="type">LOST</span>).contains(state)) &#123;</span><br><span class="line">                taskResultGetter.enqueueFailedTask(taskSet, tid, state, serializedData)</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure></p>
<p>在TaskResultGetter中判断结果数据的存放位置, 如果在内存中就直接取结果, 如果在磁盘, 就根据blockid信息去对应机器上拉取数据, 然后放到driver的内存, 最后调用handleSuccessfulTask方法把结果返回给TaskScheduler.<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scheduler.handleSuccessfulTask(taskSetManager, tid, result)</span><br></pre></td></tr></table></figure></p>
<p>接下来用到了之前辅助调度创建的TaskSetManager<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleSuccessfulTask</span></span>(</span><br><span class="line">      taskSetManager: <span class="type">TaskSetManager</span>,</span><br><span class="line">      tid: <span class="type">Long</span>,</span><br><span class="line">      taskResult: <span class="type">DirectTaskResult</span>[_]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    taskSetManager.handleSuccessfulTask(tid, taskResult)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>TaskScheduler调用TaskSetManager, TaskSetManager再调用DAGScheduler, 并将结果数据返回给了DAGScheduler.<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">sched.dagScheduler.taskEnded(tasks(index), <span class="type">Success</span>, result.value(), result.accumUpdates, info)</span><br></pre></td></tr></table></figure></p>
<p>taskEnded方法向DAGScheduler维护的队列里发送了一个CompletionEvent消息, 来触发DAGScheduler的handleTaskCompletion方法来数据数据.<br>handleTaskCompletion方法里会判断这是一个ShuffleMapTask还是一个ResultTask, 如果是ShuffleMapTask则继续提交下一个Stage, 如果是ResultTask, 则会通过以下代码把结果交给JobWaiter.<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">job.listener.taskSucceeded(rt.outputId, event.result)</span><br></pre></td></tr></table></figure></p>
<p>JobWaiter最后做一些处理, 然后把结果一路返回给调用SparkContext.runJob的地方, 至此整个Job调度就完成了.</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>下面用几张图做一个总结:</p>
<p>Job的调度执行流程</p>
<p><img src="http://www.wangdanpeng.com/img/Job%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="整个Job的执行流程"></p>
<p>Job提交执行期间的函数调用<br><img src="http://www.wangdanpeng.com/img/Job%E6%89%A7%E8%A1%8C%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B.png" alt="此处输入图片的描述"></p>
<p>ps:<br>最近学习Spark的Job调度过程, 看了一遍源码后发现扭头就忘, 所以就整理了下来. Spark代码实在量太大, Job执行的有些细节实现也没自己研究, 只是把大体流程梳理了下来, 如有错误欢迎指正.</p>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>WordCount</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis-逻辑连接未关闭</title>
    <url>/2017/02/26/20170226153828/</url>
    <content><![CDATA[<p>首先环境我用的Struts2 + Sprig + Mybatis</p>
<p>最近重构了Mqsql连接池, 改用了阿里的druid. 因为druid带有WebUi, 我发现我的项目只打开数据库连接却不关闭, 那肯定是sqlSessionfactory出问题了.</p>
<p>因为之前的代码不是我写的, 尝试着关闭sqlSession后还是不管用, 干脆直接使用sqlSessionTemplate.<br>先配置Spring<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">"white-space:pre"</span>&gt;</span>	<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="comment">&lt;!--创建sqlSessionFactory --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"sqlSessionFactory"</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.SqlSessionFactoryBean"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"configLocation"</span> <span class="attr">value</span>=<span class="string">"classpath:SqlMapConfig.xml"</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- sqlSessionTemplate配置（支持批量） --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"sqlSessionTemplate"</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.SqlSessionTemplate"</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- 参数1: sqlSessionFactory|参数2：ExecutorType --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"0"</span> <span class="attr">ref</span>=<span class="string">"sqlSessionFactory"</span> /&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- 开启BATCH批量更新会丢失更新的返回值，导致返回-2147482646 --&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- &lt;constructor-arg index="1" value="BATCH" /&gt; --&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>项目中伪码如下:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//注入spring中配置的SqlSessionTemplate对象，单例</span></span><br><span class="line"><span class="meta">@Resource</span>(name=<span class="string">"sqlSessionTemplate"</span>)</span><br><span class="line"><span class="keyword">public</span> SqlSessionTemplate sqlSessionTemplate;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saveTestTrans</span><span class="params">()</span></span>&#123;</span><br><span class="line">     <span class="keyword">this</span>.sqlSessionTemplate.selectList(<span class="string">"testdomain.selectAnySql"</span>, <span class="string">"select * from my_blog where id='1'"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里的SqlSessionTemplate不仅是单例的，而且不需要手工新建和关闭SqlSession.</p>
<p>为什么mybatis-spring.jar中的SqlSessionTemplate可以被多个dao复用，而且不会造成数据连接泄露呢，并且还可以自动新建和释放数据库连接？官方解答是因为SqlSessionTemplate是线程安全的，也就是确保每个线程使用的sqlSession的唯一并不互相冲突。</p>
<p>首先看了一下mybatis-spring的源码，发现SqlSessionTemplate是通过代理拦截和SqlSessionHolder实现的sqlsession线程安全和自动新建和释放连接的。看构造函数函数中构建代理类，该代理类实现SqlSession接口，定义了方法拦截器，如果调用代理类实例中实现SqlSession接口定义的方法，该调用则被导向SqlSessionInterceptor的invoke方法，这个方法中自动进行了SqlSession的自动请求和释放（如果不被spring托管则自己新建和释放sqlsession，如果被spring管理则使用SqlSessionHolder进行request和relase操作）</p>
<p>以下网址针对SqlSessionTemplate的线程安全特性进行了详细的探究：<a href="http://www.cnblogs.com/daxin/p/3544188.html" target="_blank" rel="noopener">http://www.cnblogs.com/daxin/p/3544188.html</a></p>
<p>另外此处还有一个坑:</p>
<p>上面Spring配置里有个参数被我注释了<br><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"1"</span> <span class="attr">value</span>=<span class="string">"BATCH"</span> /&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>它的意思就是defaultExecutorType=BATCH, defaultExecutorType有三个值:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">simple -&gt; 普通返回</span><br><span class="line">reuse  -&gt; 重复返回</span><br><span class="line">batch  -&gt; 批量更新</span><br></pre></td></tr></table></figure></p>
<p>一旦选择了batch属性, 那么所有更新插入操作返回的那个int类型的数值就会使-2147482646, 也就是返回值丢失了.</p>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql-输入Emoji表情</title>
    <url>/2017/02/26/20170226152115/</url>
    <content><![CDATA[<p>之前开发app遇到过一个问题, 用户发表评论里如果带有Emoji表情就会失败,查看日志数据库会报如下错误:</p>
<pre><code>java.sql.SQLException: Incorrect string value: &apos;\xF0\x9F\x98\x97\xF0\x9F...&apos; for column &apos;CONTENT&apos; at row 1
</code></pre><p>网上搜了一圈说是字符集的问题, 详细解释在这里 -&gt; <a href="http://blog.csdn.net/qdkfriend/article/details/7576524" target="_blank" rel="noopener">Emoji表情符号兼容方案</a><br>既然说了utf8的字符集不行, 那就去改字符集, 统统改成utf8mb4.</p>
<p> 1.先去修改表字段字符集为utf8mb4:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">MODIFY</span> <span class="string">`字段名`</span> <span class="built_in">TEXT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci<span class="string">';</span></span><br></pre></td></tr></table></figure></p>
<p> 2.再去修改表字符集utf8mb4:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">CHARSET</span>=utf8mb4;</span><br></pre></td></tr></table></figure></p>
<p>3.再去配饰文件my.ini修改数据库的字符集utf8mb4:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">init-connect=&apos;SET NAMES utf8mb4&apos;</span><br><span class="line">character-set-server=utf8mb4</span><br></pre></td></tr></table></figure></p>
<p>三步完成后重启mysql服务, 再查看数据库字符集</p>
<pre><code>mysql&gt; show variables like &apos;%char%&apos;;
</code></pre><p>+————————–+———————————-+<br>| Variable_name            | Value                            |<br>+————————–+———————————-+<br>| character_set_client     | utf8mb4                          |<br>| character_set_connection | utf8mb4                          |<br>| character_set_database   | utf8mb4                          |<br>| character_set_filesystem | binary                           |<br>| character_set_results    | utf8mb4                          |<br>| character_set_server     | utf8mb4                          |<br>| character_set_system     | utf8                             |<br>| character_sets_dir       | /usr/local/mysql/share/charsets/ |<br>+————————–+———————————-+</p>
<p>再发表情测试通过!到此一切搞定收工.</p>
<p>(ps:如果以上方法下来并没有成功的话, 一定是你的mysql配置没放好, 那么请参考下面这篇文章, 绝对妥妥的 -&gt; <a href="http://www.cnblogs.com/HondaHsu/p/3640180.html" target="_blank" rel="noopener">如何修改MySQL字符集</a>)</p>
<p>下面是一些相关命令:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--修改数据库字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">DATABASE</span> <span class="string">`数据库名`</span> <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--把表默认的字符集和所有字符列改为新的字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span> <span class="keyword">CONVERT</span> <span class="keyword">TO</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--只修改表的默认字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span> <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--修改字段的字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span> <span class="keyword">CHANGE</span> <span class="string">`字段名`</span> <span class="string">`字段名`</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--查看数据库编码</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="string">`数据库名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--查看表编码</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--查看字段编码</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">FULL</span> <span class="keyword">COLUMNS</span> <span class="keyword">FROM</span> <span class="string">`表名`</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Emoji</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题-url结尾带不带斜杠的访问速度</title>
    <url>/2017/02/26/20170226142341/</url>
    <content><![CDATA[<p>之前有一次面试遇到一个问题(拿我的博客举例):</p>
<blockquote>
<p><a href="http://www.wangdanpeng.com/about和www.wangdanpeng.com/about/哪种访问方式速度更快">www.wangdanpeng.com/about和www.wangdanpeng.com/about/哪种访问方式速度更快</a>?</p>
</blockquote>
<p>之前也没考虑过这个, 遇到这个题还真是一脸懵逼,事后就在CSDN发了篇帖子, 没想到还被上了推荐,真是受宠若惊.<a href="http://bbs.csdn.net/topics/391942437" target="_blank" rel="noopener">一个高深莫测的面试题</a></p>
<p>在上面访问的url中:<br>当请求第一个不带斜杠的url时, 服务器会优先查找根目录下有没有叫about的文件, 没有文件再把about当做目录处理, 再去加载about目录下的默认首页;<br>但是当请求第二个带有斜杠的url则直接把about当做目录处理, 理论上会比第一种快那么一点点.</p>
<p>拿百度来说, 不管请求<a href="http://www.baidu.com还是www.baidu.com/从控制台看到的request" target="_blank" rel="noopener">www.baidu.com还是www.baidu.com/从控制台看到的request</a> url都是<a href="https://www.baidu.com/" target="_blank" rel="noopener">https://www.baidu.com/</a>, 所以在自己做开发的时候尽量都在url结尾带上斜杠,这也算是一种SEO优化.</p>
]]></content>
      <categories>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>MyEclipse-新装MyEclipse后的一系列设置汇总</title>
    <url>/2017/02/19/20170319224848/</url>
    <content><![CDATA[<p>首先第一步肯定是破解无疑，我没钱去买正版的。。。</p>
<p>按我习惯的顺序来，导入一项目，方便参考着设置。</p>
<h3 id="1-收起包名"><a href="#1-收起包名" class="headerlink" title="1. 收起包名"></a>1. 收起包名</h3><p>默认情况下是这个样子一长串<br><img src="http://img.blog.csdn.net/20160212203014158?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="此处输入图片的描述"></p>
<p>  点击此处三角，然后package presentation—&gt;hierarchical，就会就会变成如下图的效果</p>
<p><img src="http://img.blog.csdn.net/20160212202939129?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="此处输入图片的描述"></p>
<h3 id="2-显示行号"><a href="#2-显示行号" class="headerlink" title="2. 显示行号"></a>2. 显示行号</h3><p>  直接打开一个文件，在文件最最侧栏右键，勾选上show line numbers</p>
<h3 id="3-更改字体大小"><a href="#3-更改字体大小" class="headerlink" title="3. 更改字体大小"></a>3. 更改字体大小</h3><p>Window –&gt; Preferences –&gt; General –&gt; Appearance –&gt; Colors and Fonts –&gt; Text Font，双击进行修改</p>
<h3 id="4-更改文件编码（推荐全部改为utf-8）"><a href="#4-更改文件编码（推荐全部改为utf-8）" class="headerlink" title="4. 更改文件编码（推荐全部改为utf-8）"></a>4. 更改文件编码（推荐全部改为utf-8）</h3><ul>
<li>windows-&gt;Preferences-&gt;general-&gt;Workspace，右侧窗口Text file encoding，选择Other，改变为UTF-8，以后新建立工程其属性对话框中的Text file encoding即为UTF-8。</li>
<li>windows—-&gt;Preferences—&gt;General—&gt;Content Types，右侧Context Types窗口，点开Text树中每一颗子项，并在中输入”UTF-8”，点“update ”更新。</li>
<li>window—&gt;preference—&gt;MyEclipse—&gt;Files and Editors，将每个子项的”Encoding”改为”ISO 10645/Unicode（UTF-8）”，点Apply。</li>
</ul>
<p>经过这样的设置，一切编码都已经统一了</p>
<h3 id="5-设置配色方案"><a href="#5-设置配色方案" class="headerlink" title="5. 设置配色方案"></a>5. 设置配色方案</h3><p>个人认为编辑器白色背景太刺眼了，习惯换成黑色背景<br>配色方案可以从这里下载<a href="http://eclipsecolorthemes.org/" target="_blank" rel="noopener">http://eclipsecolorthemes.org/</a> ，下载epf格式用来导入<br>File-&gt;Import-&gt;General-&gt;preference,然后选中你下载的epf文件，点击finish</p>
<hr>
<p>到此为止设置就先告一段落, 如有其它用到的配置再进行补充.</p>
]]></content>
      <categories>
        <category>MyEclipse</category>
      </categories>
      <tags>
        <tag>MyEclipse</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-通过配置向 Quartz定时任务 注入service</title>
    <url>/2017/02/19/20170219215026/</url>
    <content><![CDATA[<p>写了一个定时任务, 但是调用service会报空, 原因是service注入不进去, 解决办法如下:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">name</span>=<span class="string">"quartzScheduler"</span> <span class="attr">class</span>=<span class="string">"org.springframework.scheduling.quartz.SchedulerFactoryBean"</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span> /&gt;</span>    </span><br><span class="line">            </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"schedulerContextAsMap"</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">map</span>&gt;</span>    </span><br><span class="line">                <span class="comment">&lt;!-- spring 管理的service需要放到这里，才能够注入成功 --&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>schedulerContextAsMap<span class="tag">&lt;/<span class="name">description</span>&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"webSiteService"</span> <span class="attr">value-ref</span>=<span class="string">"webSiteService"</span>/&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span> = <span class="string">"mappingService"</span> <span class="attr">value-ref</span>=<span class="string">"mappingService"</span>/&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"detailService"</span> <span class="attr">value-ref</span> = <span class="string">"detailService"</span>&gt;</span><span class="tag">&lt;/<span class="name">entry</span>&gt;</span>   </span><br><span class="line">            <span class="tag">&lt;/<span class="name">map</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"applicationContextSchedulerContextKey"</span> <span class="attr">value</span>=<span class="string">"applicationContextKey"</span> /&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"configLocation"</span> <span class="attr">value</span>=<span class="string">"classpath:quartz.properties"</span> /&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span>    </span><br><span class="line">        </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"jobDetail"</span> <span class="attr">class</span>=<span class="string">"org.springframework.scheduling.quartz.JobDetailBean"</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jobClass"</span> <span class="attr">value</span> = <span class="string">"com.fangjia.dc.quartz.MyQuartzJob"</span>/&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jobDataAsMap"</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">map</span>&gt;</span>    </span><br><span class="line">                <span class="comment">&lt;!-- 非spring管理的service放到这里，就可以注入进去 --&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>jobDataAsMap<span class="tag">&lt;/<span class="name">description</span>&gt;</span>    </span><br><span class="line">                <span class="comment">&lt;!-- key 属性值，value 对应的bean --&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"uploader"</span> <span class="attr">value-ref</span>=<span class="string">"uploader"</span> /&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;/<span class="name">map</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>// —————–割割割———–下面这部分我没用到——</p>
<p>定时任务的动态管理, 没有配置的Spring文件中<br>采用页面传值, 实现quartz定时任务的CRUD</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">schedule</span><span class="params">(String name, CronExpression cronExpression,String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">           </span><br><span class="line">        <span class="comment">//添加Job 给scheduler,允许 replace  </span></span><br><span class="line">           </span><br><span class="line">        jobDetail.setRequestsRecovery(<span class="keyword">true</span>);   </span><br><span class="line">        <span class="comment">//孤立线程 不再保存在DB中  </span></span><br><span class="line">        jobDetail.setDurability(<span class="keyword">false</span>);   </span><br><span class="line">        jobDetail.setName(name);   </span><br><span class="line">        logger.info(<span class="string">" is  durable:"</span> + jobDetail.isDurable());   </span><br><span class="line">        <span class="comment">//设置replace为true，相同名字的job存在，则替换  </span></span><br><span class="line">        scheduler.addJob(jobDetail, <span class="keyword">true</span>);   </span><br><span class="line">           </span><br><span class="line">        CronTrigger cronTrigger = <span class="keyword">new</span> CronTrigger(name, group, jobDetail.getName(), Scheduler.DEFAULT_GROUP);  </span><br><span class="line">        cronTrigger.setCronExpression(cronExpression);   </span><br><span class="line">        scheduler.scheduleJob(cronTrigger);   </span><br><span class="line">        scheduler.rescheduleJob(cronTrigger.getName(), cronTrigger.getGroup(), cronTrigger);  </span><br><span class="line">    &#125;   </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pauseTrigger</span><span class="params">(String triggerName, String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">        logger.info(<span class="string">"pause triggerName:"</span> + triggerName);   </span><br><span class="line">        scheduler.pauseTrigger(triggerName, group);   </span><br><span class="line">    &#125;   </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resumeTrigger</span><span class="params">(String triggerName, String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">        logger.info(<span class="string">"resume trigger:"</span> + triggerName + <span class="string">" group:"</span> + group);   </span><br><span class="line">        scheduler.resumeTrigger(triggerName, group);   </span><br><span class="line">    &#125;   </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">removeTrigdger</span><span class="params">(String triggerName, String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">        scheduler.pauseTrigger(triggerName, group);   </span><br><span class="line">        <span class="keyword">return</span> scheduler.unscheduleJob(triggerName, group);   </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>quartz.properties设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.quartz.scheduler.instanceName = DefaultQuartzScheduler     </span><br><span class="line">org.quartz.scheduler.rmi.export = false    </span><br><span class="line">org.quartz.scheduler.rmi.proxy = false    </span><br><span class="line">org.quartz.scheduler.wrapJobExecutionInUserTransaction = false    </span><br><span class="line">    </span><br><span class="line">org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool     </span><br><span class="line">org.quartz.threadPool.threadCount = 10    </span><br><span class="line">org.quartz.threadPool.threadPriority = 5    </span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true   </span><br><span class="line">    </span><br><span class="line">org.quartz.jobStore.misfireThreshold = 60000    </span><br><span class="line">    </span><br><span class="line">#org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore     </span><br><span class="line">    </span><br><span class="line">org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX     </span><br><span class="line">org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate    </span><br><span class="line">org.quartz.jobStore.tablePrefix = QRTZ_       </span><br><span class="line">org.quartz.jobStore.isClustered = false       </span><br><span class="line">org.quartz.jobStore.maxMisfiresToHandleAtATime=1      </span><br><span class="line">#org.quartz.jobStore.txIsolationLevelReadCommitted = true</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title>MyEclipse-设置JAVA选中高亮显示</title>
    <url>/2017/02/18/20170218201209/</url>
    <content><![CDATA[<ol>
<li>打开高亮显示功能<br>选择Windows-&gt;Preferences-&gt;Java-&gt; Editor-&gt; Mark Occurrences ，勾选选项。这时，当你单击一个元素的时候，代码中所有该元素存在的地方都会被高亮显示。 </li>
<li>设置高亮的颜色<br>Window/preferences/general/Editors/Text Editors/Annotations/Occurences</li>
</ol>
]]></content>
      <categories>
        <category>MyEclipse</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MyEclipse</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-基于HttpClient的java后台访问URL</title>
    <url>/2017/02/18/20170218200349/</url>
    <content><![CDATA[<p>写支付相关东西遇到需要在后台访问url，搜了搜找到一篇不错的代码，收藏下来以留后用。</p>
<p>httpUtils.java中有两个公共的静态方法，一个是URLPost，另一个是URLGet，一目了然，前者是提供POST方式提交数据的，后者是提供GET方式提交数据的。其中所需要传送的数据以Map的方式传入，剩下的工作就交给我这个HttpUtils吧！当然如果Http服务器端对所提交的数据的编码有要求的话，也没问题，你可以传入UTF-8或者GBK，当然大家还可自行增加。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.net.URLEncoder;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.HttpClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.HttpException;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.HttpStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.MultiThreadedHttpConnectionManager;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.methods.GetMethod;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.methods.PostMethod;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.Log;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * HTTP工具类</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> lixiangyang</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Log log = LogFactory.getLog(HttpUtils.class);</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 定义编码格式 UTF-8</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String URL_PARAM_DECODECHARSET_UTF8 = <span class="string">"UTF-8"</span>;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 定义编码格式 GBK</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String URL_PARAM_DECODECHARSET_GBK = <span class="string">"GBK"</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String URL_PARAM_CONNECT_FLAG = <span class="string">"&amp;"</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String EMPTY = <span class="string">""</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> MultiThreadedHttpConnectionManager connectionManager = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> connectionTimeOut = <span class="number">25000</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> socketTimeOut = <span class="number">25000</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> maxConnectionPerHost = <span class="number">20</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> maxTotalConnections = <span class="number">20</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> HttpClient client;</span><br><span class="line">	<span class="keyword">static</span>&#123;</span><br><span class="line">		connectionManager = <span class="keyword">new</span> MultiThreadedHttpConnectionManager();</span><br><span class="line">		connectionManager.getParams().setConnectionTimeout(connectionTimeOut);</span><br><span class="line">		connectionManager.getParams().setSoTimeout(socketTimeOut);</span><br><span class="line">		connectionManager.getParams().setDefaultMaxConnectionsPerHost(maxConnectionPerHost);</span><br><span class="line">		connectionManager.getParams().setMaxTotalConnections(maxTotalConnections);</span><br><span class="line">		client = <span class="keyword">new</span> HttpClient(connectionManager);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * POST方式提交数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> url</span></span><br><span class="line"><span class="comment">	 * 			待请求的URL</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> params</span></span><br><span class="line"><span class="comment">	 * 			要提交的数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> enc</span></span><br><span class="line"><span class="comment">	 * 			编码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 * 			响应结果</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">	 * 			IO异常</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">URLPost</span><span class="params">(String url, Map&lt;String, String&gt; params, String enc)</span></span>&#123;</span><br><span class="line">		String response = EMPTY;		</span><br><span class="line">		PostMethod postMethod = <span class="keyword">null</span>;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			postMethod = <span class="keyword">new</span> PostMethod(url);</span><br><span class="line">			postMethod.setRequestHeader(<span class="string">"Content-Type"</span>, <span class="string">"application/x-www-form-urlencoded;charset="</span> + enc);</span><br><span class="line">			<span class="comment">//将表单的值放入postMethod中</span></span><br><span class="line">			Set&lt;String&gt; keySet = params.keySet();</span><br><span class="line">			<span class="keyword">for</span>(String key : keySet)&#123;</span><br><span class="line">				String value = params.get(key);</span><br><span class="line">				postMethod.addParameter(key, value);</span><br><span class="line">			&#125;			</span><br><span class="line">			<span class="comment">//执行postMethod</span></span><br><span class="line">			<span class="keyword">int</span> statusCode = client.executeMethod(postMethod);</span><br><span class="line">			<span class="keyword">if</span>(statusCode == HttpStatus.SC_OK) &#123;</span><br><span class="line">				response = postMethod.getResponseBodyAsString();</span><br><span class="line">			&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				log.error(<span class="string">"响应状态码 = "</span> + postMethod.getStatusCode());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">catch</span>(HttpException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生致命的异常，可能是协议不对或者返回的内容有问题"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">catch</span>(IOException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生网络异常"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">			<span class="keyword">if</span>(postMethod != <span class="keyword">null</span>)&#123;</span><br><span class="line">				postMethod.releaseConnection();</span><br><span class="line">				postMethod = <span class="keyword">null</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> response;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * GET方式提交数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> url</span></span><br><span class="line"><span class="comment">	 * 			待请求的URL</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> params</span></span><br><span class="line"><span class="comment">	 * 			要提交的数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> enc</span></span><br><span class="line"><span class="comment">	 * 			编码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 * 			响应结果</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">	 * 			IO异常</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">URLGet</span><span class="params">(String url, Map&lt;String, String&gt; params, String enc)</span></span>&#123;</span><br><span class="line">		String response = EMPTY;</span><br><span class="line">		GetMethod getMethod = <span class="keyword">null</span>;		</span><br><span class="line">		StringBuffer strtTotalURL = <span class="keyword">new</span> StringBuffer(EMPTY);</span><br><span class="line">		</span><br><span class="line">	    <span class="keyword">if</span>(strtTotalURL.indexOf(<span class="string">"?"</span>) == -<span class="number">1</span>) &#123;</span><br><span class="line">	      strtTotalURL.append(url).append(<span class="string">"?"</span>).append(getUrl(params, enc));</span><br><span class="line">	    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	    	strtTotalURL.append(url).append(<span class="string">"&amp;"</span>).append(getUrl(params, enc));</span><br><span class="line">	    &#125;</span><br><span class="line">	    log.debug(<span class="string">"GET请求URL = \n"</span> + strtTotalURL.toString());</span><br><span class="line">	    </span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			getMethod = <span class="keyword">new</span> GetMethod(strtTotalURL.toString());</span><br><span class="line">			getMethod.setRequestHeader(<span class="string">"Content-Type"</span>, <span class="string">"application/x-www-form-urlencoded;charset="</span> + enc);</span><br><span class="line">			<span class="comment">//执行getMethod</span></span><br><span class="line">			<span class="keyword">int</span> statusCode = client.executeMethod(getMethod);</span><br><span class="line">			<span class="keyword">if</span>(statusCode == HttpStatus.SC_OK) &#123;</span><br><span class="line">				response = getMethod.getResponseBodyAsString();</span><br><span class="line">			&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				log.debug(<span class="string">"响应状态码 = "</span> + getMethod.getStatusCode());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">catch</span>(HttpException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生致命的异常，可能是协议不对或者返回的内容有问题"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">catch</span>(IOException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生网络异常"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">			<span class="keyword">if</span>(getMethod != <span class="keyword">null</span>)&#123;</span><br><span class="line">				getMethod.releaseConnection();</span><br><span class="line">				getMethod = <span class="keyword">null</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> response;</span><br><span class="line">	&#125;	</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 据Map生成URL字符串</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> map</span></span><br><span class="line"><span class="comment">	 * 			Map</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> valueEnc</span></span><br><span class="line"><span class="comment">	 * 			URL编码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 * 			URL</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">static</span> String <span class="title">getUrl</span><span class="params">(Map&lt;String, String&gt; map, String valueEnc)</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (<span class="keyword">null</span> == map || map.keySet().size() == <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> (EMPTY);</span><br><span class="line">		&#125;</span><br><span class="line">		StringBuffer url = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">		Set&lt;String&gt; keys = map.keySet();</span><br><span class="line">		<span class="keyword">for</span> (Iterator&lt;String&gt; it = keys.iterator(); it.hasNext();) &#123;</span><br><span class="line">			String key = it.next();</span><br><span class="line">			<span class="keyword">if</span> (map.containsKey(key)) &#123;</span><br><span class="line">				String val = map.get(key);</span><br><span class="line">				String str = val != <span class="keyword">null</span> ? val : EMPTY;</span><br><span class="line">				<span class="keyword">try</span> &#123;</span><br><span class="line">					str = URLEncoder.encode(str, valueEnc);</span><br><span class="line">				&#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">				&#125;</span><br><span class="line">				url.append(key).append(<span class="string">"="</span>).append(str).append(URL_PARAM_CONNECT_FLAG);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		String strURL = EMPTY;</span><br><span class="line">		strURL = url.toString();</span><br><span class="line">		<span class="keyword">if</span> (URL_PARAM_CONNECT_FLAG.equals(EMPTY + strURL.charAt(strURL.length() - <span class="number">1</span>))) &#123;</span><br><span class="line">			strURL = strURL.substring(<span class="number">0</span>, strURL.length() - <span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> (strURL);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-json对象转java对象</title>
    <url>/2017/02/18/20170218195321/</url>
    <content><![CDATA[<p>项目里需要把json对象转换成java对象，还挺费劲的搜了搜，于是自己记下来，以后方便使用。</p>
<p>第一种方法，使用 JSON-lib 。</p>
<p>第二种方法，使用 JACKSON。</p>
<p>前两种方法，对相对简单的Pojo 对象来说，还是比较容易的。但是相对于嵌套多层的数据来说，复杂度就直接上去了。</p>
<p>第三种方法，使用GOOGLE 的Gson 来解决了。写过安卓的都知道，这东西，是Google出来的，最大的好处就是，基本不依赖其他的包。用起来自然很爽，取值方式非常灵活。对复杂的JSON 取值，基本统统搞定。</p>
<p>在Gson 中分为两种概念。一个就是 JsonObject 和 JsonArray。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mycompany.gsondata;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.JsonArray;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.JsonObject;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.JsonParser;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hello world!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String jsonData = <span class="string">"&#123;\"questionnaireID\": \"QNTest\",\"answerResults\":[&#123;\"questionID\":\"QSTest01\",\"anserContent\":\"cfb7f441-9086-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest01\",\"anserContent\":\"cfb7f441-9086-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest03\",\"anserContent\":\"6b3a9cce-9087-11e3-8cf8-000c2945c442,a086331d-9087-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest01\",\"anserContent\":\"cfb7f441-9086-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest05\",\"anserContent\":\"test测试文字填空\"&#125;,&#123;\"questionID\":\"QSTest06\",\"anserContent\":\"3\"&#125;,&#123;\"questionID\":\"QSTest07\",\"anserContent\":\"2.2\"&#125;]&#125;"</span>;</span><br><span class="line">        JsonObject root = <span class="keyword">new</span> JsonParser().parse(jsonData).getAsJsonObject();</span><br><span class="line">        System.out.println(root.get(<span class="string">"questionnaireID"</span>).toString());<span class="comment">//直接取的根节点值</span></span><br><span class="line"></span><br><span class="line">        JsonArray AnswerList = root.getAsJsonArray(<span class="string">"answerResults"</span>);<span class="comment">//取数组</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; AnswerList.size(); i++) &#123;</span><br><span class="line">            System.out.println(AnswerList.get(i).getAsJsonObject().get(<span class="string">"questionID"</span>).toString());</span><br><span class="line">            System.out.println(AnswerList.get(i).getAsJsonObject().get(<span class="string">"anserContent"</span>).toString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis-关于Mapped Statements collection does not contain value for错误</title>
    <url>/2017/02/18/20170218194929/</url>
    <content><![CDATA[<p>使用Mybatis时不时会遇到一下这种报错:</p>
<pre><code>Mapped Statements collection does not contain value for XXX
</code></pre><p>错误原因有以下几种:</p>
<ul>
<li>mapper.xml中没有加入namespace</li>
<li>mapper.xml中的方法和接口mapper的方法不对应</li>
<li>mapper.xml没有加入到mybatis-config.xml中(即总的配置文件)，例外：配置了mapper文件的包路径的除外</li>
<li>mapper.xml文件名和所写的mapper名称不相同</li>
</ul>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>ERROR</tag>
      </tags>
  </entry>
  <entry>
    <title>微信开发, 经纬度转地址问题</title>
    <url>/2017/02/18/20170218155323/</url>
    <content><![CDATA[<blockquote>
<p>之前搞微信二次开发遇见过一个超级大坑, 根据微信提供的接口, 获取到的经纬度, 不知道是什么坐标系的(ps: 各个地图使用的坐标系不一, 自行百度), 我把得到的经纬度放到百度.腾讯.高德地图里, 得到的位置都有很大的偏差, 后来绞尽脑汁, 发帖加群各种求助, 无意间发现一篇文章, 特此分享一下, 以防以后有人遇到同样的问题不用像我一样彷徨.</p>
</blockquote>
<p>这是原文 <a href="http://www.weixin66.net/newsshow.php?cid=4&amp;id=7" target="_blank" rel="noopener">微信如何根据经纬度坐标查询具体地理位置</a> </p>
<p>微信获取到的经纬度是GPS坐标, 知道这个一切就好办了, 下一步只要要一个GPS坐标转换的接口就可以了.</p>
<p> 我一开始用的上面链接里的接口, 然而用的好好的有一天突然服务挂了, 最后发现他的接口403了. </p>
<p> 然后我就找到了下面这个不错的网站, 看他们的合作伙伴还有CSDN, 应该还算靠谱, 从我发现这个网站距今已经快三年了, 它还在, 所以…</p>
<p>废话不多说, 上链接 <a href="http://www.zdoz.net/index.html" target="_blank" rel="noopener">各种地图接口</a></p>
]]></content>
      <categories>
        <category>微信</category>
      </categories>
      <tags>
        <tag>地图</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-Hello World</title>
    <url>/2017/02/18/20170218153653/</url>
    <content><![CDATA[<p>好久没有维护我的网站, 也懒得买服务器, 直接在github上用hexo搭了这么一个博客, 还是很方便的, 教程如下:</p>
<p><a href="http://www.wuxubj.cn/2016/08/Hexo-nexT-build-personal-blog/" target="_blank" rel="noopener">Hexo+NexT主题搭建个人博客</a></p>
<p>  顺便贴上比较常用的命令, 和关键文件位置, 省的我这个记性扭头就忘了.</p>
<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g                        # 生成public静态资源</span><br><span class="line"></span><br><span class="line">hexo s                        # 启动服务</span><br><span class="line"></span><br><span class="line">hexo d                        # 提交到GitHub</span><br><span class="line"></span><br><span class="line">hexo clean                    # 清除静态资源</span><br><span class="line"></span><br><span class="line">hexo n page &quot;xxx&quot;             # 生成xxx页面</span><br><span class="line"></span><br><span class="line">hexo n &quot;xxx&quot;                  # 生成文章</span><br></pre></td></tr></table></figure>
<h2 id="重要文件"><a href="#重要文件" class="headerlink" title="重要文件"></a>重要文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blog/_config.yml              # 站点配置文件</span><br><span class="line"></span><br><span class="line">blog/themes/next/_config.yml  # 主题配置文件</span><br></pre></td></tr></table></figure>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>如果想给项目加README文件, 把后缀名改成”MDOWN”并放到source文件夹下即可.</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
