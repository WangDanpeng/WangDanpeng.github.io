<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>GitHub-整个活, 好看的GitHub自我介绍</title>
    <url>/2020/11/19/20201119190543/</url>
    <content><![CDATA[<p>突然发现, 在GitHub创建和用户名同名的仓库会有彩蛋, 呐<br>
<img src="http://www.wangdanpeng.com/img/20201119190543-1.png" alt="彩蛋"><br>
意思说这是一个特殊的库, 它的README.md文件的内容将会显示到你的主页上<br>
那么咱们就可以用markdown在这里写一些带格式的自我介绍(尽情发挥脑洞)</p>
<p>另外呢, 还有这么一个项目 <a href="https://github.com/anuraghazra/github-readme-stats/blob/master/docs/readme_cn.md" target="_blank" rel="noopener">github-readme-stats</a><br>
可以动态获取你的账户的统计信息, 具体内容看它的介绍, 主题也可以选择<br>
另外搭配<code>&lt;img&gt;</code>标签, 可以控制展示的位置, 比如以下让他靠右</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">align</span>=<span class="string">"right"</span> <span class="attr">src</span>=<span class="string">"https://github-readme-stats.vercel.app/api?username=WangDanPeng&amp;show_icons=true"</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>那么最终效果就如下了<br>
<img src="http://www.wangdanpeng.com/img/20201119190543-2.png" alt="效果图"><br>
赞👍</p>
]]></content>
      <categories>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-在本地使用多个git账号</title>
    <url>/2020/11/18/20201118183648/</url>
    <content><![CDATA[<p>如何设置在本地使用多个Git账号, 比如一个公司的gitlab账号和一个本人的github账号</p>
<p>1 分别给每个账号生成ssh密钥<br>
默认的生成路径在~/.ssh/id_rea, 记得指定文件名改地址防止覆盖当前的, 例如~/.ssh/id_rsa_gh</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;xxx@gmail.com&quot;</span><br></pre></td></tr></table></figure>
<p>2 把生成好的key, 对应创建到github和公司的gitlab里</p>
<p>3 让ssh识别新密钥, 添加到ssh agent</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-add ~&#x2F;.ssh&#x2F;id_rsa_gh</span><br></pre></td></tr></table></figure>
<p>4 配置config<br>
<code>~/.ssh/config</code>文件, 没有就创建一个, 添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#公司的</span><br><span class="line">Host gitlab.com</span><br><span class="line">HostName gitlab.com</span><br><span class="line">User xxx@公司邮箱.com</span><br><span class="line">IdentityFile ~&#x2F;.ssh&#x2F;id_rsa_work</span><br><span class="line"></span><br><span class="line">#个人的</span><br><span class="line">Host github.com</span><br><span class="line">HostName github.com</span><br><span class="line">User xxx@gmail.com</span><br><span class="line">IdentityFile ~&#x2F;.ssh&#x2F;id_rsa_gh</span><br></pre></td></tr></table></figure>
<p>测试一下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com(github.com是你的host)</span><br></pre></td></tr></table></figure>
<p>5 删掉曾经设置过的全局变量 ~/.gitconfig<br>
对单个项目设置用户名和邮箱</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config user.name &quot;xxx&quot;</span><br><span class="line">git config user.email &quot;xxx@gmail.com&quot;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-记不住的命令整理</title>
    <url>/2017/03/18/20170318053142/</url>
    <content><![CDATA[<p>git作为代码管理工具基本上每天都在使用中, 然而有时候总有一些难记的命令让我每次用都需要去百度, 干脆把它们整理出来, 以后再遇到直接看自己博客就好啦, hah</p>
<p>1.忽略已经add进暂存区的文件<br>
有时候一不留神会把一些并不想提交的东西一起add到暂存区, 一下两下想不起来该用什么命令, 网上搜的有的还不对, 下面给出正解:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把文件从暂存区移除</span></span><br><span class="line">git reset HEAD xxx</span><br></pre></td></tr></table></figure>
<p>2.放弃一些本地的修改</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 放弃一个文件修改</span></span><br><span class="line">git checkout xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 放弃当前文件夹所有文件的修改</span></span><br><span class="line">git checkout .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会退到某个版本</span></span><br><span class="line">git reset --hard xxx版本号</span><br></pre></td></tr></table></figure>
<p>3.切换分支保存代码<br>
有时写了一部分代码但是突然需要切换分支或者其他操作, 需要把当前修改暂存一下, 那就下面用到的命令</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 暂存信息</span></span><br><span class="line">git stash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取存入的信息</span></span><br><span class="line">git stash pop</span><br></pre></td></tr></table></figure>
<p>4.commit message写错<br>
如果尚未push到远端, 只需要</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git commit --amend</span><br></pre></td></tr></table></figure>
<p>5.删除远端分支</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git push --delete 分支名</span><br></pre></td></tr></table></figure>
<p>6.重命名本地分支</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git branch -m 旧分支名 新分支名</span><br></pre></td></tr></table></figure>
<p>最近收藏的就这几条命令了, 以后再有记不住的随时更新, 另附上我初学git的启蒙文档 <a href="http://git.oschina.net/progit/" target="_blank" rel="noopener">Pro Git(中文版)</a>.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-Hello World</title>
    <url>/2017/02/18/20170218153653/</url>
    <content><![CDATA[<p>好久没有维护我的网站, 也懒得买服务器, 直接在github上用hexo搭了这么一个博客, 还是很方便的, 教程如下:</p>
<p><a href="http://www.wuxubj.cn/2016/08/Hexo-nexT-build-personal-blog/" target="_blank" rel="noopener">Hexo+NexT主题搭建个人博客</a></p>
<p>顺便贴上比较常用的命令, 和关键文件位置, 省的我这个记性扭头就忘了.</p>
<h2 id="命令">命令</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g                        # 生成public静态资源</span><br><span class="line"></span><br><span class="line">hexo s                        # 启动服务</span><br><span class="line"></span><br><span class="line">hexo d                        # 提交到GitHub</span><br><span class="line"></span><br><span class="line">hexo clean                    # 清除静态资源</span><br><span class="line"></span><br><span class="line">hexo n page &quot;xxx&quot;             # 生成xxx页面</span><br><span class="line"></span><br><span class="line">hexo n &quot;xxx&quot;                  # 生成文章</span><br></pre></td></tr></table></figure>
<h2 id="重要文件">重要文件</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blog&#x2F;_config.yml              # 站点配置文件</span><br><span class="line"></span><br><span class="line">blog&#x2F;themes&#x2F;next&#x2F;_config.yml  # 主题配置文件</span><br></pre></td></tr></table></figure>
<h2 id="其他">其他</h2>
<p>如果想给项目加README文件, 把后缀名改成&quot;MDOWN&quot;并放到source文件夹下即可.</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-live2d插件给你的博客加一只可爱的看板娘</title>
    <url>/2020/09/12/20200912164541/</url>
    <content><![CDATA[<h2 id="简介">简介</h2>
<p>放一只简简单单的看板娘, 没有什么互动, 安安静静的陪着你读博客.<br>
插件github地址 -&gt; <a href="https://github.com/EYHN/hexo-helper-live2d/blob/master/README.zh-CN.md" target="_blank" rel="noopener">hexo-helper-live2d</a><br>
我的博客效果图 -&gt; <a href="http://www.wangdanpeng.com/2020/09/12/20200912164541/">Mr.Wang_Blog</a></p>
<h2 id="模块安装">模块安装</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-helper-live2d</span><br></pre></td></tr></table></figure>
<h2 id="准备工作">准备工作</h2>
<p>以<code>live2d-widget-model-miku</code>模型为例</p>
<ol>
<li>在博客根目录下创建一个<code>live2d_models</code>文件夹.</li>
<li>使用<code>npm install live2d-widget-model-miku</code>下载模型, 并将模型目录<code>live2d-widget-model-miku</code>从<code>node_modules</code>里复制到<code>live2d_models</code>下.</li>
<li>进入<code>live2d-widget-model-miku</code>, 把<code>assets</code>里的内容复制到外一层.</li>
<li>添加如下配置文件, 并修改use的模型名称为<code>live2d-widget-model-miku</code>, 部署即可看到效果.</li>
</ol>
<h2 id="配置">配置</h2>
<p>向博客根目录的<code>_config.yml</code>配置文件添加配置, 可以自己微调</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">live2d:</span><br><span class="line">  enable: true</span><br><span class="line">  scriptFrom: local</span><br><span class="line">  pluginRootPath: live2dw&#x2F;</span><br><span class="line">  pluginJsPath: lib&#x2F;</span><br><span class="line">  pluginModelPath: assets&#x2F;</span><br><span class="line">  tagMode: false</span><br><span class="line">  debug: false</span><br><span class="line">  model:</span><br><span class="line">    use: live2d-widget-model-wanko # 使用的模型名称</span><br><span class="line">  display:</span><br><span class="line">    position: right # 在页面里的位置</span><br><span class="line">    hOffset: 0 # 水平偏移量, 自己微调</span><br><span class="line">    vOffset: -20 # 垂直偏移量, 自己微调</span><br><span class="line">    width: 150 </span><br><span class="line">    height: 300</span><br><span class="line">  mobile:</span><br><span class="line">    show: true</span><br><span class="line">  react:</span><br><span class="line">    opacity: 0.7 # 透明度</span><br></pre></td></tr></table></figure>
<h2 id="模型">模型</h2>
<p>现有的模型包及预览<br>
<code>live2d-widget-model-chitose</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-chitose.png" alt="chitose"><br>
<code>live2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru)</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-haur01.png" alt="haru01"><br>
<code>live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru)</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-haru02.png" alt="haru02"><br>
<code>live2d-widget-model-haruto</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-haruto.png" alt="haruto"><br>
<code>live2d-widget-model-hibiki</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-hibiki.png" alt="hibiki"><br>
<code>live2d-widget-model-hijiki</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-hijiki.png" alt="hijiki"><br>
<code>live2d-widget-model-izumi</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-izumi.png" alt="izumi"><br>
<code>live2d-widget-model-koharu</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-koharu.png" alt="koharu"><br>
<code>live2d-widget-model-miku</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-miku.png" alt="miku"><br>
<code>live2d-widget-model-ni-j</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-ni-j.png" alt="nij"><br>
<code>live2d-widget-model-nico</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-nico.png" alt="nico"><br>
<code>live2d-widget-model-nietzsche</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-nietzsche.png" alt="nietzsche"><br>
<code>live2d-widget-model-nipsilon</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-nipsilon.png" alt="nipsilon"><br>
<code>live2d-widget-model-nito</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-nito.png" alt="nito"><br>
<code>live2d-widget-model-shizuku</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-shizuku.png" alt="shizuku"><br>
<code>live2d-widget-model-tororo</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-tororo.png" alt="tororo"><br>
<code>live2d-widget-model-tsumiki</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-tsumiki.png" alt="tsumiki"><br>
<code>live2d-widget-model-unitychan</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-unitychan.png" alt="unitychan"><br>
<code>live2d-widget-model-wanko</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-wanko.png" alt="wanko"><br>
<code>live2d-widget-model-z16</code><br>
<img src="http://www.wangdanpeng.com/img/live2d/live2d-z16.png" alt="z16"></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo-接入畅言评论</title>
    <url>/2017/03/29/20170329230400/</url>
    <content><![CDATA[<p>众所周知, 多说评论要关闭了, 不管它处于什么原因和什么考虑, 总之我们要考虑换下家了, 看来看去感觉搜狐畅言的评论模块看着还算舒服, 决定接入畅言的评论系统. 可以见下方, 我正在使用的就是.</p>
<h3 id="注册">注册</h3>
<p>第一步肯定是注册畅言没啥说的, 官网地址-&gt; <a href="http://changyan.kuaizhan.com/" target="_blank" rel="noopener">畅言</a>, 需要注意的是畅言需要绑定你的域名, 还要审核备案信息, 否则只能试用15天的, 审核备案很快, 我当时用的一个多小时就过了.</p>
<h3 id="替换模板文件">替换模板文件</h3>
<p>在畅言的后台有如下安装畅言的代码:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--PC版--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"SOHUCS"</span> <span class="attr">sid</span>=<span class="string">"请将此处替换为配置SourceID的语句"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://changyan.sohu.com/upload/changyan.js"</span> &gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript"><span class="built_in">window</span>.changyan.api.config(&#123;</span></span><br><span class="line"><span class="actionscript">appid: <span class="string">'你的appid'</span>,</span></span><br><span class="line"><span class="actionscript">conf: <span class="string">'你的appkey'</span></span></span><br><span class="line">&#125;);</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>此处appid和appkey可以在你的畅言后台总览中得到, 这里的sid比较重要, 多说两句.</p>
<p>sid是用来区分各个文章的, 如果不设置, 就会所有文章共享全部的评论, 比较讨厌. 所以sid其实就是设置一个文章的唯一标示, 有的人使用文章title, 但是有可能你想修改title时, 以前的评论就会丢失, 所以安全起见, 我选用了另一个文章参数做sid, 哪个参数呢, “page.permalink”.<br>
关于文章有哪些参数可以见 -&gt; <a href="https://hexo.io/zh-cn/docs/front-matter.html" target="_blank" rel="noopener">官方文档</a>, 简单的可以把permalink参数设置成写文章时的年月日时分秒, 一般来说是不会重复的, 你也不会在同一秒写两篇文章. 好, 那么开始来配置我的模板.</p>
<p>我用的hexo的next模板, 评论模板文件在项目目录下的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">themes&#x2F;next&#x2F;layout&#x2F;_partials&#x2F;comments.swig</span><br></pre></td></tr></table></figure>
<p>把comments.swig文件备个份, 万一以后还用呢, 然后新建一个同名文件, 写入如下内容:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% if page.comments %&#125;</span><br><span class="line"> <span class="tag">&lt;<span class="name">section</span> <span class="attr">id</span>=<span class="string">"comments"</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--PC版--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"SOHUCS"</span> <span class="attr">sid</span>=<span class="string">"&#123;&#123; page.permalink &#125;&#125;"</span> &gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://changyan.sohu.com/upload/changyan.js"</span> &gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span>&gt;</span></span><br><span class="line"><span class="javascript"><span class="built_in">window</span>.changyan.api.config(&#123;</span></span><br><span class="line"><span class="actionscript">appid: <span class="string">'你的appid'</span>,</span></span><br><span class="line"><span class="actionscript">conf: <span class="string">'你的appkey'</span></span></span><br><span class="line">&#125;);</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<p>if条件判断是否设置comments参数, 想开评论的文章就添加comments参数并设为true, 不想开的页面就设为false.</p>
为把permalink参数输出到这里, hexo的各个模板的标签使用方式好像不太一样, 具体的已自己使用的模板为准, 我就见过是用<%= page.permalink %>方式输出的.
<h3 id="结束">结束</h3>
<p>到此就已经配置完成了, 你可以推代码进行验证了.</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-基于HttpClient的java后台访问URL</title>
    <url>/2017/02/18/20170218200349/</url>
    <content><![CDATA[<p>写支付相关东西遇到需要在后台访问url，搜了搜找到一篇不错的代码，收藏下来以留后用。</p>
<p>httpUtils.java中有两个公共的静态方法，一个是URLPost，另一个是URLGet，一目了然，前者是提供POST方式提交数据的，后者是提供GET方式提交数据的。其中所需要传送的数据以Map的方式传入，剩下的工作就交给我这个HttpUtils吧！当然如果Http服务器端对所提交的数据的编码有要求的话，也没问题，你可以传入UTF-8或者GBK，当然大家还可自行增加。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.net.URLEncoder;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.HttpClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.HttpException;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.HttpStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.MultiThreadedHttpConnectionManager;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.methods.GetMethod;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.httpclient.methods.PostMethod;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.Log;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * HTTP工具类</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> lixiangyang</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Log log = LogFactory.getLog(HttpUtils<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 定义编码格式 UTF-8</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String URL_PARAM_DECODECHARSET_UTF8 = <span class="string">"UTF-8"</span>;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 定义编码格式 GBK</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String URL_PARAM_DECODECHARSET_GBK = <span class="string">"GBK"</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String URL_PARAM_CONNECT_FLAG = <span class="string">"&amp;"</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String EMPTY = <span class="string">""</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> MultiThreadedHttpConnectionManager connectionManager = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> connectionTimeOut = <span class="number">25000</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> socketTimeOut = <span class="number">25000</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> maxConnectionPerHost = <span class="number">20</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> maxTotalConnections = <span class="number">20</span>;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> HttpClient client;</span><br><span class="line">	<span class="keyword">static</span>&#123;</span><br><span class="line">		connectionManager = <span class="keyword">new</span> MultiThreadedHttpConnectionManager();</span><br><span class="line">		connectionManager.getParams().setConnectionTimeout(connectionTimeOut);</span><br><span class="line">		connectionManager.getParams().setSoTimeout(socketTimeOut);</span><br><span class="line">		connectionManager.getParams().setDefaultMaxConnectionsPerHost(maxConnectionPerHost);</span><br><span class="line">		connectionManager.getParams().setMaxTotalConnections(maxTotalConnections);</span><br><span class="line">		client = <span class="keyword">new</span> HttpClient(connectionManager);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * POST方式提交数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> url</span></span><br><span class="line"><span class="comment">	 * 			待请求的URL</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> params</span></span><br><span class="line"><span class="comment">	 * 			要提交的数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> enc</span></span><br><span class="line"><span class="comment">	 * 			编码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 * 			响应结果</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">	 * 			IO异常</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">URLPost</span><span class="params">(String url, Map&lt;String, String&gt; params, String enc)</span></span>&#123;</span><br><span class="line">		String response = EMPTY;		</span><br><span class="line">		PostMethod postMethod = <span class="keyword">null</span>;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			postMethod = <span class="keyword">new</span> PostMethod(url);</span><br><span class="line">			postMethod.setRequestHeader(<span class="string">"Content-Type"</span>, <span class="string">"application/x-www-form-urlencoded;charset="</span> + enc);</span><br><span class="line">			<span class="comment">//将表单的值放入postMethod中</span></span><br><span class="line">			Set&lt;String&gt; keySet = params.keySet();</span><br><span class="line">			<span class="keyword">for</span>(String key : keySet)&#123;</span><br><span class="line">				String value = params.get(key);</span><br><span class="line">				postMethod.addParameter(key, value);</span><br><span class="line">			&#125;			</span><br><span class="line">			<span class="comment">//执行postMethod</span></span><br><span class="line">			<span class="keyword">int</span> statusCode = client.executeMethod(postMethod);</span><br><span class="line">			<span class="keyword">if</span>(statusCode == HttpStatus.SC_OK) &#123;</span><br><span class="line">				response = postMethod.getResponseBodyAsString();</span><br><span class="line">			&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				log.error(<span class="string">"响应状态码 = "</span> + postMethod.getStatusCode());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">catch</span>(HttpException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生致命的异常，可能是协议不对或者返回的内容有问题"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">catch</span>(IOException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生网络异常"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">			<span class="keyword">if</span>(postMethod != <span class="keyword">null</span>)&#123;</span><br><span class="line">				postMethod.releaseConnection();</span><br><span class="line">				postMethod = <span class="keyword">null</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> response;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * GET方式提交数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> url</span></span><br><span class="line"><span class="comment">	 * 			待请求的URL</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> params</span></span><br><span class="line"><span class="comment">	 * 			要提交的数据</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> enc</span></span><br><span class="line"><span class="comment">	 * 			编码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 * 			响应结果</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">	 * 			IO异常</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">URLGet</span><span class="params">(String url, Map&lt;String, String&gt; params, String enc)</span></span>&#123;</span><br><span class="line">		String response = EMPTY;</span><br><span class="line">		GetMethod getMethod = <span class="keyword">null</span>;		</span><br><span class="line">		StringBuffer strtTotalURL = <span class="keyword">new</span> StringBuffer(EMPTY);</span><br><span class="line">		</span><br><span class="line">	    <span class="keyword">if</span>(strtTotalURL.indexOf(<span class="string">"?"</span>) == -<span class="number">1</span>) &#123;</span><br><span class="line">	      strtTotalURL.append(url).append(<span class="string">"?"</span>).append(getUrl(params, enc));</span><br><span class="line">	    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	    	strtTotalURL.append(url).append(<span class="string">"&amp;"</span>).append(getUrl(params, enc));</span><br><span class="line">	    &#125;</span><br><span class="line">	    log.debug(<span class="string">"GET请求URL = \n"</span> + strtTotalURL.toString());</span><br><span class="line">	    </span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			getMethod = <span class="keyword">new</span> GetMethod(strtTotalURL.toString());</span><br><span class="line">			getMethod.setRequestHeader(<span class="string">"Content-Type"</span>, <span class="string">"application/x-www-form-urlencoded;charset="</span> + enc);</span><br><span class="line">			<span class="comment">//执行getMethod</span></span><br><span class="line">			<span class="keyword">int</span> statusCode = client.executeMethod(getMethod);</span><br><span class="line">			<span class="keyword">if</span>(statusCode == HttpStatus.SC_OK) &#123;</span><br><span class="line">				response = getMethod.getResponseBodyAsString();</span><br><span class="line">			&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				log.debug(<span class="string">"响应状态码 = "</span> + getMethod.getStatusCode());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">catch</span>(HttpException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生致命的异常，可能是协议不对或者返回的内容有问题"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">catch</span>(IOException e)&#123;</span><br><span class="line">			log.error(<span class="string">"发生网络异常"</span>, e);</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">			<span class="keyword">if</span>(getMethod != <span class="keyword">null</span>)&#123;</span><br><span class="line">				getMethod.releaseConnection();</span><br><span class="line">				getMethod = <span class="keyword">null</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> response;</span><br><span class="line">	&#125;	</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 据Map生成URL字符串</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> map</span></span><br><span class="line"><span class="comment">	 * 			Map</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> valueEnc</span></span><br><span class="line"><span class="comment">	 * 			URL编码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 * 			URL</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">static</span> String <span class="title">getUrl</span><span class="params">(Map&lt;String, String&gt; map, String valueEnc)</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (<span class="keyword">null</span> == map || map.keySet().size() == <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> (EMPTY);</span><br><span class="line">		&#125;</span><br><span class="line">		StringBuffer url = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">		Set&lt;String&gt; keys = map.keySet();</span><br><span class="line">		<span class="keyword">for</span> (Iterator&lt;String&gt; it = keys.iterator(); it.hasNext();) &#123;</span><br><span class="line">			String key = it.next();</span><br><span class="line">			<span class="keyword">if</span> (map.containsKey(key)) &#123;</span><br><span class="line">				String val = map.get(key);</span><br><span class="line">				String str = val != <span class="keyword">null</span> ? val : EMPTY;</span><br><span class="line">				<span class="keyword">try</span> &#123;</span><br><span class="line">					str = URLEncoder.encode(str, valueEnc);</span><br><span class="line">				&#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">					e.printStackTrace();</span><br><span class="line">				&#125;</span><br><span class="line">				url.append(key).append(<span class="string">"="</span>).append(str).append(URL_PARAM_CONNECT_FLAG);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		String strURL = EMPTY;</span><br><span class="line">		strURL = url.toString();</span><br><span class="line">		<span class="keyword">if</span> (URL_PARAM_CONNECT_FLAG.equals(EMPTY + strURL.charAt(strURL.length() - <span class="number">1</span>))) &#123;</span><br><span class="line">			strURL = strURL.substring(<span class="number">0</span>, strURL.length() - <span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> (strURL);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive-创建外部分区表</title>
    <url>/2021/05/06/20210506154231/</url>
    <content><![CDATA[<h2 id="Hive外部分区表">Hive外部分区表</h2>
<h3 id="建表语句">建表语句</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create external table xxx(</span><br><span class="line">xxx int,</span><br><span class="line">xxx string,</span><br><span class="line">xxx array&lt;bigint&gt;,</span><br><span class="line">xxx struct&lt;aaa:string,bbb:string&gt;</span><br><span class="line">)</span><br><span class="line">partitioned by(pk string) # 分区</span><br><span class="line">row format delimited fields terminated by &#39;,&#39; # 按逗号分隔, text存储时使用</span><br><span class="line">row format serde &#39;org.apache.hadoop.hive.serde2.JsonSerDe&#39; # json格式的话加上这条, stored选textfile</span><br><span class="line">stored as parquet # 五种类型可选, textfile, sequencefile, rcfile, orcfile, parquet</span><br><span class="line">location &#39;数据地址&#39;</span><br></pre></td></tr></table></figure>
<h3 id="常用命令">常用命令</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 修复分区</span><br><span class="line">msck repair table xxx;</span><br><span class="line"># 添加&#x2F;删除分区</span><br><span class="line">alter table xxx add partition(pk&#x3D;&#39;xxx&#39;) location &#39;xxxx&#39;;</span><br><span class="line">alter table xxx drop partition(pk&#x3D;&#39;xxx&#39;);</span><br><span class="line"># 查看分区</span><br><span class="line">show partitions xxx;</span><br><span class="line"># 查看分区结构</span><br><span class="line">desc formatted xxx;</span><br><span class="line"># 查看建表语句</span><br><span class="line">show create table xxxx;</span><br><span class="line"># 查看表字段</span><br><span class="line">describe table;</span><br></pre></td></tr></table></figure>
<h3 id="创建view">创建view</h3>
<p>kylin只能导入扁平化hive表, 不支持hive复杂数据类型, 导入进去不显示<br>
可通过创建view拍平复杂字段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create view if not exists xxx</span><br><span class="line">partitioned on (pk)</span><br><span class="line">as</span><br><span class="line">select aaa, bbb, ccc from yyy</span><br><span class="line">lateral view inline(properties) pp_table; # properties是struct结构字段, pp_table是lateral view创建的一张虚拟表</span><br></pre></td></tr></table></figure>
<h3 id="序列化">序列化</h3>
<p>SerDe是Serialize/Deserilize的简称, 用于序列化和反序列化<br>
用户在建表时可以用自定义的SerDe或者Hive自带的SerDe<br>
例如json文件, 在Hive0.12以上版本使用<strong>org.apache.hive.hcatalog.data.JsonSerDe</strong><br>
在Hive3.0开始被添加到Hive Serde中, <strong>org.apache.hadoop.hive.serde2.JsonSerDe</strong><br>
预计在Hive4.0中可直接支持为独立的文件格式, 即stored as jsonfile</p>
]]></content>
      <categories>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-json对象转java对象</title>
    <url>/2017/02/18/20170218195321/</url>
    <content><![CDATA[<p>项目里需要把json对象转换成java对象，还挺费劲的搜了搜，于是自己记下来，以后方便使用。</p>
<p>第一种方法，使用 JSON-lib 。</p>
<p>第二种方法，使用 JACKSON。</p>
<p>前两种方法，对相对简单的Pojo 对象来说，还是比较容易的。但是相对于嵌套多层的数据来说，复杂度就直接上去了。</p>
<p>第三种方法，使用GOOGLE 的Gson 来解决了。写过安卓的都知道，这东西，是Google出来的，最大的好处就是，基本不依赖其他的包。用起来自然很爽，取值方式非常灵活。对复杂的JSON 取值，基本统统搞定。</p>
<p>在Gson 中分为两种概念。一个就是 JsonObject 和 JsonArray。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mycompany.gsondata;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.JsonArray;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.JsonObject;</span><br><span class="line"><span class="keyword">import</span> com.google.gson.JsonParser;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hello world!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String jsonData = <span class="string">"&#123;\"questionnaireID\": \"QNTest\",\"answerResults\":[&#123;\"questionID\":\"QSTest01\",\"anserContent\":\"cfb7f441-9086-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest01\",\"anserContent\":\"cfb7f441-9086-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest03\",\"anserContent\":\"6b3a9cce-9087-11e3-8cf8-000c2945c442,a086331d-9087-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest01\",\"anserContent\":\"cfb7f441-9086-11e3-8cf8-000c2945c442\"&#125;,&#123;\"questionID\":\"QSTest05\",\"anserContent\":\"test测试文字填空\"&#125;,&#123;\"questionID\":\"QSTest06\",\"anserContent\":\"3\"&#125;,&#123;\"questionID\":\"QSTest07\",\"anserContent\":\"2.2\"&#125;]&#125;"</span>;</span><br><span class="line">        JsonObject root = <span class="keyword">new</span> JsonParser().parse(jsonData).getAsJsonObject();</span><br><span class="line">        System.out.println(root.get(<span class="string">"questionnaireID"</span>).toString());<span class="comment">//直接取的根节点值</span></span><br><span class="line"></span><br><span class="line">        JsonArray AnswerList = root.getAsJsonArray(<span class="string">"answerResults"</span>);<span class="comment">//取数组</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; AnswerList.size(); i++) &#123;</span><br><span class="line">            System.out.println(AnswerList.get(i).getAsJsonObject().get(<span class="string">"questionID"</span>).toString());</span><br><span class="line">            System.out.println(AnswerList.get(i).getAsJsonObject().get(<span class="string">"anserContent"</span>).toString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-抓取音乐网站下载链接</title>
    <url>/2017/03/18/20170318014719/</url>
    <content><![CDATA[<p>当年SongTaste网站还没关闭, 在上面找到过很多我喜欢的音乐, 当时已经被多米收购, 下载音乐超级麻烦, 后来看到网上有说扒下载链接的, 我也自己试了一下用Java开发了一个Windows小窗口, 输入音乐网址就会返回下载链接.</p>
<p>参考链接<a href="http://www.cnblogs.com/weixliu/p/3985551.html" target="_blank" rel="noopener">SongTaste网站真实URL获取</a></p>
<p>研究发现直接获取下载地址的一些关键参数在页面里都有, 只需要正则提取出来即可. 然后拼出一个请求, 发送之后就会返回下载链接, 还是很简单的, 虽然现在SongTaste已经闭站了, 就当是分享了一个小爬虫, github传送门 -&gt; <a href="https://github.com/WangDanpeng/SongTaste" target="_blank" rel="noopener">SongTaste</a></p>
<p>简简单单的一个小程序, 然而貌似是我第一次真正把编程应用到实际生活中, 当时还用这个小工具下载了不少歌, 还是很有趣的(￣▽￣)&quot;</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Kylin-4.0beta版搭建报错指南</title>
    <url>/2021/05/10/20210510191429/</url>
    <content><![CDATA[<p>大部分问题是jar包版本冲突, 导致各种类找不到<br>
根本问题是kylin4.0测试版, 依赖spark2.4.6和cdh6.3.2<br>
spark2.4.6依赖hadoop2.7和hive1.x<br>
cdh6.3.2自带hadoop3.0和hive2.x<br>
或者可以试试EMR5.31, 自带spark2.4.6, 可能冲突小一些</p>
<h3 id="NoSuchFieldError-INSTANCE">NoSuchFieldError: INSTANCE</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- java.lang.NoSuchFieldError: INSTANCE</span><br><span class="line">- java.lang.NoClassDefFoundError: Could not initialize class org.apache.http.conn.ssl.SSLConnectionSocketFactory</span><br></pre></td></tr></table></figure>
<p>http包冲突, INSTANCE字段在低版本包不存在<br>
cdh6.3.2和spark2.4.6使用的都是httpcore-4.4.x以上版本, kylin4.0启动web页面的tomcat中的kylin.war包里打着一个httpcore-4.2.2.jar<br>
<strong>解决办法:</strong> 解压war包替换httpcore包版本, 重新打war包放回tomcat里</p>
<h3 id="Spark相关ClassNotFound">Spark相关ClassNotFound</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- java.lang.ClassNotFoundException: parquet.DefaultSource</span><br><span class="line">- java.lang.ClassNotFoundException: Failed to find data source: parquet.</span><br><span class="line">- yarn找不到</span><br></pre></td></tr></table></figure>
<p>kylin目录下的spark相关jar包没被加载进classpath<br>
<strong>解决办法:</strong> 修改kylin.sh启动脚本, 手动把spark依赖加进去</p>
<h3 id="7337端口拒接访问">7337端口拒接访问</h3>
<p>kylin默认启动了spark的shuffle service<br>
<strong>解决办法:</strong> 要么去查看yarn的7337端口是不是没起来, 要么直接修改kylin配置, 关闭shuffle service</p>
<h3 id="java-lang-NoSuchFieldError-HIVE-STATS-JDBC-TIMEOUT">java.lang.NoSuchFieldError: HIVE_STATS_JDBC_TIMEOUT</h3>
<p>hive版本问题, 该字段在hive1.x中存在, hive2.x被删除<br>
spark2.4.6依赖的hive1.x, cdh6.3.2依赖的hive2.x<br>
网上有各种办法, 试了对我都不起作用, 下面是我的解决办法<br>
<strong>解决办法:</strong> 下载spark2.4.6源码, 删除源码中<strong>HIVE_STATS_JDBC_TIMEOUT</strong>和<strong>HIVE_STATS_RETRIES_WAIT</strong>字段, 然后重新编译spark, 使用编译好的spark-hive包替换spark/jars中的spark-hive包<br>
理论依据: <a href="https://issues.apache.org/jira/browse/SPARK-18112" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/SPARK-18112</a><br>
编译命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;build&#x2F;mvn -Pyarn -Phadoop-2.7 -Dhadoop.version&#x3D;2.7.5 -Phive -Phive-thriftserver -DskipTests clean package</span><br></pre></td></tr></table></figure>
<h3 id="Class-org-apache-hive-hcatalog-data-JsonSerDe-not-found">Class org.apache.hive.hcatalog.data.JsonSerDe not found</h3>
<p>创建json格式的外部表报的相关错误</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Class org.apache.hive.hcatalog.data.JsonSerDe not found</span><br><span class="line">- java.lang.ClassNotFoundException: org.apache.hadoop.hive.serde2.Deserializer</span><br><span class="line">- java.lang.ClassCastException: org.apache.hive.hcatalog.data.JsonSerDe cannot be cast to org.apache.hadoop.hive.serde2.Deserializer</span><br><span class="line">- cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD</span><br></pre></td></tr></table></figure>
<p><strong>解决办法:</strong> 一开始hive-hcatalog-core包没找到, 加到cdh的hive目录下,  后续还是有问题, 更换了json表的序列化类, 换成了org.apache.hadoop.hive.serde2.JsonSerDe</p>
<h3 id="未解决">未解决</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- Error occurred when check resource. Ignore it and try to submit this job.</span><br><span class="line">- java.lang.UnsupportedOperationException: empty.max</span><br></pre></td></tr></table></figure>
<h3 id="我忘了">我忘了</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- java.lang.NoSuchMethodException: org.apache.hadoop.hive.ql.metadata.Hive.alterTable(java.lang.String, org.apache.hadoop.hive.ql.metadata.Table)</span><br><span class="line">- java.lang.NoSuchMethodError: org.apache.parquet.bytes.BytesInput.toInputStream()Lorg&#x2F;apache&#x2F;parquet&#x2F;bytes&#x2F;ByteBufferInputStream;</span><br><span class="line">- java.lang.ClassCastException: org.apache.hadoop.hive.ql.metadata.Partition cannot be cast to org.apache.hadoop.hive.ql.metadata.PartitiontectUtils$$anonfun$getPaths$1.apply(ResourceDetectUtils.scala:43)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kylin</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Kylin</tag>
      </tags>
  </entry>
  <entry>
    <title>Sublime Text3 更换主题及插件安装</title>
    <url>/2018/11/09/20181109210424/</url>
    <content><![CDATA[<p>毫无疑问, Sublime Text是Mac电脑上为数不多十分好用的文本编辑器之一, 日常使用的频率也是非常的高, 所以配置一个好看又好用的Sublime Text就十分的有必要.</p>
<h2 id="更换主题">更换主题</h2>
<p>关于主题, 个人也是非常喜欢 <a href="https://github.com/ihodev/sublime-boxy" target="_blank" rel="noopener">sublime-boxy</a>, 安装步骤也非常简单</p>
<ol>
<li>在Sublime中按下<code>Cmd + shift + p</code>, 弹出一个输入框</li>
<li>在框中输入 <code>install package</code> 敲回车, 稍等一下会又弹出一个插件管理的输入框</li>
<li>在框中输入 <code>Boxy Theme</code>, 选择第一个安装, 稍等一会就安装完毕</li>
<li>安装完成以后可能会自动弹出要求你安装 <code>A File Icon</code>(比较好看的左侧文件图标), 同意安装就好, 如果没有自动安装就回到第三步手动安装一下</li>
<li>装好以后重启Sublime默认是一个浅色主题, 不喜欢可以自己改配置文件, 直接按下<code> Cmd + ,</code>弹出配置文件, 左侧为默认配置文件, 右侧为用户自定义配置文件, 想改什么就往右侧加, 可选主题参考<a href="https://github.com/ihodev/sublime-boxy/wiki/Get-It#activation" target="_blank" rel="noopener">官方说明</a>, 把相应配置加到配置文件再重启即可生效</li>
</ol>
<h2 id="Vim设置">Vim设置</h2>
<p>另外我个人喜欢使用vim模式, 感觉比较舒服, 顺带附上vim模式的开启方法, 非常简单如下</p>
<p>同上在Sublime中按下<code>Cmd + ,</code>弹出配置文件, 在右侧有一个<code>ignored_packages</code>配置, 其中默认有<code>Vintage</code>, 把它删掉, 留下一个空的括号, 重启生效, 就可以使用vim了<br>
想要关闭的话同理再把<code>Vintage</code>加回去</p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Kylin-4.0beta版部署</title>
    <url>/2021/05/18/20210518173009/</url>
    <content><![CDATA[<h3 id="新特性">新特性</h3>
<ul>
<li>Spark唯一构建引擎</li>
<li>引入parquet, 正在踢出HBase</li>
<li>可存储到HDFS</li>
</ul>
<h3 id="1-准备机器">1. 准备机器</h3>
<ul>
<li>准备三台机器, 系统CentOS7, 切记, 后续安装CDH版本为6.3.2, 高版本系统不支持</li>
<li>改hosts, ssh, 免密登录</li>
<li>改用户可打开文件数量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">* vi /etc/security/limits.conf</span><br><span class="line">*    soft    nofile   32728</span><br><span class="line">*    hard    nofile   1024999</span><br><span class="line">*    soft    nproc    65535</span><br><span class="line">*    hard    noroc    unlimited</span><br><span class="line">*    soft    memlock    unlimited</span><br><span class="line">*    hard    memlock    unlimited</span><br><span class="line">* sysctl -p</span><br></pre></td></tr></table></figure>
<ul>
<li>禁用透明大页面压缩</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>
<p>并将上面的两条命令写入开机自启动/etc/rc.local。</p>
<ul>
<li>设置swap空间(所有节点)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo "vm.swappiness = 0" &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure>
<h3 id="2-准备数据库">2. 准备数据库</h3>
<ul>
<li>主节点安装Mysql</li>
<li>创建用户,数据库, 后续使用, 安装什么服务就建对应的数据库, 或者到后续配置前创建</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- cloudera-manager</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> scm <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'scm'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> scm.* <span class="keyword">TO</span> <span class="string">'scm'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'scm'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- active_monitor</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> active_monitor <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'active_monitor'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> active_monitor.* <span class="keyword">TO</span> <span class="string">'active_monitor'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'active_monitor'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- amon</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> amon <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'amon'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> amon.* <span class="keyword">TO</span> <span class="string">'amon'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'amon'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- hive</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> hive <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'hive'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> hive.* <span class="keyword">TO</span> <span class="string">'hive'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'hive'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- hue</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> hue <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'hue'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> hue.* <span class="keyword">TO</span> <span class="string">'hue'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'hue'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- oozie</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> oozie <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'oozie'</span>@<span class="string">'%'</span><span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> oozie.* <span class="keyword">TO</span> <span class="string">'oozie'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span>; </span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'oozie'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'Kylin@2021!'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br><span class="line"><span class="comment">-- 刷新mysql的权限列表 </span></span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>主节点放置Mysql驱动包</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz</span><br></pre></td></tr></table></figure>
<h3 id="3-安装依赖">3. 安装依赖</h3>
<ul>
<li>安装jdk, 配置Java home</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install java-1.8.0-openjdk-devel.x86_64</span><br><span class="line">ll /etc/alternatives/java</span><br></pre></td></tr></table></figure>
<ul>
<li>安装依赖</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y bind-utils psmisc libxslt cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs httpd mod_ssl openssl-devel /lib/lsb/init-functions libpq.so.5python27postgresql-devel*postgresql-odbc.x86_64python2-develchkconfig zlib sqlite  redhat-lsb postgresql*   openssl  telnet pcre-devel gcc gcc-c++ MySQL-python</span><br></pre></td></tr></table></figure>
<ul>
<li>更新pip</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install --upgrade pip</span><br><span class="line">pip install --upgrade setuptools</span><br><span class="line">pip2 install psycopg2</span><br></pre></td></tr></table></figure>
<h3 id="4-部署CDH">4. 部署CDH</h3>
<p>CDH版本6.3.2, 官网停止下载了, 我还留了一份安装包, <a href="https://download.csdn.net/download/u012355401/18809481" target="_blank" rel="noopener">csdn下载地址</a></p>
<h4 id="安装CM">安装CM</h4>
<ul>
<li>解压, 主节点安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/cloudera-manager/cm6.3.1/RPMS/x86_64/</span><br><span class="line">rpm -ivh cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br><span class="line">rpm -ivh cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br><span class="line">rpm -ivh cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br></pre></td></tr></table></figure>
<ul>
<li>其他节点</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/cloudera-manager/cm6.3.1/RPMS/x86_64/</span><br><span class="line">rpm -ivh cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br><span class="line">rpm -ivh cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm --nodeps --force</span><br></pre></td></tr></table></figure>
<ul>
<li>所有节点修改agent配置, 指向master</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/etc/cloudera-scm-agent/config.ini server_host=主机名</span><br></pre></td></tr></table></figure>
<ul>
<li>初始化数据库, 测试Mysql连接</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm Kylin@2021!</span><br><span class="line">All done, your SCM database is configured correctly! 成功</span><br></pre></td></tr></table></figure>
<ul>
<li>启动cm server</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 主节点启动server</span></span><br><span class="line">systemctl restart cloudera-scm-server</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看server运行状态</span></span><br><span class="line">service cloudera-scm-server status</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看server日志</span></span><br><span class="line">tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点启动agent</span></span><br><span class="line">systemctl restart cloudera-scm-agent  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看agent运行状态</span></span><br><span class="line">service cloudera-scm-agent  status</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看agent日志</span></span><br><span class="line">tail -f /var/log/cloudera-scm-agent/cloudera-scm-agent.log</span><br></pre></td></tr></table></figure>
<ul>
<li>启动完毕, 浏览器访问master ip:7180, 默认密码admin/admin</li>
</ul>
<h4 id="安装CDH">安装CDH</h4>
<ul>
<li>开始离线安装CDH,准备parcel包</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 部署离线parcel源</span></span><br><span class="line">mkdir -p /var/www/html/cdh6_parcel</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将parcel包放在httpd的目录下</span></span><br><span class="line">cp cdh/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel /var/www/html/cdh6_parcel/</span><br><span class="line">cp cdh/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel.sha1 /var/www/html/cdh6_parcel/CDH-6.3.1</span><br><span class="line">cp cdh/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel.sha1 /var/www/html/cdh6_parcel/CDH-6.3.1-1.cdh6.3.1.p0.1470567-el7.parcel.sha</span><br><span class="line">cp cdh/manifest.json /var/www/html/cdh6_parcel/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动httpd服务</span></span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure>
<p>浏览器访问master ip/cdh6_parcel</p>
<ul>
<li>返回CM, 选择免费版下一步下一步, 选主机, 更多选项, 添加源继续, 等解压, 检查集群, 忽略,下一步, 选择安装的组件, 使用之前创建好的账号配置数据库, 配置默认下一步</li>
<li>CDH部署完成</li>
</ul>
<h3 id="5-部署Kylin">5. 部署Kylin</h3>
<p>以上都顺利的话, 按照官方步骤执行, 即可启动成功<br>
<a href="https://cwiki.apache.org/confluence/display/KYLIN/Deploy+Kylin+4+on+CDH+6" target="_blank" rel="noopener">Deploy Kylin4 on CDH6</a></p>
]]></content>
      <categories>
        <category>Kylin</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Kylin</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis-逻辑连接未关闭</title>
    <url>/2017/02/26/20170226153828/</url>
    <content><![CDATA[<p>首先环境我用的Struts2 + Sprig + Mybatis</p>
<p>最近重构了Mqsql连接池, 改用了阿里的druid. 因为druid带有WebUi, 我发现我的项目只打开数据库连接却不关闭, 那肯定是sqlSessionfactory出问题了.</p>
<p>因为之前的代码不是我写的, 尝试着关闭sqlSession后还是不管用, 干脆直接使用sqlSessionTemplate.<br>
先配置Spring</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">"white-space:pre"</span>&gt;</span>	<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="comment">&lt;!--创建sqlSessionFactory --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"sqlSessionFactory"</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.SqlSessionFactoryBean"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"configLocation"</span> <span class="attr">value</span>=<span class="string">"classpath:SqlMapConfig.xml"</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- sqlSessionTemplate配置（支持批量） --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"sqlSessionTemplate"</span> <span class="attr">class</span>=<span class="string">"org.mybatis.spring.SqlSessionTemplate"</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- 参数1: sqlSessionFactory|参数2：ExecutorType --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"0"</span> <span class="attr">ref</span>=<span class="string">"sqlSessionFactory"</span> /&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- 开启BATCH批量更新会丢失更新的返回值，导致返回-2147482646 --&gt;</span></span><br><span class="line">		<span class="comment">&lt;!-- &lt;constructor-arg index="1" value="BATCH" /&gt; --&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>项目中伪码如下:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//注入spring中配置的SqlSessionTemplate对象，单例</span></span><br><span class="line"><span class="meta">@Resource</span>(name=<span class="string">"sqlSessionTemplate"</span>)</span><br><span class="line"><span class="keyword">public</span> SqlSessionTemplate sqlSessionTemplate;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">saveTestTrans</span><span class="params">()</span></span>&#123;</span><br><span class="line">     <span class="keyword">this</span>.sqlSessionTemplate.selectList(<span class="string">"testdomain.selectAnySql"</span>, <span class="string">"select * from my_blog where id='1'"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的SqlSessionTemplate不仅是单例的，而且不需要手工新建和关闭SqlSession.</p>
<p>为什么mybatis-spring.jar中的SqlSessionTemplate可以被多个dao复用，而且不会造成数据连接泄露呢，并且还可以自动新建和释放数据库连接？官方解答是因为SqlSessionTemplate是线程安全的，也就是确保每个线程使用的sqlSession的唯一并不互相冲突。</p>
<p>首先看了一下mybatis-spring的源码，发现SqlSessionTemplate是通过代理拦截和SqlSessionHolder实现的sqlsession线程安全和自动新建和释放连接的。看构造函数函数中构建代理类，该代理类实现SqlSession接口，定义了方法拦截器，如果调用代理类实例中实现SqlSession接口定义的方法，该调用则被导向SqlSessionInterceptor的invoke方法，这个方法中自动进行了SqlSession的自动请求和释放（如果不被spring托管则自己新建和释放sqlsession，如果被spring管理则使用SqlSessionHolder进行request和relase操作）</p>
<p>以下网址针对SqlSessionTemplate的线程安全特性进行了详细的探究：<a href="http://www.cnblogs.com/daxin/p/3544188.html" target="_blank" rel="noopener">http://www.cnblogs.com/daxin/p/3544188.html</a></p>
<p>另外此处还有一个坑:</p>
<p>上面Spring配置里有个参数被我注释了</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">constructor-arg</span> <span class="attr">index</span>=<span class="string">"1"</span> <span class="attr">value</span>=<span class="string">"BATCH"</span> /&gt;</span></span><br></pre></td></tr></table></figure>
<p>它的意思就是defaultExecutorType=BATCH, defaultExecutorType有三个值:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">simple -&gt; 普通返回</span><br><span class="line">reuse  -&gt; 重复返回</span><br><span class="line">batch  -&gt; 批量更新</span><br></pre></td></tr></table></figure>
<p>一旦选择了batch属性, 那么所有更新插入操作返回的那个int类型的数值就会使-2147482646, 也就是返回值丢失了.</p>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>MyEclipse-新装MyEclipse后的一系列设置汇总</title>
    <url>/2017/02/19/20170319224848/</url>
    <content><![CDATA[<p>首先第一步肯定是破解无疑，我没钱去买正版的。。。</p>
<p>按我习惯的顺序来，导入一项目，方便参考着设置。</p>
<h3 id="1-收起包名">1. 收起包名</h3>
<p>默认情况下是这个样子一长串<br>
<img src="http://img.blog.csdn.net/20160212203014158?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="此处输入图片的描述"></p>
<p>点击此处三角，然后package presentation—&gt;hierarchical，就会就会变成如下图的效果</p>
<p><img src="http://img.blog.csdn.net/20160212202939129?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="此处输入图片的描述"></p>
<h3 id="2-显示行号">2. 显示行号</h3>
<p>直接打开一个文件，在文件最最侧栏右键，勾选上show line numbers</p>
<h3 id="3-更改字体大小">3. 更改字体大小</h3>
<p>Window --&gt; Preferences --&gt; General --&gt; Appearance --&gt; Colors and Fonts --&gt; Text Font，双击进行修改</p>
<h3 id="4-更改文件编码（推荐全部改为utf-8）">4. 更改文件编码（推荐全部改为utf-8）</h3>
<ul>
<li>windows-&gt;Preferences-&gt;general-&gt;Workspace，右侧窗口Text file encoding，选择Other，改变为UTF-8，以后新建立工程其属性对话框中的Text file encoding即为UTF-8。</li>
<li>windows----&gt;Preferences—&gt;General—&gt;Content Types，右侧Context Types窗口，点开Text树中每一颗子项，并在中输入&quot;UTF-8&quot;，点“update ”更新。</li>
<li>window—&gt;preference—&gt;MyEclipse—&gt;Files and Editors，将每个子项的&quot;Encoding&quot;改为&quot;ISO 10645/Unicode（UTF-8）&quot;，点Apply。</li>
</ul>
<p>经过这样的设置，一切编码都已经统一了</p>
<h3 id="5-设置配色方案">5. 设置配色方案</h3>
<p>个人认为编辑器白色背景太刺眼了，习惯换成黑色背景<br>
配色方案可以从这里下载http://eclipsecolorthemes.org/ ，下载epf格式用来导入<br>
File-&gt;Import-&gt;General-&gt;preference,然后选中你下载的epf文件，点击finish</p>
<hr>
<p>到此为止设置就先告一段落, 如有其它用到的配置再进行补充.</p>
]]></content>
      <categories>
        <category>MyEclipse</category>
      </categories>
      <tags>
        <tag>MyEclipse</tag>
      </tags>
  </entry>
  <entry>
    <title>MyEclipse-设置JAVA选中高亮显示</title>
    <url>/2017/02/18/20170218201209/</url>
    <content><![CDATA[<ol>
<li>打开高亮显示功能<br>
选择Windows-&gt;Preferences-&gt;Java-&gt; Editor-&gt; Mark Occurrences ，勾选选项。这时，当你单击一个元素的时候，代码中所有该元素存在的地方都会被高亮显示。</li>
<li>设置高亮的颜色<br>
Window/preferences/general/Editors/Text Editors/Annotations/Occurences</li>
</ol>
]]></content>
      <categories>
        <category>MyEclipse</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MyEclipse</tag>
      </tags>
  </entry>
  <entry>
    <title>SBT-修改资源库地址</title>
    <url>/2017/04/06/20170406210224/</url>
    <content><![CDATA[<p>做大数据开发, 用scala的都会用到sbt来打包依赖, 但是sbt默认配置里连接的国外地址, 根本就下不下来依赖包, 而且还有的地址是https的, 连接都被拒绝了, 所以我们就来修改sbt默认的配置.</p>
<p>首先, 我的系统是mac, 不管是用idea装的scala插件里带的sbt, 还是用Homebrew安装的sbt, 都会在用户目录下有个.sbt文件夹, 执行<code>ll -a</code>即可看到.</p>
<h3 id="方法一">方法一</h3>
<p>进入.sbt文件夹, 创建一个名叫repositories的文件, 默认应该是没有的, 并加入以下内容, 来覆盖默认配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[repositories]</span><br><span class="line">  local</span><br><span class="line">  aliyun: http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;</span><br><span class="line">  maven-central: http:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#x2F;</span><br><span class="line">  sbt-maven-releases: http:&#x2F;&#x2F;repo.scala-sbt.org&#x2F;scalasbt&#x2F;maven-releases&#x2F;, bootOnly</span><br><span class="line">  sbt-maven-snapshots: http:&#x2F;&#x2F;repo.scala-sbt.org&#x2F;scalasbt&#x2F;maven-snapshots&#x2F;, bootOnly</span><br><span class="line">  typesafe-ivy-releases: http:&#x2F;&#x2F;repo.typesafe.com&#x2F;typesafe&#x2F;ivy-releases&#x2F;, [organization]&#x2F;[module]&#x2F;[revision]&#x2F;[type]s&#x2F;[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line">  sbt-ivy-snapshots: http:&#x2F;&#x2F;repo.scala-sbt.org&#x2F;scalasbt&#x2F;ivy-snapshots&#x2F;, [organization]&#x2F;[module]&#x2F;[revision]&#x2F;[type]s&#x2F;[artifact](-[classifier]).[ext], bootOnly</span><br></pre></td></tr></table></figure>
<p>可见其中加入了阿里云的maven地址, 之前用过开源中国的, 后来他们干不下去了, 这次阿里云接盘, 应该不会轻易的狗带.</p>
<h3 id="方法二">方法二</h3>
<p>理论上添加以上配置后即可覆盖原来的默认配置, 然而我的sbt好像死活就是不行, 所以我还有第二个比较hacker的方法, 既然默认配置覆盖不掉, 那我就把默认配置改了.</p>
<p>我的sbt是用Homebrew安装的, 默认安装位置在 <code>/usr/local/Cellar/sbt</code>, 此处有一个bin文件夹和一个conf文件夹, 我们要破坏的jar包就是bin下的sbt-launch.jar文件.<br>
tar解压sbt-launch.jar文件可以得到以下文件结构:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">total 72</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  5 12  2016 META-INF</span><br><span class="line">-rwxr-xr-x   1 wdp  staff    59B  8 17  2015 module.properties</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  5 12  2016 org</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  1  3 19:58 sbt</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.10.0</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.10.1</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.11.0</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.11.1</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   681B  5 12  2016 sbt.boot.properties0.11.2</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   675B  5 12  2016 sbt.boot.properties0.11.3</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   959B  5 12  2016 sbt.boot.properties0.13.0</span><br><span class="line">-rwxr-xr-x   1 wdp  staff   690B  5 12  2016 sbt.boot.properties0.7</span><br><span class="line">drwxr-xr-x  61 wdp  staff   2.0K  5 12  2016 scala</span><br><span class="line">drwxr-xr-x   3 wdp  staff   102B  5 12  2016 xsbt</span><br><span class="line">drwxr-xr-x  24 wdp  staff   816B  5 12  2016 xsbti</span><br></pre></td></tr></table></figure>
<p>默认的配置文件就在sbt文件夹下的sbt.boot.properties文件, 对此文件内的内容进行替换, 如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[scala]</span><br><span class="line">  version: $&#123;sbt.scala.version-auto&#125;</span><br><span class="line"></span><br><span class="line">[app]</span><br><span class="line">  org: $&#123;sbt.organization-org.scala-sbt&#125;</span><br><span class="line">  name: sbt</span><br><span class="line">  version: $&#123;sbt.version-read(sbt.version)[1.0.0-M4]&#125;</span><br><span class="line">  class: $&#123;sbt.main.class-sbt.xMain&#125;</span><br><span class="line">  components: xsbti,extra</span><br><span class="line">  cross-versioned: $&#123;sbt.cross.versioned-false&#125;</span><br><span class="line">  resources: $&#123;sbt.extraClasspath-&#125;</span><br><span class="line"></span><br><span class="line">[repositories]</span><br><span class="line">  local</span><br><span class="line">  aliyun: http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public</span><br><span class="line">  maven-central: http:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#x2F;</span><br><span class="line">  sbt-maven-releases: http:&#x2F;&#x2F;repo.scala-sbt.org&#x2F;scalasbt&#x2F;maven-releases&#x2F;, bootOnly</span><br><span class="line">  sbt-maven-snapshots: http:&#x2F;&#x2F;repo.scala-sbt.org&#x2F;scalasbt&#x2F;maven-snapshots&#x2F;, bootOnly</span><br><span class="line">  typesafe-ivy-releases: http:&#x2F;&#x2F;repo.typesafe.com&#x2F;typesafe&#x2F;ivy-releases&#x2F;, [organization]&#x2F;[module]&#x2F;[revision]&#x2F;[type]s&#x2F;[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line">  sbt-ivy-snapshots: http:&#x2F;&#x2F;repo.scala-sbt.org&#x2F;scalasbt&#x2F;ivy-snapshots&#x2F;, [organization]&#x2F;[module]&#x2F;[revision]&#x2F;[type]s&#x2F;[artifact](-[classifier]).[ext], bootOnly</span><br><span class="line"></span><br><span class="line">[boot]</span><br><span class="line">  directory: $&#123;sbt.boot.directory-$&#123;sbt.global.base-$&#123;user.home&#125;&#x2F;.sbt&#125;&#x2F;boot&#x2F;&#125;</span><br><span class="line"></span><br><span class="line">[ivy]</span><br><span class="line">  ivy-home: $&#123;sbt.ivy.home-$&#123;user.home&#125;&#x2F;.ivy2&#x2F;&#125;</span><br><span class="line">  checksums: $&#123;sbt.checksums-sha1,md5&#125;</span><br><span class="line">  override-build-repos: $&#123;sbt.override.build.repos-false&#125;</span><br><span class="line">  repository-config: $&#123;sbt.repository.config-$&#123;sbt.global.base-$&#123;user.home&#125;&#x2F;.sbt&#125;&#x2F;repositories&#125;</span><br></pre></td></tr></table></figure>
<p>修改完成, 再执行<code>jar -cfM ./sbt-launch.jar .</code>打成jar包, 把bin目录下的原始jar包替换掉即可, 这次保证妥妥的.</p>
<p>附上我改好的jar包下载地址, 送给懒得自己动手的人们, 传送门 -&gt; <a href="http://www.wangdanpeng.com/jars/sbt-launch.jar">sbt-launch.jar</a></p>
]]></content>
      <categories>
        <category>SBT</category>
      </categories>
      <tags>
        <tag>SBT</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala-抓取项目代码中全部代码注释</title>
    <url>/2019/05/13/Scala-%E6%8A%93%E5%8F%96%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E4%B8%AD%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81%E6%B3%A8%E9%87%8A/</url>
    <content><![CDATA[<p>日前某站代码泄露, 大佬们贴出很多代码中有趣的注释, 于是突发奇想, 写了一个没有用的小程序…</p>
<p>(ps: 某站代码我没看, 你们可, 别瞎说…)</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"><span class="keyword">import</span> java.util.regex.<span class="type">Pattern</span></span><br><span class="line"><span class="keyword">import</span> java.io.&#123;<span class="type">File</span>, <span class="type">PrintWriter</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Bi</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getFile</span></span>(file:<span class="type">File</span>): <span class="type">Array</span>[<span class="type">File</span>] =&#123;</span><br><span class="line">    <span class="keyword">val</span> files = file.listFiles()</span><br><span class="line">                    .filter(! _.isDirectory)</span><br><span class="line">                    <span class="comment">// 指定要读取什么文件</span></span><br><span class="line">                    .filter(t =&gt; t.toString.endsWith(<span class="string">".go"</span>))</span><br><span class="line">    files ++ file.listFiles()</span><br><span class="line">                  .filter(f =&gt; f.isDirectory</span><br><span class="line">                    <span class="comment">// 指定排除掉什么文件夹</span></span><br><span class="line">                    &amp;&amp; f.getName != <span class="string">"vendor"</span>)</span><br><span class="line">                  .flatMap(getFile)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">check</span></span>(s: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> pattern = <span class="string">"[\u4e00-\u9fa5]+"</span></span><br><span class="line">    <span class="keyword">val</span> p = <span class="type">Pattern</span>.compile(pattern)</span><br><span class="line">    <span class="keyword">val</span> result = p.matcher(s)</span><br><span class="line">    <span class="keyword">if</span> (result.find()) <span class="literal">true</span> <span class="keyword">else</span> <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> path = <span class="keyword">new</span> <span class="type">File</span>(<span class="string">"目标文件夹路径"</span>)</span><br><span class="line">    <span class="keyword">val</span> writer = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="keyword">new</span> <span class="type">File</span>(<span class="string">"输出文件路径"</span>))</span><br><span class="line"></span><br><span class="line">    getFile(path).foreach&#123; file =&gt;</span><br><span class="line">      <span class="keyword">var</span> flag = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> text=<span class="type">Source</span>.fromFile(file)</span><br><span class="line">      <span class="keyword">for</span>(line &lt;- text.getLines)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">if</span> (line.trim.startsWith(<span class="string">"//"</span>) &amp;&amp; check(line)) &#123;</span><br><span class="line">          flag = <span class="literal">true</span></span><br><span class="line">          writer.println(<span class="string">s"-----<span class="subst">$line</span>"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (flag) &#123;</span><br><span class="line">        <span class="comment">// 打印以上注释出自哪个文件</span></span><br><span class="line">        writer.println(file.getPath)</span><br><span class="line">      &#125;</span><br><span class="line">      text.close</span><br><span class="line">    &#125;</span><br><span class="line">    writer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-RDD简单介绍</title>
    <url>/2018/11/28/20181128141747/</url>
    <content><![CDATA[<p>结合Spark官网, 对Spark RDD的一些简单介绍和总结.</p>
<p>RDD是Spark提供的主要抽象, 全称弹性分布式数据集, 它是跨集群节点来分区的元素集合, 可以并行操作, 可以保留在内存, 还可以自动从节点故障中恢复.</p>
<h2 id="创建RDD">创建RDD</h2>
<p>创建RDD有两种方法</p>
<p><strong>并行化现有集合</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val data &#x3D; Array(1, 2, 3, 4, 5)</span><br><span class="line">val rdd &#x3D; sc.parallelize(data)</span><br><span class="line">val rdd2 &#x3D; sc.parallelize(data, 10)</span><br></pre></td></tr></table></figure>
<p>并行集合的一个重要参数就是将数据集切分的分区数. Spark执行任务时, 为每一个分区产生一个task, 分区数也就是任务执行时的并行度, 所以可以通过第二个参数来手动设置分区数.</p>
<p><strong>引用外部存储系统中的数据集</strong><br>
Spark可以从Hadoop支持的任何存储系统创建RDD, 包括本地文件系统, HDFS, HBase等等.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val rdd &#x3D; sc.textFile(&quot;data.text&quot;)</span><br></pre></td></tr></table></figure>
<p>关于读取文件的注意事项</p>
<ul>
<li>如果使用的是本地文件系统路径, 要确保该文件已发送到所有worker节点上的相同路径下.</li>
<li>文件的URI支持使用通配符, 如textFile(“/my/directory/*.txt”)</li>
<li>该方法同样有第二个可选参数来控制分区数, 默认Spark为文件的每个块创建一个分区(HDFS中默认一块128MB), 你只能创建比现有块更多的分区, 不能更少.</li>
</ul>
<h2 id="RDD操作">RDD操作</h2>
<p>RDD的操作分两种类型: transformation(转换, 从现有数据集创建新的数据集)和action(行动, 在数据集上运行计算后将值返回给driver端).<br>
Spark中所有的转换都是懒惰的, 所以转换操作并不会触发Spark job的提交, 只有触发action时, 才会提交job运算结果.</p>
<p>常见的转换操作</p>
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>map</strong>(func)</td>
<td style="text-align:left">将RDD中每个元素一一转换成新元素返回新数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>filter</strong>(func)</td>
<td style="text-align:left">返回func为true的元素形成的新数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>flatMap</strong>(func)</td>
<td style="text-align:left">将RDD中的每个元素进行一对多转换形成新的数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>union</strong>(otherDataset)</td>
<td style="text-align:left">将两个集合中的数据进行合并, 返回两个集合的并集, 不去重</td>
</tr>
<tr>
<td style="text-align:left"><strong>join</strong>(otherDataset, [numPartitions])</td>
<td style="text-align:left">当调用类型(K, V)和(K, W)的数据集时, 返回(K, (V, W))对的数据集以及每个键的所有元素对</td>
</tr>
<tr>
<td style="text-align:left"><strong>groupByKey</strong>([numPartitions])</td>
<td style="text-align:left">在(K, V)对的数据集上调用, 返回(K, Iterable<V>)对的数据集;默认输出的并行度取决于父RDD的分区数, 也可以使用numPartitions参数指定</td>
</tr>
<tr>
<td style="text-align:left"><strong>reduceByKey</strong>(func, [numPartitions])</td>
<td style="text-align:left">当调用(K, V)对的数据集时, 返回(K, V)对数据集, 使用给定的reduce函数func聚合每个键的值, 同样可以通过numPartitions参数指定任务数量</td>
</tr>
<tr>
<td style="text-align:left"><strong>sortByKey</strong>([ascending], [numpartitions])</td>
<td style="text-align:left">返回按Key升序或降序的(K, V)对的数据集</td>
</tr>
<tr>
<td style="text-align:left"><strong>repartition</strong>(numPartitions)</td>
<td style="text-align:left">随机重新调整RDD中的数据以创建更平衡的分区</td>
</tr>
</tbody>
</table>
<p>常见行动操作</p>
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>reduce</strong>(func)</td>
<td style="text-align:left">使用func来聚合数据集的元素</td>
</tr>
<tr>
<td style="text-align:left"><strong>collect</strong>()</td>
<td style="text-align:left">在driver端将数据集所有元素作为数组返回, 注意当结果集很大时十分消耗内存</td>
</tr>
<tr>
<td style="text-align:left"><strong>count</strong>()</td>
<td style="text-align:left">返回数据集中的元素数</td>
</tr>
<tr>
<td style="text-align:left"><strong>first</strong>()</td>
<td style="text-align:left">返回数据集中的第一个元素</td>
</tr>
<tr>
<td style="text-align:left"><strong>take</strong>(n)</td>
<td style="text-align:left">返回数据集中的前n个元素的数组</td>
</tr>
<tr>
<td style="text-align:left"><strong>saveAsTextFile</strong>(path)</td>
<td style="text-align:left">将数据集的元素作为文本文件写入Hadoop支持的文件系统的指定目录中</td>
</tr>
<tr>
<td style="text-align:left"><strong>foreach</strong>(func)</td>
<td style="text-align:left">在每个元素上运行func</td>
</tr>
</tbody>
</table>
<h2 id="Shuffle">Shuffle</h2>
<p>在Spark中, 单个任务在单个分区上运行, 为了组织执行单个reduce任务的所有数据, 就必须从所有分区中读取所有键的所有值, 然后将各个值组合在一起以计算每个键的结果, 这就是Shuffle.</p>
<p>一般触发shuffle的操作包括重新分区, 如repartition和coalesce; ByKey操作, 如groupByKey和reduceByKey;连接操作, 如join和cogroup.</p>
<p>shuffle操作消耗巨大, 因为它涉及到磁盘I/O, 数据序列化和网络I/O.为了组织shuffle的数据, Spark生成多组map任务以组织数据, 以及一组reduce任务来聚合数据.map任务的结果会保留在内存中, 直到内存放不下, Spark会将这些数据溢出到磁盘, 从而导致磁盘I/O的额外开销和垃圾回收的增加.<br>
Shuffle还会在磁盘上生成大量中间文件, 从Spark1.3开始, 这些文件直到相关RDD不再使用才会被垃圾回收, 这样做是为了在重新计算时, 不需要重新创建shuffle文件.spark.local.dir可配置临时存储目录.</p>
<h2 id="RDD持久性">RDD持久性</h2>
<p>Spark中最重要的功能之一就是跨操作在内存中持久化数据集.当你缓存RDD时, 每个节点都会将它计算的分区数据存储在内存中, 并在该数据集的其他操作中重用它们, 这使得后续操作执行更快.缓存是迭代算法和快速交互式使用的关键工具.</p>
<p>你可以使用persist()或cache()方法标记要缓存的RDD.第一次计算它时, 会将RDD保留在节点内存中.</p>
<p>此外, 每个持久化的RDD都可以使用不同的存储级别进行存储.例如, 存在内存里, 存在磁盘上, 序列化为Java对象等.persist()通过传递StorageLevel对象来设置级别, cache()方法默认实用StorageLevel.MEMORY_ONLY.<br>
全部存储级别有</p>
<table>
<thead>
<tr>
<th style="text-align:left">存储级别</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">“MEMORY_ONLY”</td>
<td style="text-align:left">默认级别,将RDD存储为JVM中的反序列化Java对象, 如果内存不够将不会被缓存</td>
</tr>
<tr>
<td style="text-align:left">“MEMORY_AND_DISK”</td>
<td style="text-align:left">将RDD存储为JVM中的反序列化Java对象, 如果内存不够将溢出到磁盘</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_ONLY_SER(Java和Scala)</td>
<td style="text-align:left">将RDD存储为序列化Java对象, 这通常比反序列化对象更节省空间, 但是读取CPU密集程度更高</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_AND_DISK_SER(Java和Scala)</td>
<td style="text-align:left">与MEMORY_ONLY_SER类似, 但将不适合在内存的分区溢出到磁盘.</td>
</tr>
<tr>
<td style="text-align:left">DISK_ONLY</td>
<td style="text-align:left">仅将RDD存储在磁盘上</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_ONLY_2,MEMORY_AND_DISK_2等</td>
<td style="text-align:left">与以上级别相同, 但在集群的两个节点上复制</td>
</tr>
<tr>
<td style="text-align:left">OFF_HEAP(实验性)</td>
<td style="text-align:left">与MEMORY_ONLY_SER类似, 但将数据存储在堆外内存, 这需要启用堆外内存</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>RDD</tag>
        <tag>文档</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-从wordCount到job调度过程</title>
    <url>/2017/03/05/20170305231525/</url>
    <content><![CDATA[<p>以wordCount为例, 研究学习spark(版本2.1.0)的整个job调度过程,整理总结如下:</p>
<h3 id="WordCount">WordCount</h3>
<p>首先, 一个简单的wordCount程序</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rawFile = sc.textFile(<span class="string">"README.md"</span>)</span><br><span class="line"><span class="keyword">val</span> words = rawFile.flatMap(w =&gt; w.split(<span class="string">" "</span>))</span><br><span class="line"><span class="keyword">val</span> wordNum = words.map(w =&gt; (w, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> wordCount = wordNum.reduceByKey(_ + _)</span><br><span class="line">wordCount.collect</span><br></pre></td></tr></table></figure>
<p>我是用idea + spark-shell断点调试spark源码的, 可以一行代码一行代码的追执行过程,  调试方法可见我的另一篇文章 <a href="http://www.wangdanpeng.com/2017/03/12/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95/">Spark-断点调试</a>.</p>
<h4 id="第一行">第一行</h4>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rawFile = sc.textFile(<span class="string">"README.md"</span>)</span><br></pre></td></tr></table></figure>
<p>调用的SparkContext的textFile方法, 看源码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">textFile</span></span>(</span><br><span class="line">    path: <span class="type">String</span>,</span><br><span class="line">    minPartitions: <span class="type">Int</span> = defaultMinPartitions): <span class="type">RDD</span>[<span class="type">String</span>] = withScope &#123;</span><br><span class="line">  assertNotStopped()</span><br><span class="line">  hadoopFile(path, classOf[<span class="type">TextInputFormat</span>], classOf[<span class="type">LongWritable</span>], classOf[<span class="type">Text</span>],</span><br><span class="line">    minPartitions).map(pair =&gt; pair._2.toString).setName(path)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出此处先是hadoopFile方法读取hdfs上的一个README.md文件, 并生成了一个HadoopRDD, 随后又调用map方法, 生成了一个MapPartitionsRDD.</p>
<p>执行结果:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">scala&gt; val rawFile = sc.textFile(<span class="string">"README.md"</span>)</span><br><span class="line">rawFile: org.apache.spark.rdd.RDD[String] = README.md MapPartitionsRDD[3] at textFile at &lt;console&gt;:24</span><br></pre></td></tr></table></figure>
<h4 id="第二行">第二行</h4>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> words = rawFile.flatMap(w =&gt; w.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure>
<p>此处调用了MapPartitionsRDD继承自RDD类的flatMap方法, 源码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.flatMap(cleanF))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>flatMap方法可以将RDD中的每一个元素进行一对多转换, 所以此处使用flatMap方法将读入的内容按空格分割, 每个单词成为一个元素, 转变完仍为MapPartitionsRDD.</p>
<h4 id="第三行">第三行</h4>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> wordNum = words.map(w =&gt; (w, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>此处调用了MapPartitionsRDD继承自RDD类的map方法, 见源码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">U</span>): <span class="type">RDD</span>[<span class="type">U</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.map(cleanF))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>map方法将RDD中类型为T的元素一对一映射为类型为U的元素, 所以此处我们要统计的单个单词被转换为了(w, 1)形式的键值对, 进过此步转换仍为MapPartitionsRDD.</p>
<h4 id="第四行">第四行</h4>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> wordCount = wordNum.reduceByKey(_ + _)</span><br></pre></td></tr></table></figure>
<p>这次调用的reduceByKey方法不在RDD类里, 而在PairRDDFunctions类, 这里发生了一个隐式转换, 将MapPartitionsRDD转换成了PairRDDFunctions, 方法源码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)] = self.withScope &#123;</span><br><span class="line">  reduceByKey(defaultPartitioner(self), func)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>reduceByKey按key把相同单词加到一起, 得出每个单词出现的频率.</p>
<h4 id="第五行">第五行</h4>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">wordCount.collect</span><br></pre></td></tr></table></figure>
<p>到第四行为止, 所有任务并没有执行, 只到第五步, 调用RDD的collect方法, 会调用sc.runJob, 源码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">  <span class="keyword">val</span> results = sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.toArray)</span><br><span class="line">  <span class="type">Array</span>.concat(results: _*)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从这里开始生成Job并提交到Spark集群中运行, 至此才引出我们研究的重点, Job的整个调度过程.</p>
<p>此处调用的是SparkContext的runJob方法, 在SparkContext中重载了很多runJob方法, 通过一连串的runJob间调用, 设置了RDD, function, 分区数, 匿名函数转换等, 最后到了最重要的DAGScheduler.runJob.</p>
<h3 id="Jobd调度流程">Jobd调度流程</h3>
<h4 id="1-DAGScheduler提交Job">1. DAGScheduler提交Job</h4>
<p>DAGScheduler最重要的任务之一就是分析依赖关系划分Stage, 而发起job调度入口有两个, 一个是submitJob:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  <span class="comment">// Check to make sure we are not launching a task on a partition that does not exist.</span></span><br><span class="line">  <span class="keyword">val</span> maxPartitions = rdd.partitions.length</span><br><span class="line">  partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; <span class="number">0</span>).foreach &#123; p =&gt;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</span><br><span class="line">      <span class="string">"Attempting to access a non-existent partition: "</span> + p + <span class="string">". "</span> +</span><br><span class="line">        <span class="string">"Total number of partitions: "</span> + maxPartitions)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</span><br><span class="line">  <span class="keyword">if</span> (partitions.size == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Return immediately if the job is running 0 tasks</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  assert(partitions.size &gt; <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</span><br><span class="line">  <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">  eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">    <span class="type">SerializationUtils</span>.clone(properties)))</span><br><span class="line">  waiter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它返回一个JobWaiter对象, 可以用在异步调用中.<br>
另一个入口就是runJob:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</span><br><span class="line">  <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br><span class="line">  <span class="comment">// Note: Do not call Await.ready(future) because that calls `scala.concurrent.blocking`,</span></span><br><span class="line">  <span class="comment">// which causes concurrent SQL executions to fail if a fork-join pool is used. Note that</span></span><br><span class="line">  <span class="comment">// due to idiosyncrasies in Scala, `awaitPermission` is not actually used anywhere so it's</span></span><br><span class="line">  <span class="comment">// safe to pass in null here. For more detail, see SPARK-13747.</span></span><br><span class="line">  <span class="keyword">val</span> awaitPermission = <span class="literal">null</span>.asInstanceOf[scala.concurrent.<span class="type">CanAwait</span>]</span><br><span class="line">  waiter.completionFuture.ready(<span class="type">Duration</span>.<span class="type">Inf</span>)(awaitPermission)</span><br><span class="line">  waiter.completionFuture.value.get <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Success</span>(_) =&gt;</span><br><span class="line">      logInfo(<span class="string">"Job %d finished: %s, took %f s"</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Failure</span>(exception) =&gt;</span><br><span class="line">      logInfo(<span class="string">"Job %d failed: %s, took %f s"</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">      <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.</span></span><br><span class="line">      <span class="keyword">val</span> callerStackTrace = <span class="type">Thread</span>.currentThread().getStackTrace.tail</span><br><span class="line">      exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)</span><br><span class="line">      <span class="keyword">throw</span> exception</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>runJob在内部调用submitJob, 阻塞等待直到Job完成或失败.<br>
从submitJob方法里可以看到, 在此处向eventProcessLoop里发送了一个JobSubmitted的消息.<br>
那么eventProcessLoop是什么呢</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="keyword">val</span> eventProcessLoop = <span class="keyword">new</span> <span class="type">DAGSchedulerEventProcessLoop</span>(<span class="keyword">this</span>)</span><br></pre></td></tr></table></figure>
<p>这就是DAGScheduler自己维护的一个消息队列, 处理各种类型的消息, 当收到JobSubmitted消息时会调用handleJobSubmitted方法, 在这个方法里开始重要的第二步, 分析继承关系拆分Stages.</p>
<h4 id="2-拆分提交Stages">2. 拆分提交Stages</h4>
<p>在handleJobSubmitted方法中, 首先会根据这个RDD的信息计算出这个Job的所有Stages.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">      finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">      callSite: <span class="type">CallSite</span>,</span><br><span class="line">      listener: <span class="type">JobListener</span>,</span><br><span class="line">      properties: <span class="type">Properties</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></span><br><span class="line">      <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></span><br><span class="line">      finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">        logWarning(<span class="string">"Creating new stage failed due to exception - job: "</span> + jobId, e)</span><br><span class="line">        listener.jobFailed(e)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</span><br><span class="line">    clearCacheLocs()</span><br><span class="line">    logInfo(<span class="string">"Got job %s (%s) with %d output partitions"</span>.format(</span><br><span class="line">      job.jobId, callSite.shortForm, partitions.length))</span><br><span class="line">    logInfo(<span class="string">"Final stage: "</span> + finalStage + <span class="string">" ("</span> + finalStage.name + <span class="string">")"</span>)</span><br><span class="line">    logInfo(<span class="string">"Parents of final stage: "</span> + finalStage.parents)</span><br><span class="line">    logInfo(<span class="string">"Missing parents: "</span> + getMissingParentStages(finalStage))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</span><br><span class="line">    jobIdToActiveJob(jobId) = job</span><br><span class="line">    activeJobs += job</span><br><span class="line">    finalStage.setActiveJob(job)</span><br><span class="line">    <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</span><br><span class="line">    <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</span><br><span class="line">    listenerBus.post(</span><br><span class="line">      <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</span><br><span class="line">    submitStage(finalStage)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>可以看到createResultStage方法, 生成了一个ResultStage, 代码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Create a ResultStage associated with the provided jobId.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createResultStage</span></span>(</span><br><span class="line">      rdd: <span class="type">RDD</span>[_],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">      jobId: <span class="type">Int</span>,</span><br><span class="line">      callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> parents = getOrCreateParentStages(rdd, jobId)</span><br><span class="line">    <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">    <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parents, jobId, callSite)</span><br><span class="line">    stageIdToStage(id) = stage</span><br><span class="line">    updateJobIdStageIdMaps(jobId, stage)</span><br><span class="line">    stage</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>其中getOrCreateParentStages方法根据依赖关系拆分了Stage, 返回了一个List[Stage]又传入了ResultStage中, 拆分Stage部分的代码我就不贴出来了, 感兴趣可以自行阅读.<br>
handleJobSubmitted方法中得到finalStage后, 进行了一系列操作, 构建ActiveJob, 启动Job, 最后提交了Stage, 准备开始生成真正下发执行的Task任务.</p>
<p>那么看submitStage方法:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Submits stage, but first recursively submits any missing parents. */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">    <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">      logDebug(<span class="string">"submitStage("</span> + stage + <span class="string">")"</span>)</span><br><span class="line">      <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">        <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">        logDebug(<span class="string">"missing: "</span> + missing)</span><br><span class="line">        <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">          logInfo(<span class="string">"Submitting "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">"), which has no missing parents"</span>)</span><br><span class="line">          submitMissingTasks(stage, jobId.get)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">            submitStage(parent)</span><br><span class="line">          &#125;</span><br><span class="line">          waitingStages += stage</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      abortStage(stage, <span class="string">"No active job for stage "</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>递归提交Stage, 有parent的先提交parent, 没有parent的才开始生成Task.</p>
<h4 id="3-创建提交Task">3. 创建提交Task</h4>
<p>创建提交Task调用的是submitStage方法里的submitMissingTasks方法, 这个方法代码比较长, 我就不全部贴出来了.<br>
Stage分ShuffleMapStage和ResultStage, Task也分为ShuffleMapTask和ResultTask两种, 方法里导出都是模式匹配分别处理这两种Stage, 关键生成Task的代码如下:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">      stage <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">          partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(id)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</span><br><span class="line">              taskBinary, part, locs, stage.latestInfo.taskMetrics, properties, <span class="type">Option</span>(jobId),</span><br><span class="line">              <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">          partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(p)</span><br><span class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</span><br><span class="line">              taskBinary, part, locs, id, properties, stage.latestInfo.taskMetrics,</span><br><span class="line">              <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId)</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">        abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>"</span>, <span class="type">Some</span>(e))</span><br><span class="line">        runningStages -= stage</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>生成Task之后通过TaskScheduler把Task提交.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">        tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))</span><br></pre></td></tr></table></figure>
<p>submitTasks方法的实现在TaskSchedulerimpl.scala, 这里首先创建了一个TaskSetManager来辅助调度, 然后调用了SchedulerBackend的reviveOffers方法去申请资源.</p>
<h4 id="4-分配executors">4. 分配executors</h4>
<p>这里reviveOffers方法的实现跳到了CoarseGrainedSchedulerBackend.scala文件:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>() &#123;</span><br><span class="line">    driverEndpoint.send(<span class="type">ReviveOffers</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>此处发送了一条ReviveOffers消息, 被自身接收到然后继续处理:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ReviveOffers</span> =&gt;</span><br><span class="line">        makeOffers()</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>makeOffers方法很重要, 这里调用了resourceOffers方法去获取当前可用的资源信息, 而当前正在执行的多个TaskSet会根据这些资源信息将当前可执行的Task和这个Task要运行在哪个executor上包装到一个TaskDescription中返回回来, 再调用launchTasks正式把Task推倒executor端去执行.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>(executorId: <span class="type">String</span>) &#123;</span><br><span class="line">      <span class="comment">// Filter out executors under killing</span></span><br><span class="line">      <span class="keyword">if</span> (executorIsAlive(executorId)) &#123;</span><br><span class="line">        <span class="keyword">val</span> executorData = executorDataMap(executorId)</span><br><span class="line">        <span class="keyword">val</span> workOffers = <span class="type">IndexedSeq</span>(</span><br><span class="line">          <span class="keyword">new</span> <span class="type">WorkerOffer</span>(executorId, executorData.executorHost, executorData.freeCores))</span><br><span class="line">        launchTasks(scheduler.resourceOffers(workOffers))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Launch tasks returned by a set of resource offers</span></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchTasks</span></span>(tasks: <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]]) &#123;</span><br><span class="line">      <span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;</span><br><span class="line">        <span class="keyword">val</span> serializedTask = ser.serialize(task)</span><br><span class="line">        <span class="keyword">if</span> (serializedTask.limit &gt;= maxRpcMessageSize) &#123;</span><br><span class="line">          scheduler.taskIdToTaskSetManager.get(task.taskId).foreach &#123; taskSetMgr =&gt;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">var</span> msg = <span class="string">"Serialized task %s:%d was %d bytes, which exceeds max allowed: "</span> +</span><br><span class="line">                <span class="string">"spark.rpc.message.maxSize (%d bytes). Consider increasing "</span> +</span><br><span class="line">                <span class="string">"spark.rpc.message.maxSize or using broadcast variables for large values."</span></span><br><span class="line">              msg = msg.format(task.taskId, task.index, serializedTask.limit, maxRpcMessageSize)</span><br><span class="line">              taskSetMgr.abort(msg)</span><br><span class="line">            &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; logError(<span class="string">"Exception in error callback"</span>, e)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> executorData = executorDataMap(task.executorId)</span><br><span class="line">          executorData.freeCores -= scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line"></span><br><span class="line">          logDebug(<span class="string">s"Launching task <span class="subst">$&#123;task.taskId&#125;</span> on executor id: <span class="subst">$&#123;task.executorId&#125;</span> hostname: "</span> +</span><br><span class="line">            <span class="string">s"<span class="subst">$&#123;executorData.executorHost&#125;</span>."</span>)</span><br><span class="line"></span><br><span class="line">          executorData.executorEndpoint.send(<span class="type">LaunchTask</span>(<span class="keyword">new</span> <span class="type">SerializableBuffer</span>(serializedTask)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>在launchTasks方法中才把executors资源真的分配给Task并把分配掉的资源扣除, 然后把Task序列化后发送往executor端.</p>
<h4 id="5-executor执行Task">5. executor执行Task</h4>
<p>接下来程序就运行到了CoarseGrainedExecutorBackend.scala的receive方法, 这里接收到driver端发来的LaunchTask消息开始触发执行, 关键代码:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">LaunchTask</span>(data) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;</span><br><span class="line">        exitExecutor(<span class="number">1</span>, <span class="string">"Received LaunchTask command but executor was null"</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> taskDesc = ser.deserialize[<span class="type">TaskDescription</span>](data.value)</span><br><span class="line">        logInfo(<span class="string">"Got assigned task "</span> + taskDesc.taskId)</span><br><span class="line">        executor.launchTask(<span class="keyword">this</span>, taskId = taskDesc.taskId, attemptNumber = taskDesc.attemptNumber,</span><br><span class="line">          taskDesc.name, taskDesc.serializedTask)</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>这里首先把Task反序列化, 然后交给Executor.scala的launchTask方法:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">launchTask</span></span>(</span><br><span class="line">      context: <span class="type">ExecutorBackend</span>,</span><br><span class="line">      taskId: <span class="type">Long</span>,</span><br><span class="line">      attemptNumber: <span class="type">Int</span>,</span><br><span class="line">      taskName: <span class="type">String</span>,</span><br><span class="line">      serializedTask: <span class="type">ByteBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tr = <span class="keyword">new</span> <span class="type">TaskRunner</span>(context, taskId = taskId, attemptNumber = attemptNumber, taskName,</span><br><span class="line">      serializedTask)</span><br><span class="line">    runningTasks.put(taskId, tr)</span><br><span class="line">    threadPool.execute(tr)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>这里new了一个TaskRunner, 继续执行TaskRunner的run方法, run方法代码很长就不贴了, 这里就是具体执行Task的实现, 可以自己去看源码.</p>
<h4 id="6-执行结果返回">6. 执行结果返回</h4>
<p>当run方法执行完以后, 把结果数据序列化返回, 如果数据过大, 就把数据写磁盘返回数据的位置, 通过statusUpdate方法回传给<br>
CoarseGrainedExecutorBackend.scala, executorBackend再发送了一条StatusUpdate消息把结果返回给了CoarseGrainedSchedulerBackend.scala</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">StatusUpdate</span>(executorId, taskId, state, data) =&gt;</span><br><span class="line">        scheduler.statusUpdate(taskId, state, data.value)</span><br><span class="line">        <span class="keyword">if</span> (<span class="type">TaskState</span>.isFinished(state)) &#123;</span><br><span class="line">          executorDataMap.get(executorId) <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="type">Some</span>(executorInfo) =&gt;</span><br><span class="line">              executorInfo.freeCores += scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line">              makeOffers(executorId)</span><br><span class="line">            <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">              <span class="comment">// Ignoring the update since we don't know about the executor.</span></span><br><span class="line">              logWarning(<span class="string">s"Ignored task status update (<span class="subst">$taskId</span> state <span class="subst">$state</span>) "</span> +</span><br><span class="line">                <span class="string">s"from unknown executor with ID <span class="subst">$executorId</span>"</span>)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>driver端收到消息后, 先把结果传给了TaskScheduler, 然后释放了executor资源.<br>
接下来到TaskScheduler之后调用比较绕, 首先把Task清理掉, 然后使用TaskResultGetter来处理结果:</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="type">TaskState</span>.isFinished(state)) &#123;</span><br><span class="line">              cleanupTaskState(tid)</span><br><span class="line">              taskSet.removeRunningTask(tid)</span><br><span class="line">              <span class="keyword">if</span> (state == <span class="type">TaskState</span>.<span class="type">FINISHED</span>) &#123;</span><br><span class="line">                taskResultGetter.enqueueSuccessfulTask(taskSet, tid, serializedData)</span><br><span class="line">              &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="type">Set</span>(<span class="type">TaskState</span>.<span class="type">FAILED</span>, <span class="type">TaskState</span>.<span class="type">KILLED</span>, <span class="type">TaskState</span>.<span class="type">LOST</span>).contains(state)) &#123;</span><br><span class="line">                taskResultGetter.enqueueFailedTask(taskSet, tid, state, serializedData)</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<p>在TaskResultGetter中判断结果数据的存放位置, 如果在内存中就直接取结果, 如果在磁盘, 就根据blockid信息去对应机器上拉取数据, 然后放到driver的内存, 最后调用handleSuccessfulTask方法把结果返回给TaskScheduler.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">scheduler.handleSuccessfulTask(taskSetManager, tid, result)</span><br></pre></td></tr></table></figure>
<p>接下来用到了之前辅助调度创建的TaskSetManager</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleSuccessfulTask</span></span>(</span><br><span class="line">      taskSetManager: <span class="type">TaskSetManager</span>,</span><br><span class="line">      tid: <span class="type">Long</span>,</span><br><span class="line">      taskResult: <span class="type">DirectTaskResult</span>[_]): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">    taskSetManager.handleSuccessfulTask(tid, taskResult)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>TaskScheduler调用TaskSetManager, TaskSetManager再调用DAGScheduler, 并将结果数据返回给了DAGScheduler.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">sched.dagScheduler.taskEnded(tasks(index), <span class="type">Success</span>, result.value(), result.accumUpdates, info)</span><br></pre></td></tr></table></figure>
<p>taskEnded方法向DAGScheduler维护的队列里发送了一个CompletionEvent消息, 来触发DAGScheduler的handleTaskCompletion方法来数据数据.<br>
handleTaskCompletion方法里会判断这是一个ShuffleMapTask还是一个ResultTask, 如果是ShuffleMapTask则继续提交下一个Stage, 如果是ResultTask, 则会通过以下代码把结果交给JobWaiter.</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">job.listener.taskSucceeded(rt.outputId, event.result)</span><br></pre></td></tr></table></figure>
<p>JobWaiter最后做一些处理, 然后把结果一路返回给调用SparkContext.runJob的地方, 至此整个Job调度就完成了.</p>
<h3 id="总结">总结</h3>
<p>下面用几张图做一个总结:</p>
<p>Job的调度执行流程</p>
<p><img src="http://www.wangdanpeng.com/img/Job%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png" alt="整个Job的执行流程"></p>
<p>Job提交执行期间的函数调用<br>
<img src="http://www.wangdanpeng.com/img/Job%E6%89%A7%E8%A1%8C%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B.png" alt="此处输入图片的描述"></p>
<p>ps:<br>
最近学习Spark的Job调度过程, 看了一遍源码后发现扭头就忘, 所以就整理了下来. Spark代码实在量太大, Job执行的有些细节实现也没自己研究, 只是把大体流程梳理了下来, 如有错误欢迎指正.</p>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>WordCount</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown常用样式</title>
    <url>/2022/02/09/20220209185324/</url>
    <content><![CDATA[<h1 id="可表示1-6级标题"># 可表示1-6级标题</h1>
<p><em>斜体</em> : *斜体*<br>
<strong>粗体</strong> : **粗体**<br>
<em><strong>粗体加斜体</strong></em> : ***粗体***</p>
<p>🐫 😊 😄 : :smil\e:(去掉斜线)<br>
分割线(下面这条) : ---</p>
<hr>
<p><sup>上角标</sup> : ^上角标^<br>
<sub>下角标</sub> : ~下角标~<br>
<s>删除线</s> : ~~删除线~~<br>
<u> 下划线 </u> : &lt;u&gt;下划线&lt;/u&gt;</p>
<hr>
<ul>
<li>无序列表 : - 无序列表</li>
</ul>
<ol>
<li>有序列表 : 1. 有序列表</li>
</ol>
<p><input type="checkbox" id="checkbox1"><label for="checkbox1"> 代办列表 : [ ]代办列表(hexo语法), csdn写法为 - [ ]</label><br>
<input type="checkbox" id="checkbox0" checked="true"><label for="checkbox0"> 已完成 : [x]已完成(hexo语法)</label></p>
<blockquote>
<p>区块 : &gt; 区块</p>
</blockquote>
<blockquote>
<blockquote>
<p>可以嵌套 : &gt;&gt; 可以嵌套</p>
</blockquote>
</blockquote>
<p><code>代码</code> : `代码`</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">代码段 : \&#96;\&#96;\&#96;代码段\&#96;\&#96;\&#96;(删掉斜杠)</span><br></pre></td></tr></table></figure>
<p><a href="%E7%BD%91%E5%9D%80">链接</a> : [链接](网址)<br>
<img src="https://img-blog.csdnimg.cn/c8e32cf4043a496ab84ed8e64b684d02.png#pic_center" alt="图片"></p>
<p>图片 : ![描述](网址), 注意某些网址不适用, 比如csdn</p>
<p>其他html元素<br>
<kbd>Ctrl</kbd> : &lt;kbd&gt;Ctrl&lt;/kbd&gt;<br>
\ : 转义</p>
<hr>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mo>−</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">f(x)=a-b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">a</span><span class="mbin">−</span><span class="mord mathit">b</span></span></span></span> : $f(x)=a-b$</p>
<p>$\$f(x)=a+b$\$(删掉斜杠) 如下</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">f(x)=a+b
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">a</span><span class="mbin">+</span><span class="mord mathit">b</span></span></span></span></span></p>
<hr>
<p>高级公式和矩阵用到了自己去搜<br>
还支持各种流程图</p>
<h1 id="更换hexo默认md渲染器">更换hexo默认md渲染器</h1>
<p>hexo默认采用<code>hexo-renderer-marked</code>渲染器, 不支持插件, 上述例子中部分不支持, 下面一个一个解决</p>
<ul>
<li>
<p>更换渲染器<br>
换成支持插件扩展的<code>hexo-renderer-markdown-it</code>, 在hexo项目目录下执行以下命令</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line">npm i hexo-renderer-markdown-it --save</span><br><span class="line"># 安装emoji插件</span><br><span class="line">npm install markdown-it-emoji --save</span><br><span class="line"># 安装数学公式插件</span><br><span class="line">npm install markdown-it-katex --save</span><br><span class="line"># 安装待办事项插件</span><br><span class="line">npm install markdown-it-checkbox --save</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>编辑hexo项目配置文件<br>
项目根目录下的<code>_config.yml</code>, 添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Markdown-it config</span><br><span class="line">## Docs: https:&#x2F;&#x2F;github.com&#x2F;celsomiranda&#x2F;hexo-renderer-markdown-it&#x2F;wiki</span><br><span class="line">markdown:</span><br><span class="line">render:</span><br><span class="line">  html: true          # 是否对HTML标签进行解析，false时HTML将按照原样输出</span><br><span class="line">  xhtmlOut: false     # 是否需要满足严格的XHTML格式，换行为&lt;br &#x2F;&gt;</span><br><span class="line">  breaks: true</span><br><span class="line">  linkify: true</span><br><span class="line">  typographer: true</span><br><span class="line">  quotes: &#39;“”‘’&#39;</span><br><span class="line">plugins:</span><br><span class="line">  - markdown-it-abbr</span><br><span class="line">  - markdown-it-footnote</span><br><span class="line">  - markdown-it-ins</span><br><span class="line">  - markdown-it-sub</span><br><span class="line">  - markdown-it-sup</span><br><span class="line">  - markdown-it-emoji  # add emoji</span><br><span class="line">  - markdown-it-katex</span><br><span class="line">  - markdown-it-checkbox</span><br><span class="line">anchors:</span><br><span class="line">  # Minimum level for ID creation. (Ex. h2 to h6)</span><br><span class="line">  level: 2</span><br><span class="line">  # A suffix that is prepended to the number given if the ID is repeated.</span><br><span class="line">  collisionSuffix: &#39;v&#39;</span><br><span class="line">  # If &#96;true&#96;, creates an anchor tag with a permalink besides the heading.</span><br><span class="line">  permalink: false</span><br><span class="line">  # Class used for the permalink anchor tag.</span><br><span class="line">  permalinkClass: header-anchor</span><br><span class="line">  # The symbol used to make the permalink</span><br><span class="line">  permalinkSymbol: ¶</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>另外<br>
安装数学公式插件, 需要在主题的模板文件中加一行代码, 路径大概在</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">themes&#x2F;next&#x2F;layout&#x2F;_partial&#x2F;head.swig</span><br></pre></td></tr></table></figure>
<p>加入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;link href&#x3D;&quot;https:&#x2F;&#x2F;cdn.bootcss.com&#x2F;KaTeX&#x2F;0.7.1&#x2F;katex.min.css&quot; rel&#x3D;&quot;stylesheet&quot;&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql-输入Emoji表情</title>
    <url>/2017/02/26/20170226152115/</url>
    <content><![CDATA[<p>之前开发app遇到过一个问题, 用户发表评论里如果带有Emoji表情就会失败,查看日志数据库会报如下错误:</p>
<pre><code>java.sql.SQLException: Incorrect string value: '\xF0\x9F\x98\x97\xF0\x9F...' for column 'CONTENT' at row 1
</code></pre>
<p>网上搜了一圈说是字符集的问题, 详细解释在这里 -&gt; <a href="http://blog.csdn.net/qdkfriend/article/details/7576524" target="_blank" rel="noopener">Emoji表情符号兼容方案</a><br>
既然说了utf8的字符集不行, 那就去改字符集, 统统改成utf8mb4.</p>
<p>1.先去修改表字段字符集为utf8mb4:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">MODIFY</span> <span class="string">`字段名`</span> <span class="built_in">TEXT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci<span class="string">';</span></span><br></pre></td></tr></table></figure>
<p>2.再去修改表字符集utf8mb4:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 表名 <span class="keyword">CHARSET</span>=utf8mb4;</span><br></pre></td></tr></table></figure>
<p>3.再去配饰文件my.ini修改数据库的字符集utf8mb4:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">init-connect&#x3D;&#39;SET NAMES utf8mb4&#39;</span><br><span class="line">character-set-server&#x3D;utf8mb4</span><br></pre></td></tr></table></figure>
<p>三步完成后重启mysql服务, 再查看数据库字符集</p>
<pre><code>mysql&gt; show variables like '%char%';
</code></pre>
<p>±-------------------------±---------------------------------+<br>
| Variable_name            | Value                            |<br>
±-------------------------±---------------------------------+<br>
| character_set_client     | utf8mb4                          |<br>
| character_set_connection | utf8mb4                          |<br>
| character_set_database   | utf8mb4                          |<br>
| character_set_filesystem | binary                           |<br>
| character_set_results    | utf8mb4                          |<br>
| character_set_server     | utf8mb4                          |<br>
| character_set_system     | utf8                             |<br>
| character_sets_dir       | /usr/local/mysql/share/charsets/ |<br>
±-------------------------±---------------------------------+</p>
<p>再发表情测试通过!到此一切搞定收工.</p>
<p>(ps:如果以上方法下来并没有成功的话, 一定是你的mysql配置没放好, 那么请参考下面这篇文章, 绝对妥妥的 -&gt; <a href="http://www.cnblogs.com/HondaHsu/p/3640180.html" target="_blank" rel="noopener">如何修改MySQL字符集</a>)</p>
<p>下面是一些相关命令:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--修改数据库字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">DATABASE</span> <span class="string">`数据库名`</span> <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--把表默认的字符集和所有字符列改为新的字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span> <span class="keyword">CONVERT</span> <span class="keyword">TO</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--只修改表的默认字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span> <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--修改字段的字符集</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span> <span class="keyword">CHANGE</span> <span class="string">`字段名`</span> <span class="string">`字段名`</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> <span class="string">`字符集名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--查看数据库编码</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="string">`数据库名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--查看表编码</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`表名`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--查看字段编码</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">FULL</span> <span class="keyword">COLUMNS</span> <span class="keyword">FROM</span> <span class="string">`表名`</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Emoji</tag>
      </tags>
  </entry>
  <entry>
    <title>VS Code-常用插件</title>
    <url>/2019/05/11/VS-Code-%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>久闻vs code比sublime text要好用, 感觉sublime text已经够好用了, 一直懒得换, 今天下载vs code试用了一下, 感觉嗯~ 真香~</p>
<p>初次使用先安装了一些常用插件, 以后如有进阶插件再持续更新</p>
<h2 id="0-插件安装方法">0. 插件安装方法</h2>
<p>不得不说, vs code插件安装比sublime text要更优雅, 左侧工具栏直接提供了插件安装选项(最下面的方块块), 直接搜索插件名, 可以查看各个插件的使用说明, 安装次数等等信息, 顿时好感爆棚</p>
<h2 id="1-vim">1. vim</h2>
<p>平时和服务器打交道多, 习惯vim操作一切, 编辑器当然也是必须vim模式走起, 直接搜<strong>vim</strong>, 目前版本1.8.0, 690w人次安装</p>
<h2 id="2-图标">2. 图标</h2>
<p>由于平时打开的文件夹和文件比较多, 习惯装一个图标插件, 能美化图标的显示, 这里选择的是<strong>vscode-icons</strong>, 版本8.6.0, 1500w人次安装</p>
<h2 id="3-json格式化工具">3. json格式化工具</h2>
<p>平时处理json格式数据也比较多, 经常需要格式化, 每次打开格式化网站也很麻烦, 不如插件来的实在, 这里选择的<strong>JSON Tools</strong>, 版本1.0.2, 26w人次安装, 后续有更好用的再换</p>
<h2 id="4-Markdown工具">4. Markdown工具</h2>
<p>vs code原本就支持写markdown的实时预览, 只要把文件保存成**.md<strong>后缀, 在右上角就会有一个分屏带放大镜的图标, 点击就可以, 不过黑色主题下预览也是黑色, 有些格式看起来不舒服, 所以我选择</strong>Markdown Preview Enhanced**, 版本0.3.13, 110w人次安装</p>
<p>同时, 想要规范自己写的md格式, 可以一起安装一个<strong>markdownlint</strong>, 根据他的数条规则发起检查, 格式不规范的地方就会划绿色波浪线, 助你写出完美md, 版本0.26.0, 437w人次安装</p>
<h2 id="5-颜色主题">5. 颜色主题</h2>
<p>直接<strong>cmd + shift + p</strong>在输入框输入<strong>color theme</strong>, 就有多种自带主题供你选择, 不过我又另外多安装了一个<strong>One Dark Pro</strong>主题, 可以搜索看一下适不适合你, 版本2.22.1, 1000w人次安装</p>
<h2 id="6-编程语言插件">6. 编程语言插件</h2>
<p>这个就不过多介绍, 对应安装自己常用的语言, 比如我的<strong>Scala</strong>和<strong>Python</strong></p>
<h2 id="7-最后的骚操作">7. 最后的骚操作</h2>
<p>最骚的来了, vs code居然有简体中文包…<br>
直接搜索<strong>Chinese</strong>就可以, 版本1.33.2, 560w人次安装</p>
]]></content>
      <categories>
        <category>VS Code</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>VS Code</tag>
      </tags>
  </entry>
  <entry>
    <title>微信开发, 经纬度转地址问题</title>
    <url>/2017/02/18/20170218155323/</url>
    <content><![CDATA[<blockquote>
<p>之前搞微信二次开发遇见过一个超级大坑, 根据微信提供的接口, 获取到的经纬度, 不知道是什么坐标系的(ps: 各个地图使用的坐标系不一, 自行百度), 我把得到的经纬度放到百度.腾讯.高德地图里, 得到的位置都有很大的偏差, 后来绞尽脑汁, 发帖加群各种求助, 无意间发现一篇文章, 特此分享一下, 以防以后有人遇到同样的问题不用像我一样彷徨.</p>
</blockquote>
<p>这是原文 <a href="http://www.weixin66.net/newsshow.php?cid=4&amp;id=7" target="_blank" rel="noopener">微信如何根据经纬度坐标查询具体地理位置</a></p>
<p>微信获取到的经纬度是GPS坐标, 知道这个一切就好办了, 下一步只要要一个GPS坐标转换的接口就可以了.</p>
<p>我一开始用的上面链接里的接口, 然而用的好好的有一天突然服务挂了, 最后发现他的接口403了.</p>
<p>然后我就找到了下面这个不错的网站, 看他们的合作伙伴还有CSDN, 应该还算靠谱, 从我发现这个网站距今已经快三年了, 它还在, 所以…</p>
<p>废话不多说, 上链接 <a href="http://www.zdoz.net/index.html" target="_blank" rel="noopener">各种地图接口</a></p>
]]></content>
      <categories>
        <category>微信</category>
      </categories>
      <tags>
        <tag>地图</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark-断点调试</title>
    <url>/2017/03/12/20170312193459/</url>
    <content><![CDATA[<p>我是用idea + spark-shell断点调试spark源码的, 可以一行代码一行代码的追执行过程, 很是方便, 学习Spark源码必备.</p>
<h4 id="准备工作-v2">准备工作</h4>
<p>首先肯定是要把Spark的源码准备好, 并且导入到idea里, 从哪下Spark源码和怎么导入到idea里我就不详细解释了.<br>
另外启动Spark需要Hadoop和Hive的支持, 首先要把这两个服务搭好启动起来, 关于这部分本篇文章暂且不讲, 请自行百度.</p>
<h4 id="设置idea的debug配置">设置idea的debug配置</h4>
<p><img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95%281%29.png" alt="此处输入图片的描述"><br>
点击Edit Configuration去添加调试.<br>
<img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%94%B5%E8%B0%83%E8%AF%95%282%29.png" alt="此处输入图片的描述"><br>
然后点击左上角的加号, 在列表中选择Remote选项<br>
<img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95%283%29.png" alt="此处输入图片的描述"><br>
创建出来的这些东西什么设置都不用动, 可以把Name改一个自己好记的, 比如我的local Spark, 划红线的部分就是一会要使用的.</p>
<h4 id="启动spark-shell">启动spark-shell</h4>
<p>进入Spark的bin目录下执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./spark-shell -h</span><br></pre></td></tr></table></figure>
<p>可以看到spark-shell启动时可以指定个各种参数, 其中我们要用到的有以下两个:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--master MASTER_URL         spark://host:port, mesos://host:port, yarn, or local.</span><br><span class="line"></span><br><span class="line">--driver-java-options       Extra Java options to pass to the driver.</span><br></pre></td></tr></table></figure>
<p>master参数, 指定启动方式, 我们起本地模式, 所以用local.<br>
driver-java-options参数, driver端的一些java参数, 就是刚才划红线的部分.</p>
<p>那么启动命令拼起来就是这样的:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./spark-shell --master local --driver-java-options -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005</span><br></pre></td></tr></table></figure>
<p>敲回车启动以后可以看到这么一句话</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Listening for transport dt_socket at address: 5005</span><br></pre></td></tr></table></figure>
<p>表示已经开始监听5005端口, 接下来去启动idea.</p>
<h4 id="启动idea">启动idea</h4>
<p><img src="http://www.wangdanpeng.com/img/Spark-%E6%96%AD%E7%82%B9%E8%B0%83%E8%AF%95%284%29.png" alt="此处输入图片的描述"><br>
再回到图一的位置, 选择上刚才创建的local Spark, 然后点击旁边的debug按钮, 就正式进入debug模式了, 现在就可以随心所欲的打断点调试Spark了.</p>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis-关于Mapped Statements collection does not contain value for错误</title>
    <url>/2017/02/18/20170218194929/</url>
    <content><![CDATA[<p>使用Mybatis时不时会遇到一下这种报错:</p>
<pre><code>Mapped Statements collection does not contain value for XXX
</code></pre>
<p>错误原因有以下几种:</p>
<ul>
<li>mapper.xml中没有加入namespace</li>
<li>mapper.xml中的方法和接口mapper的方法不对应</li>
<li>mapper.xml没有加入到mybatis-config.xml中(即总的配置文件)，例外：配置了mapper文件的包路径的除外</li>
<li>mapper.xml文件名和所写的mapper名称不相同</li>
</ul>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>ERROR</tag>
      </tags>
  </entry>
  <entry>
    <title>工具-破解pdf密码</title>
    <url>/2019/05/14/%E5%B7%A5%E5%85%B7-%E7%A0%B4%E8%A7%A3pdf%E5%AF%86%E7%A0%81/</url>
    <content><![CDATA[<p>今天偶得一份久仰的学习资料.pdf, 一打开却发现要输入密码, 试来试去密码都不对, 寻遍google找到了一个神器~</p>
<h2 id="pdfcrack">pdfcrack</h2>
<p>官方网站 -&gt; <a href="http://pdfcrack.sourceforge.net/" target="_blank" rel="noopener">pdfcrack</a>, 目前版本0.17</p>
<h3 id="第一步-Download">第一步 Download</h3>
<p>下载下来以后是一个压缩包, 解压以后一堆c语言文件<br>
<img src="http://www.wangdanpeng.com/img/20190514193611-1.png" alt="1"></p>
<h3 id="第二步-编译">第二步 编译</h3>
<p>在解压后的文件夹里执行<strong>make</strong>, 成功后得出上图中红色的<strong>pdfcrack</strong>可执行文件</p>
<h3 id="第三步-暴力破解">第三步 暴力破解</h3>
<p>执行pdfcrack 后跟pdf路径, 如图中的测试文件123.pdf, 几秒钟后得到密码<strong>168</strong><br>
<img src="http://www.wangdanpeng.com/img/20190514193611-2.png" alt="2"></p>
<p>最后, 想偷懒的可以直接下载我编译好的执行文件 -&gt; <a href="http://www.wangdanpeng.com/jars/pdfcrack">传送门</a></p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>pdf</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(七) - 文件系统</title>
    <url>/2021/11/03/20211103194440/</url>
    <content><![CDATA[<h2 id="文件系统">文件系统</h2>
<h3 id="文件系统的概念">文件系统的概念</h3>
<p><strong>文件系统</strong>: 是操作系统中管理持久性数据的子系统, 提供数据存储和访问功能, 组织, 检索, 读写访问数据<br>
<strong>文件</strong>: 是具有符号名, 由字节序列构成的数据项集合, 是文件系统的基本数据单位, 文件名是文件的标识符号<br>
文件系统的功能<br>
分配文件磁盘空间: 管理文件块(位置和顺序), 管理空闲空间(位置), 分配算法(策略)<br>
管理文件集合: 定位(文件及其内容), 命名(通过名字找到文件), 文件系统结构(文件组织方式)<br>
数据可靠和安全: 安全(多层次保护数据安全), 可靠(持久保存, 避免系统崩溃, 攻击等)<br>
文件属性包括: 名称, 类型, 位置, 大小, 保护, 创建者, 创建时间, 最近修改时间…<br>
文件信息分为两个部分, 一部分是文件头, 存在文件系统元数据当中的文件信息, 主要是文件属性和文件存储位置和顺序</p>
<h3 id="文件描述符">文件描述符</h3>
<p><strong>文件描述符</strong>: 打开的文件在内存中维护的相关信息<br>
打开文件的过程: 内核跟踪进程打开的所有文件, 操作系统为每个进程维护一个打开文件表, 文件描述符是打开文件表的标识<br>
操作系统在打开文件表中维护的打开文件状态和信息, 包括<br>
文件指针: 最近一次读写位置, 每个进程分别维护自己的打开文件指针<br>
文件打开计数: 当前打开文件的次数, 最后一个进程关闭文件时, 将其从打开文件表中移除<br>
文件的磁盘位置: 缓存数据访问信息<br>
访问权限: 每个进程的文件访问模式信息</p>
<p>文件的用户视图: 用户进程看到的样子, 持久的数据结构<br>
文件的系统视图: 数据块的集合, 系统不关心存储在磁盘上的数据的结构, 数据块是逻辑存储单元, 扇区是物理存储单元, 通常几个扇区构成一个数据块<br>
文件系统中的基本操作单位是数据块<br>
进程读文件 -&gt; 获取字节所在的数据块, 返回数据块内对应部分<br>
进程写文件 -&gt; 获取数据块, 修改数据块中对应部分, 写回数据块<br>
访问模式<br>
顺序访问: 按字节依次读取, 大多数的文件访问都是<br>
随机访问: 从中间读写, 不常用但重要, 比如虚拟内存中把内存页存储在文件<br>
索引访问: 依据数据特征索引, 通常操作系统不完整提供索引访问<br>
文件内部结构有: 无结构, 单词/字节序列, 简单记录结构, 分列, 固定长度, 可变长度, 复杂结构, 格式化文档, 可执行文件等</p>
<h3 id="目录-文件别名和文件系统种类">目录, 文件别名和文件系统种类</h3>
<p>文件数量多了以后, 需要以目录的方式组织起来, 目录是一种特殊的文件, 目录的内容是文件索引表&lt;文件名, 指向文件的指针&gt;<br>
目录操作有, 搜索/创建/删除文件, 列目录, 重命名文件, 遍历路径, 操作系统只允许内核修改目录以确保映射的完整性, 用户通过系统调用访问目录<br>
目录的实现两种实现方式: 线性列表(数据量很大以后, 检索和增删时间变长, 但编程简单), 哈希表(减少目录搜索时间,但可能冲突需要有解决方案)<br>
文件别名: 两个或多个文件名关联同一个文件<br>
硬链接: 多个文件项指向一个文件, 删到最后一个指向它的文件名才会把文件实体删掉<br>
软链接: 以快捷方式指向其他文件, 存的另一个文件的完整路径, 删除别名文件不受任何影响<br>
名字解析(路径遍历): 把逻辑名字转换成物理资源, 比如文件, 依据路径名, 在文件系统中找到实际文件位置, 遍历文件目录直到找到目标文件<br>
举例解析/bin/ls, 读取根目录的文件头(在磁盘固定位置), 读取根目录的数据块, 搜索bin, 读取bin的文件头, 读取bin的数据块, 搜索ls, 读取ls文件头<br>
当前工作目录(pwd): 每个进程都会指向一个文件目录用于解析文件名, 允许用户指定相对路径来代替绝对路径<br>
文件系统挂载: 文件系统需要先挂载才能被访问, 未挂载的文件系统被挂载在挂载点上<br>
文件系统种类: 磁盘文件系统, 数据库文件系统, 日志文件系统, 网络/分布式文件系统, 特殊/虚拟文件系统<br>
文件缓存: 操作系统中讨论的文件缓存是内存中的数据块缓存, 数据块按需读入内存, 预读会预先读取后面的数据块, 数据块使用后被缓存, 假设数据块会再次用到, 写操作也可能被缓存和延迟写入<br>
两种缓存方式, 数据块缓存, 页缓存</p>
<h3 id="文件分配">文件分配</h3>
<p>大多数文件都很小, 块空间不能太大, 需要对小文件提供很好的支持, 而一些文件非常大, 必须支持大文件, 大文件访问需要高效<br>
文件分配研究如何表示分配给一个文件数据块的位置和顺序<br>
分配方式有:<br>
连续分配: 文件头指定起始块和长度, 文件读取表现好, 高效的顺序和随机访问, 但有碎片, 和文件增长问题<br>
链式分配: 文件以数据块链表方式存储, 文件头包含了到第一块和最后一块的指针, 创建/增大/缩小很容易, 没有碎片, 但无法实现真正的随机访问, 可靠性差, 链条破坏数据会丢失<br>
索引分配: 为每个文件创建一个索引数据块, 指向文件数据块的指针列表, 文件头包含了索引数据块指针, 创建/增大/缩小都很容易, 没有碎片, 支持直接访问, 文件很小时, 索引有开销, 大文件也有麻烦(大到一个数据块放不下索引时)<br>
大文件的索引分配: 链式索引块, 多级索引块<br>
UFS多级索引分配: 10块以内直接指到数据块, 第11个指针指向索引块, 第12个指针指向二级索引, 第13个指针指向三级索引, 提高了文件大小限制阈值, 动态分配数据块很容易, 小文件开销小, 只为大文件分配间接数据块, 大文件在访问数据块时需要大量查询</p>
<h3 id="空闲空间管理">空闲空间管理</h3>
<p>跟踪记录文件卷中未分配的数据块<br>
用位图代表空闲数据块列表, 0表示空闲1表示已分配<br>
冗余磁盘阵列: 是一种多磁盘管理技术<br>
通常磁盘通过分区来最大限度减小寻道时间, 分区是一组柱面的集合, 每个分区都可视为逻辑上独立的磁盘<br>
文件卷: 一个拥有完整文件系统实例的外存空间, 通常常驻在磁盘的单个分区上<br>
使用多磁盘可改善吞吐量(通过并行), 可靠性和可用性(通过冗余)</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(三) - 虚拟存储和页面置换算法</title>
    <url>/2021/10/28/20211028160218/</url>
    <content><![CDATA[<h2 id="虚拟存储">虚拟存储</h2>
<h3 id="需求背景">需求背景</h3>
<p>存储器的层次结构: 寄存器, 高速缓存, 内存, 磁盘, 磁带, 速度依次降低且差距巨大<br>
虚拟存储目标是解决内存不够用问题, 在有限容量的内存中, 以页为单位自动装入更多更大的程序</p>
<h3 id="覆盖和交换">覆盖和交换</h3>
<p><strong>覆盖</strong>: 应用程序将程序根据功能划分为独立的模块, 必要部分的代码和数据常驻内存, 可选部分需要时才装入到内存, 不存在调用关系的模块可以相互覆盖, 共用一块内存区域<br>
不足是, 增加编程困难(需划分功能模块, 确定模块间覆盖关系), 增加执行时间(从外存装入覆盖模块)<br>
<strong>交换</strong>: 增加正在运行程序的内存, 操作系统可自动将暂时不能运行的程序放到外存, 换入换出的基本单位是整个进程的地址空间, 只有当内存不够或有不够可能时换出<br>
依赖于<strong>局部性原理</strong>: 程序在执行过程中的一个较短时期, 所执行的指令地址和指令的操作数地址, 分别局限于一定区域, 时间局部性, 空间局部性, 分支局部性</p>
<h3 id="虚拟存储概念">虚拟存储概念</h3>
<p>核心: <strong>将不常用的部分内存块暂存到外存</strong><br>
装载程序时, 只将当前指令执行需要的部分页面或段装入内存, 指令执行中需要的指令或数据不在内存称为缺页或缺段, 处理器通知操作系统将相应的页面或段调入内存<br>
操作系统将内存中暂时不用的页面或段保存到外存</p>
<h3 id="虚拟页式存储">虚拟页式存储</h3>
<p>在页式存储管理的基础上, 增加请求调页和页面置换<br>
程序装载到内存运行时, 只装入部分页面, 就启动, 进程在运行中发现有需要的代码或数据不在内存时, 则向系统发出缺页异常请求, 操作系统在处理缺页异常时, 将外存相应的页面调入内存, 使得进程能继续运行<br>
页表项需要添加几个标志位:<br>
驻留位, 表示该页是否在内存, 修改位, 表示在内存中的该页是否被修改过, 访问位, 是否被访问过, 用于置换算法, 保护位, 表示该页允许的访问方式</p>
<h3 id="缺页异常">缺页异常</h3>
<p>处理流程, 指令-&gt;页表项, 有效直接访问, 无效就产生缺页异常-&gt;操作系统缺页异常服务例程执行-&gt;查找在外存中对应的页面-&gt;物理内存有空闲帧, 则直接放并修改页表项-&gt;重新执行指令<br>
如果以上没找到空闲帧, 则依据页面置换算法选择被替换的物理页帧, 并判断是否修改过, 修改过则写回外存, 并修改该页的页表项表示已无效<br>
未被映射的页通常保存到兑换区, 采用特殊格式存储, 代码段和共享库不去修改, 不用放到兑换区, 数据段和堆栈段需要放<br>
虚拟页式存储管理的性能: 有效存储访问时间 = 访存时间×(1-p)+缺页异常处理时间×缺页率p<br>
想要性能高就要保证缺页率p足够小</p>
<h2 id="页面置换算法">页面置换算法</h2>
<h3 id="简介-v2">简介</h3>
<p>当出现缺页异常, 需调入新页面而内存已满时, 置换算法选择被置换的物理页面, 且尽可能减少页面的调入调出次数, 把未来不再访问或短期内不访问的页面调出<br>
页面锁定: 有些不能调出, 如声明必须常驻内存的, 操作系统的关键部分, 要求响应速度的, 可通过页表中的锁定标志位锁定<br>
算法评价方法, 模拟页面置换行为, 产生缺页次数少的性能更好<br>
局部页面置换算法: 选择范围仅限于当前进程占用的物理页面, 每个进程占用的页面总数不会变化, 例如最优算法(预测未来), 先进先出, 最近最久未使用算法(统计过去), 时钟算法, 最不常用算法<br>
全局页面置换算法: 范围为所有可换出的物理页面, 进程间分配的物理页面数会发生变化, 例如工作集算法, 缺页率算法</p>
<h3 id="局部页面置换算法">局部页面置换算法</h3>
<p>依次介绍每种算法<br>
<strong>最优页面置换算法(Optimal, OPT)</strong>: 置换在未来最长时间不访问的页面, 因为需要预测未来所以无法实现, 但可以作为其他算法的评测依据<br>
<strong>先进先出算法(First-In First-Out, FIFO)</strong>: 选择在内存驻留时间最长的页面进行置换, 好实现, 但性能差, 分配物理页面增加甚至会缺页更多, 很少单独使用<br>
<strong>最近最久未使用算法(Least Recently Used, LRU)</strong>: 选择最长时间没有被引用的页面进行置换, 有点复杂, 开销大<br>
<strong>时钟页面置换算法(Clock)</strong>: 对页面访问进行粗略统计, 页表项增加访问位, 页面组成环形链表, 指针指向最先调入页面, 缺页时从指针处开始顺序找未被访问页面置换, LRU和FIFO的折中<br>
<strong>改进的时钟算法</strong>: 减少修改页的缺页处理开销, 再添加修改位, 缺页时跳过有修改的页面<br>
<strong>最不常用算法(Least Frequently Used, LFU)</strong>: 对LRU改进, 置换访问次数最少的页面, 每个页面加一个访问计数, 缺页时置换计数最小的</p>
<h3 id="全局页面置换算法">全局页面置换算法</h3>
<p><strong>工作集置换算法</strong><br>
换出不在工作集中的页面, 窗口大小b, 当前时刻前b个内存访问的页引用是工作集<br>
工作集: 一个进程当前正在使用的逻辑页面集合, 可表示为二元函数W(t, a), t是当前的执行时刻, a是工作集窗口(一个定长的页面访问时间窗口), W是指在当前时刻t前面的a时间窗口里, 所有访问页面所组成的集合, |W(t,a)|表示工作集的大小, 即页面数目<br>
常驻集: 当前时刻, 进程实际驻留内存的页面集合<br>
工作集和常驻集的关系, 工作集是进程运行过程中固有的性质, 常驻集取决于系统分配给进程的物理页面数和页面置换算法<br>
访存链表: 维护窗口内的访存页面链表, 访存时换出不在工作集的页面, 更新访存链表, 缺页时, 换入页面, 更新访存链表, 开销也很大</p>
<p><strong>缺页率算法</strong><br>
缺页率: 缺页次数/内存访问次数或者缺页平均时间间隔的倒数<br>
影响缺页率的因素: 页面置换算法, 分配给进程的物理页面数, 页面大小, 程序的编写方法<br>
缺页率置换算法通过调整常驻集大小, 使得缺页率保持在一个合理的范围内, 访存时, 设置引用标志位, 缺页时计算上次缺页时间到现在的时间间隔, 如果大于常数T, 说明缺页比较低, 减小常驻集, 如果小于T, 则缺页率较高, 增大常驻集<br>
抖动: 进程物理页面太少, 不能包含工作集, 造成大量缺页频繁置换, 进程运行速度变慢<br>
原因是随着驻留内存的进程数目增加, 分配给每个进程的物理页面不断减少, 缺页率不断上升, 解决办法负载控制, 通过调节并发进程数, 来进行系统负载控制</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>算法</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(二) - 存储管理</title>
    <url>/2021/10/25/20211025192219/</url>
    <content><![CDATA[<h2 id="存储管理">存储管理</h2>
<h3 id="计算机体系结构和内存层次">计算机体系结构和内存层次</h3>
<p>内存层次: CPU有高速缓存, 未命中查内存, 内存没有查外存, 访问速度差别很大<br>
内存管理目标: 抽象(逻辑地址空间), 保护(独立地址空间), 共享(访问相同内存), 虚拟化(更大的地址空间)<br>
操作系统中采用的内存管理方式, 重定位(Relocation), 分段(Segmentation), 分页(Paging), 虚拟存储(Virtual Memory)<br>
以上实现高度依赖硬件, 与计算机存储架构紧耦合, MMU(内存管理单元)是处理CPU存储访问请求的硬件, 多数系统采用按需页式虚拟存储</p>
<h3 id="地址空间和地址生成">地址空间和地址生成</h3>
<p>物理地址空间定义: 硬件支持的地址空间, 起始地址0, 直到MAXsys, 32位就是0到2的32次幂-1<br>
多少位地址总线, 就是物理地址总线的条数<br>
逻辑地址空间, 在CPU运行的进程看到的地址, 起始地址0,到MAXprog<br>
地址生成时机: 编译时, 加载时, 执行时, 前两种简单但是不灵活, 第三种最灵活</p>
<h3 id="连续内存分配">连续内存分配</h3>
<p>目标: 给进程分配一块不小于指定大小的连续物理内存区域<br>
内存碎片: 空闲内存不能被利用, 外碎片(较小的剩余不连续内存区域), 内碎片(分配的内存区域未使用完的剩余部分)<br>
动态分区分配: 当程序被加载执行时, 分配一个进程, 指定大小可变的分区, 分区的地址是连续的, 操作系统需要维护两个数据结构, 已分配分区和空闲分区<br>
动态分区分配有三种策略:<br>
1 最先匹配: 找第一个比申请大的区域, 分配给进程. 优点是简单, 在高地址有大块分区, 但有外部碎片, 分配大块时较慢<br>
2 最佳分配: 找比申请大小大的最小的一个(即大小最接近的), 空闲分区按大小排序, 合并时复杂一些, 优点可避免大块分区被拆分, 减小外碎片大小, 但有外碎片, 释放分区较慢, 产生无法利用的小碎片<br>
3 最差匹配: 找最大区域, 空闲按从大到小排, 合并复杂, 优点避免太多小碎片, 但释放慢, 有外碎片, 破坏了大分区</p>
<h4 id="碎片整理">碎片整理</h4>
<p>紧凑(Compaction): 通过调整进程占用的分区位置, 来减少分区碎片, 移动分配给进程的内存分区, 以合并外部碎片, 条件要求所有应用程序可动态重定位分区, 通常等待状态搬动, 还要考虑搬动开销<br>
分区兑换(Swapping In/Out): 通过抢占并回收处于等待状态进程的分区, 以增大可用内存空间, 把等待进程放到对换区</p>
<h3 id="非连续内存分配">非连续内存分配</h3>
<p>有三种, 段式, 页式, 段页式<br>
连续分配缺点: 分给程序内存必须连续, 存在内外碎片, 内存分配的动态修改困难, 内存利用率较低<br>
非连续内存分配目标: 提高内存利用率和管理灵活性<br>
允许一个程序使用非连续物理地址空间, 允许共享代码和数据, 支持动态加载和动态链接</p>
<h3 id="段式存储管理">段式存储管理</h3>
<p>段地址空间: 进程的段地址空间由多个段组成, 主代码段, 子模块代码段, 公用库代码段, 堆栈段, 堆数据, 初始化数据段, 符号表等<br>
段表示<strong>访问方式</strong>和<strong>存储数据等属性</strong>相同的一段地址空间, 对应一个连续的内存块, 若干个段组成进程的逻辑地址空间<br>
段访问机制: 逻辑地址由二元组(s, addr)表示, s是段号, addr是段内偏移, 去查进程的段表, 找到段的起始地址和长度, 然后根据偏移, 找到数据</p>
<h3 id="页式存储管理">页式存储管理</h3>
<p>把物理地址空间划分为大小相同的基本分配单位, 叫做页帧/帧(Frame), 大小2的n次幂, 常见大小4K<br>
把逻辑地址空间也划分为相同大小的基本分配单位, 叫做页面/页(Page), 页和帧的大小必须是相同的<br>
页到帧的转换通过页表完成<br>
内存物理地址表示, 二元组(f,o), 帧号和偏移<br>
不是所有的页都有对应的帧</p>
<h4 id="页表概述">页表概述</h4>
<p>每个进程都有一个页表, 每个页面对应一个页表项, 随进程运行状态动态变化, 首地址放在页表基址寄存器(Page Table Base Register, PTBR)<br>
页表项组成: 帧号, 标志位(存在位, 修改位, 引用位)<br>
页式存储性能问题, 访问一个内存单元需要两次内存访问, 先查页表项再访问数据<br>
当页表项过多, 页表可能非常大, 解决办法就是缓存(快表)和间接访问(多级页表)<br>
快表: 缓存近期访问的页表项, 使用关联存储器实现<br>
多级页表: 通过间接引用将页号分成k级, 建立页表树<br>
反置页表: 为了减少页表所占用存储空间的一种做法, 让页表项和物理地址空间对应起来, 不和逻辑地址空间对应, 进程数量增加和虚拟地址空间增大都对页表占用没有影响<br>
以上三种做法可缓解页表带来的麻烦</p>
<h3 id="段页式存储管理">段页式存储管理</h3>
<p>段式和页式的结合<br>
段式存储分的块比较大, 每块内容是同一个段, 做存储的保护是比较方便的<br>
页式存储分了很小的标准大小的块, 在内存利用效率比较有优势<br>
实现: 在段式存储管理基础上, 给每个段加一个页表(段号, 页号, 页内偏移)</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(一) - 启动,中断,异常,系统调用</title>
    <url>/2021/10/25/20211025172037/</url>
    <content><![CDATA[<h2 id="操作系统概述">操作系统概述</h2>
<h3 id="什么是操作系统">什么是操作系统</h3>
<p>操作系统是一个控制程序, 一个系统软件, 控制程序执行过程, 给用户提供各种服务, 方便用户使用计算机系统<br>
操作系统是一个资源管理器, 应用程序与硬件之间的中间层, 管理软硬件资源, 提供访问软硬件手段, 解决资源访问冲突<br>
操作系统软件的组成, Shell, GUI, Kernel</p>
<h3 id="操作系统内核的特征">操作系统内核的特征</h3>
<p>并发: 系统中同时存在多个运行的程序, 需要管理和调度<br>
共享: 宏观上&quot;同时&quot;访问, 微观上互斥共享<br>
虚拟: 利用多道程序设计技术, 让用户感觉不到其他用户<br>
异步: 程序是走走停停的; 只要运行环境相同, 运行结果也要相同</p>
<h2 id="启动-中断-异常和系统调用">启动, 中断, 异常和系统调用</h2>
<h3 id="启动">启动</h3>
<p>CPU通过总线连接I/O设备和内存<br>
内存分为RAM(随机访问存储)和ROM(只读存储), 系统加电后会从ROM读取系统初始化代码<br>
CPU完成初始化后处于实模式下, 地址总线只有20位可用, 所以内存地址640KB到1M之间为BIOS启动固件<br>
BIOS具备的功能有: 基本输入输出, 系统设置信息, 开机自检, 系统自启动程序<br>
BIOS初始化完成以后, 从磁盘读引导扇区, 长度只有512字节, 放到指定地址, 并跳转过去<br>
然后开始执行加载程序, 将操作系统代码和数据从硬盘加载到内存, 并跳转到操作系统的起始地址, 交出控制权给内核程序</p>
<h3 id="系统启动流程">系统启动流程</h3>
<p>加电后读BIOS, BIOS读主引导记录, 主引导记录读取活动分区, 活动分区读加载程序, 加载程序读内核映像<br>
<strong>BIOS初始化过程</strong><br>
硬件自检(Power On Self Test, POST), 执行系统BIOS进行系统检测, 更新CMOS芯片中的扩展系统配置数据ESCD(Extended System Configuration Data), 按指定启动顺序从软/硬盘或光驱启动, 读进第一个扇区<br>
主引导记录MBR(Master Boot Record)格式, 包括: 启动代码(检查分区表正确性, 加载并跳转到磁盘上的引导程序), 硬盘分区表, 结束标志字, 然后跳到活动分区的引导扇区上<br>
分区引导扇区格式包括, 跳转指令, 文件卷头, 启动代码, 结束标志<br>
加载程序(bootloader), 从文件系统读一个启动配置文件, 依据配置去加载内核</p>
<h3 id="中断-异常和系统调用">中断, 异常和系统调用</h3>
<p>计算机运行中, 内核是被信任的, 只有内核可以执行特权指令, 为了方便应用程序<br>
中断(Hardware Interrupt), 来自硬件设备的处理请求, 异步<br>
异常(Exception), 非法指令或者其他原因导致当前指令执行失败后的处理请求, 同步<br>
系统调用(System Call), 应用程序主动向操作系统发出的服务请求, 异步或同步<br>
当连接外设时, 需要<strong>中断</strong>做响应, 当应用程序遇到意外时, 交给<strong>异常</strong>做处理, <strong>系统调用</strong>为了应用程序方便的使用内核提供的服务, 又不会对内核安全产生影响</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring-通过配置向 Quartz定时任务 注入service</title>
    <url>/2017/02/19/20170219215026/</url>
    <content><![CDATA[<p>写了一个定时任务, 但是调用service会报空, 原因是service注入不进去, 解决办法如下:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">name</span>=<span class="string">"quartzScheduler"</span> <span class="attr">class</span>=<span class="string">"org.springframework.scheduling.quartz.SchedulerFactoryBean"</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"dataSource"</span> <span class="attr">ref</span>=<span class="string">"dataSource"</span> /&gt;</span>    </span><br><span class="line">            </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"schedulerContextAsMap"</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">map</span>&gt;</span>    </span><br><span class="line">                <span class="comment">&lt;!-- spring 管理的service需要放到这里，才能够注入成功 --&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>schedulerContextAsMap<span class="tag">&lt;/<span class="name">description</span>&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"webSiteService"</span> <span class="attr">value-ref</span>=<span class="string">"webSiteService"</span>/&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span> = <span class="string">"mappingService"</span> <span class="attr">value-ref</span>=<span class="string">"mappingService"</span>/&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"detailService"</span> <span class="attr">value-ref</span> = <span class="string">"detailService"</span>&gt;</span><span class="tag">&lt;/<span class="name">entry</span>&gt;</span>   </span><br><span class="line">            <span class="tag">&lt;/<span class="name">map</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"applicationContextSchedulerContextKey"</span> <span class="attr">value</span>=<span class="string">"applicationContextKey"</span> /&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"configLocation"</span> <span class="attr">value</span>=<span class="string">"classpath:quartz.properties"</span> /&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span>    </span><br><span class="line">        </span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"jobDetail"</span> <span class="attr">class</span>=<span class="string">"org.springframework.scheduling.quartz.JobDetailBean"</span>&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jobClass"</span> <span class="attr">value</span> = <span class="string">"com.fangjia.dc.quartz.MyQuartzJob"</span>/&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"jobDataAsMap"</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;<span class="name">map</span>&gt;</span>    </span><br><span class="line">                <span class="comment">&lt;!-- 非spring管理的service放到这里，就可以注入进去 --&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">description</span>&gt;</span>jobDataAsMap<span class="tag">&lt;/<span class="name">description</span>&gt;</span>    </span><br><span class="line">                <span class="comment">&lt;!-- key 属性值，value 对应的bean --&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"uploader"</span> <span class="attr">value-ref</span>=<span class="string">"uploader"</span> /&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;/<span class="name">map</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>// -----------------割割割-----------下面这部分我没用到------</p>
<p>定时任务的动态管理, 没有配置的Spring文件中<br>
采用页面传值, 实现quartz定时任务的CRUD</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">schedule</span><span class="params">(String name, CronExpression cronExpression,String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">           </span><br><span class="line">        <span class="comment">//添加Job 给scheduler,允许 replace  </span></span><br><span class="line">           </span><br><span class="line">        jobDetail.setRequestsRecovery(<span class="keyword">true</span>);   </span><br><span class="line">        <span class="comment">//孤立线程 不再保存在DB中  </span></span><br><span class="line">        jobDetail.setDurability(<span class="keyword">false</span>);   </span><br><span class="line">        jobDetail.setName(name);   </span><br><span class="line">        logger.info(<span class="string">" is  durable:"</span> + jobDetail.isDurable());   </span><br><span class="line">        <span class="comment">//设置replace为true，相同名字的job存在，则替换  </span></span><br><span class="line">        scheduler.addJob(jobDetail, <span class="keyword">true</span>);   </span><br><span class="line">           </span><br><span class="line">        CronTrigger cronTrigger = <span class="keyword">new</span> CronTrigger(name, group, jobDetail.getName(), Scheduler.DEFAULT_GROUP);  </span><br><span class="line">        cronTrigger.setCronExpression(cronExpression);   </span><br><span class="line">        scheduler.scheduleJob(cronTrigger);   </span><br><span class="line">        scheduler.rescheduleJob(cronTrigger.getName(), cronTrigger.getGroup(), cronTrigger);  </span><br><span class="line">    &#125;   </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pauseTrigger</span><span class="params">(String triggerName, String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">        logger.info(<span class="string">"pause triggerName:"</span> + triggerName);   </span><br><span class="line">        scheduler.pauseTrigger(triggerName, group);   </span><br><span class="line">    &#125;   </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resumeTrigger</span><span class="params">(String triggerName, String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">        logger.info(<span class="string">"resume trigger:"</span> + triggerName + <span class="string">" group:"</span> + group);   </span><br><span class="line">        scheduler.resumeTrigger(triggerName, group);   </span><br><span class="line">    &#125;   </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">removeTrigdger</span><span class="params">(String triggerName, String group)</span> <span class="keyword">throws</span> SchedulerException </span>&#123;  </span><br><span class="line">        scheduler.pauseTrigger(triggerName, group);   </span><br><span class="line">        <span class="keyword">return</span> scheduler.unscheduleJob(triggerName, group);   </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>quartz.properties设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.quartz.scheduler.instanceName &#x3D; DefaultQuartzScheduler     </span><br><span class="line">org.quartz.scheduler.rmi.export &#x3D; false    </span><br><span class="line">org.quartz.scheduler.rmi.proxy &#x3D; false    </span><br><span class="line">org.quartz.scheduler.wrapJobExecutionInUserTransaction &#x3D; false    </span><br><span class="line">    </span><br><span class="line">org.quartz.threadPool.class &#x3D; org.quartz.simpl.SimpleThreadPool     </span><br><span class="line">org.quartz.threadPool.threadCount &#x3D; 10    </span><br><span class="line">org.quartz.threadPool.threadPriority &#x3D; 5    </span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread &#x3D; true   </span><br><span class="line">    </span><br><span class="line">org.quartz.jobStore.misfireThreshold &#x3D; 60000    </span><br><span class="line">    </span><br><span class="line">#org.quartz.jobStore.class &#x3D; org.quartz.simpl.RAMJobStore     </span><br><span class="line">    </span><br><span class="line">org.quartz.jobStore.class &#x3D; org.quartz.impl.jdbcjobstore.JobStoreTX     </span><br><span class="line">org.quartz.jobStore.driverDelegateClass&#x3D;org.quartz.impl.jdbcjobstore.StdJDBCDelegate    </span><br><span class="line">org.quartz.jobStore.tablePrefix &#x3D; QRTZ_       </span><br><span class="line">org.quartz.jobStore.isClustered &#x3D; false       </span><br><span class="line">org.quartz.jobStore.maxMisfiresToHandleAtATime&#x3D;1      </span><br><span class="line">#org.quartz.jobStore.txIsolationLevelReadCommitted &#x3D; true</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(五) - 同步互斥, 信号量和管程</title>
    <url>/2021/11/03/20211103154327/</url>
    <content><![CDATA[<h2 id="同步互斥">同步互斥</h2>
<h3 id="背景">背景</h3>
<p>并发进程在多个进程间有资源共享, 导致执行过程是不确定性和不可重现的, 程序错误可能是间歇性发生<br>
<strong>原子操作</strong>: 是指一次不存在任何中断或失败的操作<br>
操作系统需要利用同步机制, 在并发执行的同时保证一些操作是原子操作<br>
几个状态:<br>
互斥: 一个进程占用资源, 其他进程不能使用<br>
死锁: 多个进程各自占用部分资源, 形成循环等待<br>
饥饿: 其他进程可能轮流占用资源, 一个进程一直得不到资源</p>
<h3 id="临界区">临界区</h3>
<p><strong>临界区</strong>: 是进程中访问临界资源的一段需要互斥执行的代码<br>
进入区, 检查可否进入临界区的一段代码, 如可进入, 设置相应正在访问临界区的标志<br>
退出区, 清除正在访问临界区的标志<br>
剩余区, 代码中的其他部分, 和同步互斥没关系<br>
临界区访问规则: 空闲则入, 忙则等待, 有限等待, 让权等待<br>
临界区的实现方法有三种: 禁用中断, 软件方法, 更高级的抽象方法<br>
禁用硬件中断: 没有中断, 没有上下文切换, 因此没有并发, 硬件将中断处理延迟到中断被启用之后, 缺点进程无法被停止, 可能导致其他进程处于饥饿, 临界区可能很长中断不能及时响应, 要小心使用<br>
软件方法: Peterson算法, Dekkers算法, Eisenberg和McGuire, 复杂, 需要两个进程间的共享数据项, 是忙等待, 浪费CPU时间<br>
更高级的抽象方法: 基于硬件的一些同步原语, 例如原子操作指令<br>
原子操作指令: 测试和置位(Teat and Set)指令, 交换指令(Exchange), 使用TS指令实现自旋锁(Spinlock), 无忙等待锁<br>
锁: 一个抽象的数据结构, 一个二进制变量, 和两个操作原语<br>
原子操作指令锁的特征, 适用于单处理器或共享主存的多处理器中任意数量的进程同步, 简单, 支持多临界区, 缺点忙等待消耗CPU时间, 可能导致饥饿, 可能死锁<br>
总结, 禁用中断, 仅用于单处理器, 软件方法, 复杂, 原子操作指令, 单处理器或多处理器均可</p>
<h2 id="信号量与管程">信号量与管程</h2>
<p>信号量与管程都属于解决同步问题的高级抽象方法</p>
<h3 id="信号量-Semaphore">信号量(Semaphore)</h3>
<p><strong>信号量</strong>: 是操作系统提供的一种协调共享资源访问的方法, 早期操作系统的主要同步机制, 现在很少用<br>
信号量由一个整型变量和两个原子操作组成, P操作(减少), V操作(增加), 被保护的整数变量, 初始化完成后, 只能通过P和V操作修改, 由操作系统保证P和V操作的原子性<br>
P可能阻塞, V不会阻塞<br>
信号量分为两种, 二进制信号量和资源信号量(任何非负数)</p>
<h3 id="管程-Moniter">管程(Moniter)</h3>
<p><strong>管程</strong>: 是一种用于多线程互斥访问共享资源的程序结构, 采用面向对象方法, 简化了线程间的同步控制, 任一时刻最多只有一个线程执行管程代码<br>
正在管程中的线程可临时放弃管程的互斥访问<br>
管程的组成: 一个锁, 控制管程代码的互斥访问, 0或多个条件变量, 管理共享数据的并发访问<br>
条件变量是管程内部的等待机制, 进入管程的线程因资源占用而进入等待状态, 每个条件变量表示一种等待原因<br>
Hansen管程和Hoare管程, 哲学家就餐问题, 读者-写着问题, 略</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(八) -  I/O系统</title>
    <url>/2021/11/04/20211104151612/</url>
    <content><![CDATA[<h2 id="I-O系统">I/O系统</h2>
<h3 id="I-O特点">I/O特点</h3>
<p>三种常见设备接口类型<br>
字符设备: 以字节为单位顺序访问, 通常使用文件访问接口和语义, 例如键盘鼠标<br>
块设备: 均匀的数据块访问, 原始I/O接口或文件系统接口, 内存映射文件访问, 例如磁盘驱动器, 光驱<br>
网络设备: 格式化报文交换, 专用的网络报文收发接口, 通过网络接口支持多种网络协议, 例如以太网, 无线, 蓝牙<br>
同步和异步I/O<br>
<strong>阻塞I/O</strong>: wait, 读数据时, 进程将进入等待状态, 直到完成数据读出, 写数据时, 进程将进入等待状态, 直到设备完成数据写入处理<br>
<strong>非阻塞I/O</strong>: don’t wait, 立即从读或写系统调返回, 返回值为成功传输字节数, 读或写的传输字节可能为零<br>
<strong>异步I/O</strong>: tell me later, 读数据时, 使用指针标记好用户缓冲区, 立即返回, 稍后内核将填充缓冲区并通知用户, 写数据时, 使用指针标记好用户缓冲区, 立即返回, 稍后内核将处理数据并通知用户</p>
<h3 id="I-O结构">I/O结构</h3>
<p>CPU在主板上分成两段, 北桥和高速的内存显卡相连, 南桥和各种各样设备相连, 比如PCI总线, 磁盘, 网络<br>
北桥高速设备, 南桥I/O设备<br>
CPU和设备的连接: 设备上有设备控制器, 功能是提供CPU和I/O设备间的接口, 向CPU提供特殊指令和寄存器, I/O地址通过总线连到CPU上, 总线和实际设备之间有总线适配器,映射过来可能是内存地址, 也可能是I/O空间的端口<br>
从设备到CPU的通道, 就是中断控制器, 设备产生中断在中断控制器进行汇总, 然后送给CPU, CPU就能对外部设备的事件做出相应<br>
CPU和设备通信的三种方式: 轮询(不用中断控制器, CPU直接访问I/O端口, 或者访问设备对应的内存地址空间), 设备中断, DMA(Direct Memory Access)控制器</p>
<p>I/O指令和内存映射I/O:<br>
I/O指令: 通过I/O端口号访问设备寄存器, 通过端口号区别访问的哪个设备, 特殊的CPU指令, OUT/IN两个指令, 不仅仅是数据的访问, 还对应相应的设备控制<br>
内存映射I/O: 设备的寄存器/存储被映射到内存物理地址空间中, 通过内存load/store指令完成I/O操作, 通过MMU(Memory Management Unit)设置映射, 硬件跳线或程序在启动时设置地址</p>
<p>内核I/O子系统结构: 最底层各种各样设备, 每个设备之上有设备控制器, 再之上是驱动软件, 上是I/O子系统, 上是内核其他部分内容依赖I/O子系统完成数据读写<br>
<strong>I/O请求生命周期</strong><br>
用户进程发起I/O请求 -&gt; 内核I/O子系统 -&gt; 向设备驱动发送I/O请求, 并等待结果 -&gt; 设备驱动处理I/O请求转换成设备控制命令发送给硬件并等待中断相应 -&gt;<br>
硬件设备完成时, 产生中断 -&gt; 中断处理例程接受中断, 保存结果并通知设备驱动 -&gt; 通知驱动层, 确定I/O操作完成状态, 区分返回结果和哪个请求相对应 -&gt;<br>
结果给到I/O子系统当中 -&gt; 送给用户进程</p>
<h3 id="I-O数据传输">I/O数据传输</h3>
<p>CPU与I/O设备的数据传输有两种方式<br>
<strong>程序控制I/O(PIO, Programmed I/O)</strong>: 通过CPU的In/Out或者load/store传输所有数据, 特点是硬件简单, 编程容易, 消耗的CPU时间和数据量成正比, 适用于简单的小型设备I/O<br>
<strong>直接内存访问(DMA)</strong>: 设备控制器可直接访问系统总线, 控制器直接与内存互相传输数据, 特点是设备传输数据不影响CPU, 开始和结束需要CPU参与设置, 适用于高吞吐量I/O</p>
<p>I/O设备通知操作系统的机制如下, 了解设备状态, I/O操作完成时间或遇到错误<br>
CPU主动轮询: I/O设备在特定的状态寄存器中放置状态和错误信息, 操作系统定时检测状态寄存器, 优点是简单, 但I/O操作频繁或不可预测时, 开销大和延时长<br>
设备中断: 处理不可预测事件效果好, 开销相对较高<br>
一些设备结合了轮询和设备中断, 如高带宽网络设备, 第一个传入数据包到达前采用中断, 轮询后面的数据包直到硬件缓存为空</p>
<h3 id="磁盘调度">磁盘调度</h3>
<p>磁盘结构分为: 磁头, 磁头组, 磁盘轴, 盘片, 读写头, 磁道, 扇区, 柱面<br>
读取或写入时, 磁头必须被定位在期望的磁道, 并从所期望的柱面和扇区开始<br>
寻道时间: 定位到期望的磁道所花费的时间<br>
旋转延迟: 从零扇区开始到达目的地花费的时间<br>
磁盘io传输时间: 等待设备可用, 等待通道可用, (寻道, 旋转延时, 数据传输)传输时间</p>
<p><strong>磁盘调度算法</strong>, 通过优化磁盘访问请求顺序来提高磁盘访问性能, 寻道时间是磁盘访问最耗时的部分, 同时会有多个在同一磁盘上的I/O请求, 随机处理磁盘访问请求的性能表现很差<br>
先进先出: 公平但性能不好, 很多进程的情况下, 接近随机调度的性能<br>
最短服务时间优先(SSTF): 选择从磁臂当前位置需要移动最少的I/O请求, 总是选择最短寻道时间<br>
扫描算法(SCAN): 磁臂在一个方向上移动, 访问所有未完成的请求, 直到磁臂到达该方向上最后的磁道<br>
循环扫描算法(C-SCAN): 限制了仅在一个方向上扫描, 当最后一个磁道也被访问过了后, 磁臂返回到磁盘的另一端再次进行<br>
N步扫描算法(N-STEP-SCAN): 将磁盘请求队列分成长度为N的子队列, 按FIFO依次处理所有子队列, 扫描算法处理每个队列<br>
双队列扫描算法(FSCAN): N步扫描算法的简化, 只将磁盘请求队列分成两个子队列, 交替使用扫描算法处理一个队列, 新到达的请求放入另一个队列, 所有的新请求都将被推迟到下一次扫描时处理, 平均等待时间会减少</p>
<h3 id="磁盘缓存">磁盘缓存</h3>
<p>缓存是数据传输双方访问速度差异较大时, 引入的速度匹配中间层<br>
放在内存里的磁盘数据的缓存, 为了避免对同一块磁盘扇区里的内容进行反复引用时候的多次磁盘访问<br>
磁盘缓存的调度算法很类似虚拟存储调度算法, 磁盘的访问频率远低于虚拟存储中的内存访问频率, 所以通常磁盘缓存调度算法会比虚拟存储复杂<br>
单缓存和双缓存, 单缓存一个缓存区, 读写互斥, 双缓存, 有两个缓存区, 写1读2, 写2读1<br>
<strong>访问频率置换算法(Frequency-Based Replacement)</strong>: 考虑磁盘访问的密集特征, 对密集引用不计数, 在短周期中使用LRU, 在长周期中使用LFU<br>
具体实现: LRU栈被分为新区域, 中间区域, 旧区域三部分, 被访问就放入栈顶(LRU)也就是新区域, 新区域引用计数不变, 中间和旧区域会加一, 满了以后置换旧区域引用计数最大的块(LFU)</p>
<p>操作系统系列到此结束</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>I/O</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(四) - 进程,线程及CPU调度</title>
    <url>/2021/10/28/20211028190613/</url>
    <content><![CDATA[<h2 id="进程和线程">进程和线程</h2>
<h3 id="进程">进程</h3>
<p>进程是指一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程<br>
进程包含了正在运行的一个程序的所有状态信息, 代码, 数据, 状态寄存器, 通用寄存器, 进程占用系统资源等<br>
进程的特点: 动态性(可动态的创建/结束), 并发性(可以被独立调度并占用CPU), 独立性(不同进程相互不影响), 制约性(因访问共享数据/资源或进程间同步而产生制约)</p>
<h3 id="进程控制块-PCB-Process-Control-Block">进程控制块(PCB, Process Control Block)</h3>
<p>管理和控制进程运行所用的信息集合, 操作系统用PCB来描述进程的基本情况及运行变化的过程<br>
PCB是进程存在的唯一标志, 对进程的组织管理都是通过PCB来实现的<br>
进程控制块内容: 进程标识信息, 处理机现场保存, 进程控制信息(调度和状态, 进程间通信信息, 存储管理信息, 所用资源, 有关数据结构连接关系)<br>
PCB可通过链表和索引表组织起来<br>
链表, 同一状态的进程其PCB成一链表, 多个状态对应多个不同的链表, 就绪链表, 阻塞链表, 等待链表<br>
索引表, 同一状态的进程归入一个索引表, 多个状态对应对个不同的索引表</p>
<h3 id="进程状态">进程状态</h3>
<p>进程生命周期划分, 创建, 执行, 等待, 抢占, 唤醒, 结束<br>
创建: 系统初始化/用户请求创建一个新进程/正在运行的进程执行了创建进程的系统调用, 创建好放到就绪队列<br>
等待: 执行过程中某个条件不成立或资源不足够, 进入等待(阻塞)状态, 一定是进程内部的原因导致<br>
被抢占: 有高优先级进程就绪/进程执行当前时间用完<br>
唤醒: 被阻塞进程需要的资源可被满足/等待的事件到达, 只能被别的进程或操作系统唤醒<br>
结束: 正常退出/错误退出(自愿的), 致命错误/被其他进程所杀(强制性的)<br>
挂起: 把进程从内存转到外存,处在挂起状态的进程映像在磁盘上, 目的是减少进程占用内存<br>
就绪, 运行, 等待, 是进程整个生命周期中三种基本状态</p>
<h3 id="线程">线程</h3>
<p>线程是进程的一部分, 描述指令流执行状态, 它是进程中指令执行流的最小单元, 是CPU调度的基本单位<br>
进程负责调度线程, 进程控制块保存多个线程堆栈, 线程控制块指针指向各自堆栈<br>
优点: 一个进程中可同时存在多个线程, 各个线程之间可以并发执行, 各个线程可以共享地址空间和文件资源<br>
缺点: 一个线程崩溃会导致所属进程的所有线程崩溃<br>
<strong>线程和进程的比较</strong><br>
进程是资源分配单位, 线程是CPU调度单位<br>
进程拥有一个完整的资源平台, 线程只独享指令流执行的必要资源(寄存器和栈)<br>
总结: 线程能减少并发执行的时间和空间开销, 创建终止时间更短, 线程切换时间短, 同一进程的各线程共享内存和文件资源, 不需要通过内核可直接通信</p>
<h2 id="CPU调度">CPU调度</h2>
<h3 id="简介-v3">简介</h3>
<p>CPU资源的时分复用<br>
进程切换: CPU资源的当前占用者切换, 处理机调度, 从就绪队列中挑选下一个占用CPU运行的进程,从多个可用CPU中挑选就绪进程可用的CPU资源<br>
调度程序: 挑选就绪进程的内核函数, 需要注意调度策略和调度时机<br>
调度时机: 进程从运行状态切换到等待状态/进程被终结<br>
比较调度算法的准则: CPU使用率, 吞吐量(单位时间内完成的进程数量), 周转时间(进程从初始化到结束包括等待的总时间), 等待时间(进程在就绪队列的总时间), 响应时间(从提交请求到产生相应的总时间)<br>
响应时间目标: 减少响应时间, 减少平均响应时间的波动<br>
吞吐量目标: 增加吞吐量, 减少等待时间<br>
公平性目标: 保证每个进程占用相同的CPU时间和相同的等待时间, 但公平通常会增加平均响应时间</p>
<h3 id="调度算法">调度算法</h3>
<p><strong>先来先服务算法(FCFS, First Come First Served)</strong>: 依据进程进入就绪状态的先后顺序排列, 简单, 但平均等待时间波动较大, I/O和CPU资源的利用率较低<br>
<strong>短进程优先算法(SPN, SJF, SRT)</strong>: 选择就绪队列中执行时间最短进程占用CPU进入执行状态, 具有最优平均周转时间, 可能导致饥饿, 长进程无法获得CPU<br>
<strong>最高响应比优先算法(HRRN)</strong>: 选择就绪队列中响应比最高的进程, (等待时间+执行时间)/执行时间, 基于上一个的改进, 不可抢占, 关注进程的等待时间, 防止无限期推迟<br>
<strong>时间片轮转算法(RR, Round-Robin)</strong>: 时间片: 分配处理机资源的基本时间单元, 时间片结束时, 按FCFS算法切换到下一个就绪进程, 每隔n-1个时间片, 进程执行一个时间片<br>
时间片太大等待时间长, 时间片太小影响吞吐量, 合适长度, 经验规则,维持上下文切换开销处于1%以内<br>
<strong>多级反馈队列算法(MLFQ)</strong>:<br>
多级队列: 就绪队列被划分为多个独立的子队列, 比如交互, 批处理, 每个队列拥有自己的调度策略, 队列间的调度使用时间片轮转<br>
多级反馈队列: 进程可在不同队列间移动的多级队列算法, 时间片大小随优先级增加而增加, 如进程在当前时间片没有完成, 则降到下一个优先级<br>
<strong>公平共享调度算法(FSS, Fair Share Scheduling)</strong>: 资源访问的公平, 对用户分组, 一些用户组比其他用户组更重要, 保证不重要的组无法垄断资源</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统系列笔记(六) - 死锁和进程通信</title>
    <url>/2021/11/03/20211103171508/</url>
    <content><![CDATA[<h2 id="死锁和进程通信">死锁和进程通信</h2>
<h3 id="死锁">死锁</h3>
<p><strong>死锁</strong>: 是由于竞争资源或者通信关系, 两个或更多线程在执行中出现, 永远相互等待只能由其他进程引发的事件<br>
进程访问资源的流程: 先申请空闲资源-&gt;进程占用资源-&gt;释放资源从占用变成空闲<br>
资源分为两类<br>
可重用资源: 资源不能被删除且在任何时刻只能有一个进程使用, 进程释放后, 其他进程可重用, 可能出现死锁<br>
消费资源: 资源可创建和销毁, 比如中断/信号/消息, 可能出现死锁<br>
死锁的四个必要条件<br>
互斥, 任何时刻只能有一个进程使用一个资源实例<br>
持有并等待, 进程保持至少一个资源, 并正在等待获取其他进程持有的资源<br>
非抢占, 资源只能在进程使用后自愿释放<br>
循环等待</p>
<h3 id="死锁处理方法">死锁处理方法</h3>
<p>1 死锁预防, 确保系统永远不会进入死锁状态, 资源利用效率低<br>
限制并发进程对资源的请求, 使系统任何时刻都不满足死锁的必要条件<br>
互斥 -&gt; 把互斥的共享资源封装成可同时访问<br>
持有并等待 -&gt; 请求资源时, 要求不能持有任何其他资源, 仅允许在开始执行时, 一次请求所有需要资源<br>
非抢占 -&gt; 如进程请求不能立即分配的资源, 则释放已占有资源, 只在能够同时获得所有需要资源时, 才执行分配<br>
循环等待 -&gt; 对资源排序, 要求进程按顺序请求资源<br>
2 死锁避免, 利用额外的先验信息, 在分配资源时判断是否会出现死锁, 只允许不会出现死锁的进程请求资源<br>
要求进程声明需要资源的最大数目, 限定提供与分配的资源数量, 确保满足进程的最大需求, 动态检查资源分配状态, 确保不会出现环形等待<br>
银行家算法是一个死锁避免算法, 以银行借贷分配策略为基础, 判断并保证系统处于安全状态<br>
3 死锁检测和恢复, 在检测到运行系统进入死锁状态后, 进行恢复<br>
恢复方式: 进程终止, 资源抢占<br>
<strong>大多数操作系统由应用进程处理死锁, 操作系统忽略死锁</strong></p>
<h3 id="进程通信-IPC-Inter-Process-Communication">进程通信 (IPC, Inter Process Communication)</h3>
<p>进程通信是进程进行通信和同步的机制, IPC提供两个基本操作, 发送send和接收receive<br>
进程通信流程: 在通信进程间建立通信链路 -&gt; 通过send/receive交换信息<br>
两种通信方式<br>
<strong>间接通信</strong>: 依赖操作系统内核, 在进程和内核之间建立相应的机构比如消息队列, 每个消息队列都有唯一标识, 只有共享了相同消息队列的进程才能通信, 连接可以是单向或双向, 消息队列可以与多个进程相关联, 每对进程可以共享多个消息队列<br>
通信流程: 创建一个新的消息队列 -&gt; 通过消息队列发送和接受信息 -&gt; 销毁消息队列<br>
<strong>直接通信</strong>: 在两个进程之间建立一个通讯信道, 即共享信道, 两个进程必须同时存在, 进程必须正确的命名对方, 通信链路的属性, 自动建立链路, 一条链路恰好对应一对通信进程, 每对进程之间只有一个链接存在, 链接可以是单向但通常为双向<br>
进程通信可划分为阻塞(同步)或非阻塞(异步)<br>
通信链路缓冲: 0容量(发送方必须等待接收方), 有限容量(通信链路缓冲队列满时, 发送方必须等待), 无限容量(发送方不需要等待)</p>
<h3 id="通信机制的具体实现">通信机制的具体实现</h3>
<p>信号和管道是操作系统提供的两种简单的通信机制<br>
<strong>信号(Signal)</strong>: 是进程间的软件中断通知和处理机制, 信号的接受处理有捕获(执行进程指定的处理函数), 忽略(执行操作系统指定的缺省处理), 屏蔽(禁止进程接受和处理信号)<br>
不足是传送的信息量小, 只有一个信号类型, 做为一种快速的相应机制<br>
<strong>管道(Pipe)</strong>: 进程间基于内存文件的通信机制, 依据子进程从父进程继承文件描述符, 进程不关心管道的另一端<br>
管道相关的系统调用, 读管道(read), 写管道(write), 创建管道(pipe)<br>
<strong>消息队列</strong>: 是由操作系统维护的以字节为基本单位的间接通信机制, 每个消息是一个字节序列, 消息先进先出<br>
消息队列相关系统调用 获取消息队列标识(msgget), 发送消息(msgsnd), 接受消息(msgrcv), 消息队列控制(msgctl)<br>
<strong>共享内存</strong>: 是把同一个物理内存区域同时映射到多个进程的内存地址空间的通信机制, 特点, 快速, 方便的共享数据, 不足, 必须用额外的同步机制来协调数据访问, 防止没写完就读<br>
最快的方式, 一个进程写另一个进程立即可见, 没有系统调用干预, 没有数据复制<br>
在进程里, 每个进程都有私有内存地址空间, 每个进程的内存地址空间需明确设置共享内存段, 在线程里, 同一进程中的线程总是共享相同的内存地址空间<br>
共享内存系统调用, 创建共享段(shmget), 把共享段映射到进程地址空间(shmat), 取消映射(shmdt), 共享段控制(shmctl)</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-二分查找</title>
    <url>/2020/12/02/20201202152632/</url>
    <content><![CDATA[<h2 id="二分查找">二分查找</h2>
<h3 id="简介-v4">简介</h3>
<p>二分查找, 也叫折半查找, 是一种简单的快速查找算法<br>
二分查找针对的是一个有序的数据集合, 查找思想类似分治, 每次都通过跟区间的中间元素对比, 将待查找的区间缩小为之前的一半, 直到找到要查找的元素, 或者区间被缩小为0<br>
时间复杂度O(logn), 对数时间复杂度</p>
<h3 id="代码实现">代码实现</h3>
<p>二分查找的递归与非递归实现<br>
最简单的情况是有序数组中不存在重复元素<br>
循环实现 (todo)<br>
递归实现 (todo)<br>
容易出错的三个地方</p>
<ol>
<li>循环退出条件, low&lt;=high</li>
<li>min的取值, low和high比较大的话, 相加可能会溢出</li>
<li>low和high的更新, low=mid或high=mid可能会死循环</li>
</ol>
<h3 id="局限性">局限性</h3>
<ol>
<li>依赖顺序表结构, 既数组, 因为依赖按下标随机访问元素</li>
<li>针对有序数据, 如果无序需要先排序, 如果插入删除操作频繁, 则需频繁排序, 所以不适用二分查找</li>
<li>数据量适中, 数据量太小直接用遍历更为方便, 数据量太大时, 因为需要存储在数组, 需要连续内存空间, 内存可能放不下</li>
</ol>
<h3 id="进阶版">进阶版</h3>
<ul>
<li>查找第一个值等于给定值的元素 (todo)</li>
<li>查找最后一个值等于给定值的元素 (todo)</li>
<li>查找第一个大于等于个定制的元素 (todo)</li>
<li>查找最后一个小于等于给定值的元素 (todo)</li>
</ul>
<h3 id="总结-v2">总结</h3>
<p>等值查找使用散列表或者二叉查找树更多, 二分查找更适合用在近似查找问题</p>
<h3 id="课后练习">课后练习</h3>
<p>求一个数的平方根, 精确到小数点后6位 (todo)<br>
一个循环有序数组[4,5,6,1,2,3]中查找某个值 (todo)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-动态规划</title>
    <url>/2021/07/30/20210730193020/</url>
    <content><![CDATA[<h2 id="动态规划-Dynamic-Programming">动态规划(Dynamic Programming)</h2>
<p>动态规划比较适合求解最优问题, 比如最大值最小值, 可以非常显著的降低时间复杂度<br>
有点难, 求解过程不符合常规思维方式, 先看两个例子</p>
<h3 id="0-1背包问题">0-1背包问题</h3>
<p>一组不同重量, 不可分割的物品, 选择一些装入背包, 在背包限重前提下, 背包里能装下的<strong>物品重量最大值</strong><br>
回溯算法时间复杂度高, 指数级别, 回溯递归求解过程中, 有些子问题的求解是重复的, 此时可引入递归中的备忘录来解决, 避免冗余计算, 此时执行效率已经和动态规划差不多了<br>
而动态规划是这么做, 求解过程分为n个阶段, 每个阶段决策一个物品是否放到背包里<br>
每次决策后, 背包的重量会有多种情况, 会达到多种不同的状态, 我们把每一层重复的状态合并, 记录不同的状态, 就可以基于上一层状态集合, 推导下一层状态集合<br>
用一个二维数组记录, 横向是物品个数, 纵向是背包重量, 数组值是boolean类型, 根据物品重量依次填进去<br>
最后一层, 最接近末尾的数, 就是得到的解, 代码todo</p>
<p>动态规划解题思路, 把问题分解为多个阶段, 每个阶段对应一个决策, 记录每个阶段可达的状态集合, 通过当前阶段状态集合, 推导下一个阶段的状态集合, 动态地往前推进<br>
这也是动态规划名字的由来, 但需要额外申请一个n* w+1的二维数组, 空间换时间, 可以优化到只用w+1的一位数组解决<br>
回溯算法时间复杂度O(2^n), 动态规划时间复杂度O(n*w)物品个数乘可以承载总重量</p>
<h3 id="0-1背包问题升级版">0-1背包问题升级版</h3>
<p>一组不同重量, 不同价值, 不可分割的物品, 在满足背包最大重量限制前提下, 可装入的<strong>总价值</strong>最大是多少<br>
还是把求解过程分为n个阶段, 每个阶段决策一个物品是否放入背包, 每个阶段决策完后, 背包中的物品总重量及总价值会有多种情况<br>
用二维数组来记录每层可到达的不同状态, 横向物品个数, 纵向背包重量, 数组里存储的当前状态对应的最大总价值, 每层中重复的状态合并, 只记录价值最大的状态, 并基于此推导下一层状态<br>
时间复杂度和空间复杂度同上</p>
<h3 id="动态规划解决的问题">动态规划解决的问题</h3>
<p>大部分动态规划能解决的问题, 都可以通过回溯算法来解决, 只不过回溯算法效率比较低<br>
什么样的问题适合用动态规划来解决, 一个模型三个特征<br>
动态规划适合解决的问题模型为 多阶段决策最优解模型<br>
我们一般是用动态规划来解决最优解问题, 而解决过程需要经历多个决策阶段, 每个阶段都对应一组状态,<br>
然后我们寻找一组决策序列, 经过这组决策序列, 能够产生最终期望求解的最优值<br>
三个特征, 最优子结构, 无后效性, 重复子问题<br>
最优子结构, 问题的最优解包含子问题的最优解, 可以通过子问题的最优解推导出问题的最优解, 即后面阶段的状态可以通过前面阶段的状态推导出来<br>
无后效性, 一是推导状态时, 只关心前面阶段的状态值, 不关心这个值怎么来的, 二是某个阶段状态一旦确定就不受后续决策影响<br>
重复子问题, 不同的决策序列, 到达某个相同的阶段时, 可能会产生重复的状态</p>
<h3 id="动态规划解题思路">动态规划解题思路</h3>
<p>动态规划解题的一般思路有两种, 状态转移表法和状态转移方程法</p>
<ol>
<li>状态转移表法<br>
回溯算法实现-定义状态-画递归树-找重复子问题-画状态转移表-根据递推关系填表-将填表过程翻译成代码<br>
先画一个状态表, 一般是二维的, 用二维数组, 每个状态包含三个变量, 行列和数组值,  我们根据决策的先后过程, 从前往后填充状态表中的每个状态<br>
并将递推填表的过程, 翻译成代码, 就是动态规划代码了<br>
如果问题的状态比较复杂, 需要很多变量来表示, 那对应的状态表就需要是高维的, 就不适合用状态转移表法来解决了</li>
<li>状态转移方程法<br>
找最优子结构-写状态转移方程-将状态转移方程翻译成代码<br>
有点类似递归的解题思路, 需要分析某个问题如何通过子问题来递归求解, 也就是所谓的最优子结构, 根据最优子结构写出递归公式, 也就是所谓的状态转移方程<br>
两种代码实现方法, 一种是递归加备忘录, 一种是迭代递推<br>
状态转移方程是解决动态规划的关键<br>
有的问题适合用第一种思路, 有的问题适合用第二种思路, 需要结合题目分析</li>
</ol>
<h3 id="四种算法思想比较分析">四种算法思想比较分析</h3>
<p>贪心, 回溯, 动态规划可以归为一类, 解决问题的模型都可以抽象成多阶段决策最优解模型, 而分治算法不行<br>
回溯算法是个万金油, 基本上能用动态规划和贪心解决的问题, 都可以用回溯算法, 不过时间复杂度非常高, 只能用来解决小规模数据问题<br>
动态规划高效但不能解决所有问题, 需要满足三个特征<br>
贪心算法实际上是动态规划的一种特殊情况, 解决问题更高效, 代码也更简洁, 能解决的问题也更有限, 需要满足三个条件, 最优子结构, 无后效性和贪心选择性<br>
(通过局部最优的选择能产生全局最优选择)<br>
拿到问题先不思考计算机如何实现, 单纯考虑人脑会如何去解决, 然后总结规律, 再套用学过的算法</p>
<h3 id="拓展-拼写纠错">拓展-拼写纠错</h3>
<p>拼写纠错功能, 量化两个字符串的相似度,  需要用到非常著名的量化方法, 编辑距离<br>
编辑距离指, 将一个字符串转化成另一个字符串, 需要的最少编辑操作次数, 比如增加/删除/替换一个字符, 编辑距离越大, 说明两个字符串相似度越小,<br>
两个完全相同的字符串, 编辑距离是0<br>
根据所包含的编辑操作种类不同, 编辑距离有多种不同的计算方式, 比较著名的有莱文斯坦距离(todo)和最长公共子串长度(todo)<br>
莱文斯坦距离允许增加, 删除, 替换字符三个编辑操作, 最长公共子串长度只允许增加, 删除两个编辑操作<br>
莱文斯坦距离表示两个字符串差异的大小, 最长公共子串的大小表示两个字符串相似程度的大小<br>
具体细节略</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-哈希算法</title>
    <url>/2020/12/16/20201216153146/</url>
    <content><![CDATA[<h2 id="哈希算法">哈希算法</h2>
<h3 id="简介-v5">简介</h3>
<p>将任意长度的二进制值串映射为固定长度的二进制值串的映射规则就是哈希算法<br>
得到的二进制值串就是哈希值</p>
<h3 id="优秀的哈希算法包括">优秀的哈希算法包括</h3>
<ul>
<li>从哈希值不能反推出原始数据</li>
<li>对输入数据非常敏感, 哪怕一点小修改, 结果也大不相同</li>
<li>散列冲突的概率要很小, 对不同原始数据, 哈希值相同的概率非常小</li>
<li>执行效率要高效, 针对较长的文本, 也能快速计算出哈希值</li>
</ul>
<h3 id="鸽巢原理">鸽巢原理</h3>
<p>为什么哈希算法无法做到零冲突<br>
因为哈希值的长度是固定的, 那么就表示数据是有限的, 而要哈希的数据是无限的, 就必然会有数据存在哈希值相同的情况</p>
<h3 id="哈希算法的应用">哈希算法的应用</h3>
<ol>
<li>安全加密<br>
MD5, SHA, DES, AES等<br>
虽然加密后不容易反推出原始数据, 但是存在字典攻击, 黑客通过庞大的原文对密文的字典表, 很容易猜中用户的常用密码<br>
针对字典攻击, 又可以使用加盐的方式来防御, 比如对原始密码加入再加入复杂的字符串后哈希, 来增加破解难度<br>
安全和攻击是一种博弈关系, 不存在绝对的安全, 所有安全措施只是增加攻击成本而已</li>
<li>唯一标识<br>
针对较大的文件或者图片, 取部分字节通过哈希算法生成唯一标识, 再存储到散列表中, 可以快速判断图片是否存在</li>
<li>数据校验<br>
使用BT下载时, 基于p2p协议会从多个电脑上并行下载, 一部电影会分为多个文件块<br>
可以使用种子文件中保存的每个文件块的哈希值来判断, 每个文件块是否被人修改或者缺失</li>
<li>散列函数<br>
散列表的散列函数也是哈希算法的一种应用<br>
不过相对其他, 散列函数对冲突要求低很多, 且对于能否反向解密也不关心, 而更加关心散列后的值是否分布均匀</li>
<li>负载均衡<br>
负载均衡的算法有轮询, 随机, 加权轮询等, 如果要实现同一个客户端, 在一次会话中的所有请求都路由到同一个服务器的话, 可以借助哈希算法<br>
通过哈希算法, 对客户端ip地址或者会话id计算哈希值, 将取得的哈希值与服务器列表的大小取模运算, 最终得到的值就是应该被路由到的服务器编号</li>
<li>数据分片<br>
分布式计算中, 对数据根据key哈希, 再根据机器数取模, key相同的数据就可以分配到同一台机器上处理</li>
<li>分布式存储<br>
分布式存储中常用的一致性哈希算法</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-二叉树</title>
    <url>/2021/01/28/20210128151430/</url>
    <content><![CDATA[<h2 id="二叉树">二叉树</h2>
<h3 id="简介-v6">简介</h3>
<p>树, 非线性表结构<br>
树有三个概念:<br>
<strong>高度</strong>从下向上数, 起点是0<br>
<strong>深度</strong>从上向下数, 起点是0<br>
<strong>层数</strong>从上向下数, 起点是1</p>
<h3 id="二叉树-v2">二叉树</h3>
<p>每个节点最多两个叉<br>
有两种特殊二叉树:<br>
<strong>满二叉树</strong>, 除了叶子节点, 每个节点都有左右两个子节点<br>
<strong>完全二叉树</strong>, 叶子节点都在最底下两层, 最后一层叶子节点都靠左排列, 且除了最后一层, 其它层节点个数都达到最大<br>
满二叉树是完全二叉树的一种特殊情况</p>
<h3 id="存储二叉树">存储二叉树</h3>
<ol>
<li>基于指针的二叉链式存储法<br>
每个节点三个字段, 一个存数据, 另外两个存左右子节点的指针, 这种方式比较常用, 大部分二叉树代码都是通过这种结构来实现的</li>
<li>基于数组的顺序存储法<br>
把根节点存储在i=1的位置, 左子节点存在2i的位置, 右子节点存储在2i+1的位置, 以此类推<br>
此种存储方式, 是完全二叉树的话, 只浪费一个下标0的存储位置, 非完全二叉树的话, 会浪费更多的数组存储空间</li>
</ol>
<blockquote>
<p>所以一个树是完全二叉树的话, 用数组存储是最节省内存的一种方式, 也是为什么完全二叉树被单拎出来说明的原因.<br>
堆其实就是一种完全二叉树, 最常用的存储方式就是数组</p>
</blockquote>
<h3 id="二叉树的遍历">二叉树的遍历</h3>
<p>如何打印所有节点, 经典方法有三种:<br>
<strong>前序遍历</strong>, 对于树中的任意节点来说, 先打印这个节点, 再打印左子树, 最后打印右子树 (todo)<br>
<strong>中序遍历</strong>, 对于树中的任意节点来说, 先打印左子树, 再打印本身, 最后打印右子树 (todo)<br>
<strong>后序遍历</strong>, 对于树中的任意节点来说, 先打印左子树, 再打印右子树, 最后打印它本身 (todo)<br>
实际上二叉树的三种遍历, 就是一个递归的过程<br>
遍历的时间复杂度是O(n)<br>
不常用的遍历, 按层遍历 (todo)</p>
<h3 id="二叉查找树">二叉查找树</h3>
<p>也叫二叉搜索树<br>
特点, 支持动态数据集合的快速插入删除, 查找操作<br>
二叉查找树要求, 在树的任意一个节点, 其左子树中的每个节点的值, 都要小于这个节点的值, 而右子树节点的值, 都大于这个节点的值</p>
<ol>
<li>查找操作<br>
先取根节点, 等于就返回, 比根节点小就在左子树递归查找, 比根节点大就在右子树递归查找</li>
<li>插入操作<br>
新插入的数据一般在叶子节点上, 类似查找操作, 从根节点开始比较, 如果要插入数据比节点大, 并且节点的右子树为空, 则直接插到右子节点位置, 如果不为空, 再递归遍历右子树找位置, 如果数据比节点小, 同理遍历左子树查找位置</li>
<li>删除操作<br>
相对复杂, 分为三种情况<br>
第一种, 要删除节点没有子节点, 直接将父节点指针置为null<br>
第二种, 要删除节点有一个子节点, 更新父节点指针指向要删除节点的子节点<br>
第三种, 要删除的节点有两个子节点, 需要找到右子树中的最小节点, 替换到要删除的节点上, 然后删除掉这个最小节点</li>
<li>其他操作<br>
二叉查找树还支持快速的查找最大节点和最小节点, 前驱节点和后继节点<br>
重要特性, 中序遍历二叉查找树, 可以输出有序的数据序列, 时间复杂度O(n), 非常高效</li>
</ol>
<h4 id="支持重复数据的二叉查找树">支持重复数据的二叉查找树</h4>
<ul>
<li>第一种, 二叉查找树中每个节点不只存一个数据, 借助链表和支持动态扩容的数组等数据结构, 把值相同的数据存在同一个节点上</li>
<li>第二种, 每个节点仍然只存储一个数据, 插入时, 遇到值相同的节点, 就插入到这个节点的右子树, 也就是把这个数当作大于这个节点处理<br>
查找数据时, 遇到值相同的节点不停下, 继续在右子树查找, 直到遇到叶子节点, 就可以把所有值相等的节点找出来<br>
删除操作同理</li>
</ul>
<h4 id="二叉查找树的时间复杂度">二叉查找树的时间复杂度</h4>
<p>不同形态的二叉查找树时间复杂度不同, 时间复杂度和树的高度成正比, 也就是O(height)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-图</title>
    <url>/2021/03/04/20210304165625/</url>
    <content><![CDATA[<h2 id="图">图</h2>
<h3 id="简介-v7">简介</h3>
<p>图是一种非线性表数据结构, 比树更加复杂<br>
涉及图的算法有很多, 比如图的搜索, 最短路径, 最小生成树, 二分图等</p>
<h3 id="图的基本概念">图的基本概念</h3>
<p>图中的元素叫做<strong>顶点</strong>, 一个顶点可以与任意其他顶点建立连接关系, 这种建立的关系, 叫做<strong>边</strong><br>
跟顶点相连接的边的条数, 叫做顶点的<strong>度</strong><br>
图的边可以有方向, 边有方向的叫做<strong>有向图</strong>, 边没有方向的叫做<strong>无向图</strong><br>
有向图中, 把度分为<strong>入度</strong>和<strong>出度</strong>, 入度表示有多少条边指向这个顶点, 出度表示有多少条边是以这个顶点为起点指向别的顶点<br>
另一种图, <strong>带权图</strong>, 每条边都有一个权重</p>
<h3 id="图的存储">图的存储</h3>
<ol>
<li>邻接矩阵存储方法<br>
图最直观的一种存储方式就是邻接矩阵<br>
底层依赖一个二维数组, 对于无向图, 若顶点i到j之前有边, 则A[i][j]和A[j][i]都标为1, 对于有向图, 若顶点i到j之前有指向j的边, 则A[i][j]标为1, 带权图中数组存储相应的权重即可<br>
用邻接矩阵来表示一个图, 虽然简单直观, 但是比较浪费存储空间, 如果存储的是稀疏图(顶点非常多), 而每个顶点的边并不多, 则大部分空间都被浪费了<br>
优点是存储方式简单, 获取两个顶点的关系时非常高效, 其次是方便计算, 可以将很多图的运算转换成矩阵之间的计算</li>
<li>邻接表存储法<br>
邻接表有点像散列表, 每个顶点对应一条链表, 链表中存储的是与这个顶点相连接的其他顶点<br>
邻接表存储起来比较节省空间, 但使用起来就比较耗时间, 要查询是否存在一条顶点a到b的边, 就要遍历顶点a的链表<br>
为了提高查找效率, 这里的链表也可换成其他更高效的数据结构, 比如平衡二叉查找树, 跳表, 散列表等</li>
</ol>
<h3 id="深度优先和广度优先">深度优先和广度优先</h3>
<p>深度优先搜索算法和广度优先搜索算法都是基于图这个数据结构的, 因为图的表达能力强, 大部分涉及搜索的场景, 都可以抽象成图<br>
图上的搜索算法, 最直接的理解就是在图中找出从一个顶点出发到另一个顶点的路径<br>
其中最简单最暴力的两种搜索就是, <strong>深度优先搜索</strong>和<strong>广度优先搜索</strong></p>
<ol>
<li>广度优先搜索(BFS)<br>
其实就是一种地毯式层层推进的搜索策略, 先查找离起始顶点最近的, 然后是次近的, 依次往外搜索<br>
广度优先搜索需要借助队列来实现<br>
广度优先搜索找出来的是最短路径<br>
代码示例(todo)</li>
<li>深度优先搜索(DFS)<br>
类似走迷宫, 在分叉口随意选择一个节点, 直到走不通再回退<br>
深度优先搜索用的是一种比较著名的算法思想, 回溯思想, 借助栈来实现<br>
深度优先搜索找出来的不是最短路径<br>
代码示例(todo)</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-字符串匹配</title>
    <url>/2021/03/11/20210311164500/</url>
    <content><![CDATA[<h2 id="字符串匹配">字符串匹配</h2>
<h3 id="简介-v8">简介</h3>
<p>字符串匹配都不陌生, 例如Java中的indexOf(), Python中的find(), 他们底层就是依赖以下的字符串匹配算法<br>
我们从字符串A中查找字符串B, 则A就是<strong>主串</strong>, B就是<strong>模式串</strong><br>
字符串匹配算法很多, BF和RK比较简单, BM和KMP比较难但更高效, 这些都是单模式串匹配, Trie树和AC自动机可以多模式串匹配</p>
<h3 id="BF算法-Brute-Force">BF算法(Brute Force)</h3>
<p>中文叫暴力匹配算法, 也叫朴素匹配算法, 简单好懂但性能不高<br>
例如主串A长度n, 模式串B长度m<br>
核心就是在主串中, 检查起始位置分别是0, 1, 2 … n-m, 且长度为m的全部n-m+1个子串, 看有没有跟模式串匹配的<br>
时间复杂度最坏情况是每次对比m个字符, 对比n-m+1次, 为O(n*m), 看上去时间复杂度很高, 但实际开发中却是一个比较常用的字符串匹配算法<br>
两点原因</p>
<ul>
<li>大部分情况下, 模式串和主串的长度都不会太长, 且子串不匹配时不需要对比m个字符, 所以实际执行效率还可以</li>
<li>朴素字符串匹配算法思想简单, 代码实现也简单, 不容易出错, 符合KISS(Keep it Simple and Stupid)设计原则, 在满足性能要求的前提下, 简单是首选</li>
</ul>
<h3 id="RK算法-Rabin-Karp">RK算法(Rabin-Karp)</h3>
<p>名字由来是两位发明者Rabin和Karp, 这个算法也不难, 是上面BF算法的升级版<br>
算法思路是, 通过哈希算法对主串中的n-m+1个子串分别求哈希值, 然后逐个与模式串的哈希值比较大小, 因为哈希值是一个数字, 所以模式串和子串比较的效率就提高了<br>
具体实现起来重点在哈希算法的设计, 假设要匹配的字符串的字符集中只包含k个字符, 我们就可以用一个k进制数来表示一个字符串, 再把这个k进制数转成十进制数, 作为子串的哈希值<br>
再细处不讲了, 用到了自己查<br>
这种哈希算法有一个特点, 在主串中, 相邻两个子串的哈希值的计算公式有交集, 使用前一个子串的哈希值可以很快计算出下一个子串的哈希值<br>
时间复杂度, 计算子串哈希值部分, 扫描一遍主串即可, 所以O(n), 模式串与子串比较的时间复杂度O(1), 一共比较n-m+1个, 所以匹配部分时间复杂度也是O(n), RK算法的整体时间复杂度为O(n)<br>
当模式串很长时, 以上哈希算法结果可能会超过整型数据范围, 则可以适当允许散列冲突的出现, 极端情况时间复杂度会退化成O(n*m), 但一般基本不会出现</p>
<h3 id="BM算法-Boyer-Moore">BM算法(Boyer-Moore)</h3>
<p>它是一种非常高效的字符串匹配算法, 但原理复杂, 比较难懂, 在一些文本编辑器中应用较多<br>
核心思想: BF和RK算法都是遇到不匹配的字符时向后滑动一位继续对比, BM是根据自己的规则, 一次向后滑动好几位, 所以效率就提高了<br>
即当模式串和主串某个字符不匹配时, 能够跳过一些肯定不会匹配的情况, 将模式串往后滑动几位<br>
具体包含两部分:</p>
<ol>
<li><strong>坏字符规则(bad character rule)</strong><br>
在匹配过程中从模式串的末尾往前倒着匹配, 当发现某个字符没法匹配时, 把这个主串中的字符叫做坏字符<br>
然后拿坏字符在模式串中查找, 若模式串中不存在这个字符, 则可以直接将模式串滑动到这个字符后一位开始比较<br>
若坏字符在模式串中存在, 则把模式串滑动到坏字符和模式串的最后出现坏字符的位置对齐, 然后开始比较<br>
利用以上操作, BM算法在最好情况下的时间复杂度非常低, 可以降到O(n/m), 但只靠坏字符规则处理不了全部情况, 所以还需要好后缀规则(更复杂)</li>
<li><strong>好后缀规则(good suffix shift)</strong><br>
在匹配过程中可能后三个字符是匹配的, 到第四个字符不匹配了, 那么后三个字符就是好后缀记做u<br>
拿u在模式串中查找, 如果找到了相匹配的u*, 就把模式串滑动到u与u<em>对齐<br>
如果没有相匹配的u</em>, 但模式串的前缀有可能和u的部分有重合, 则滑动到重合部分对齐<br>
以上就是两个最重要的规则, 在匹配中遇到字符不匹配时, 分别计算以上两个规则向后滑动的位数, 取两个数中最大的<br>
代码实现(todo)</li>
</ol>
<h3 id="KMP算法-Knuth-Morris-Pratt">KMP算法(Knuth Morris Pratt)</h3>
<p>最知名的字符串匹配算法, 出了名的不好懂, 根据三位作者的名字来命名的(D.E.Knuth, J.H.Morris V.R.Pratt)<br>
核心思想和BM非常相近, 在模式串与主串匹配的过程中, 当遇到不可匹配的字符时, 找到一些规律将模式串往后多滑动几位, 跳过肯定不会匹配的情况<br>
不能匹配的那个字符依旧叫坏字符, 已经匹配的前面那段字符串叫作好前缀, 当遇到坏字符, 向后滑动时, 其实就是拿<strong>主串中的好前缀的后缀子串</strong>和<strong>模式串的好前缀的前缀子串</strong>比较,而主串的好前缀和模式串的好前缀是等价的, 说白了就是拿好前缀本身, 用它自己的后缀子串和前缀子串比较, 查找最长的那个相等的子串, 则这个子串, 在前缀里叫最长可匹配前缀子串, 在后缀里叫最长可匹配后缀子串<br>
而好前缀其实可以不涉及到主串, 单用模式串就能解决, 所以可以进行预处理, 在匹配过程中直接调用<br>
此处提前构造一个数组叫next, 也叫失效函数, 用来存储模式串中每个好前缀的符合上面条件的最长的可匹配前缀子串的最后一个字符的下标<br>
所以next数组下标就等于每个前缀最后一个字符的下标, 也就是好前缀的长度减一, 数组的值就是上面这个最长可匹配前缀子串结尾字符下标<br>
而KMP最复杂的部分, 就是next数组的预处理, 不过next数组里前一个元素和后一个元素是有联系的, 可以快速推导出来, 具体看<a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/string/kmp.scala#L42" target="_blank" rel="noopener">代码示例及注释</a><br>
空间复杂度O(m), m为模式串长度, 时间复杂度O(n+m)</p>
<h3 id="Trie树">Trie树</h3>
<p>一个专门处理字符串匹配的树形数据结构, 用来解决在一组字符串集合中快速查找某个字符串的问题<br>
Trie树的本质, 就是利用字符串之间的公共前缀, 将重复的前缀合并在一起, 构造成一颗多叉树, 根节点不存信息, 红色节点表示一个字符串的结尾<br>
Trie数主要有两个操作, 把字符串集构造成Trie树和在Trie树中查询一个字符串<br>
存储的话, 简单点可以用每个节点一个数组, 因为是多叉树, 可能有很多子节点, 对应到数组里的不同元素<br>
但Trie树比较耗内存, 用的是空间换时间的思路, 但确实非常高效, 而对于浪费内存的问题, 可以用有序数组, 跳表, 散列表, 红黑树等代替数组, 牺牲一点查询效率<br>
Trie树不适合精确匹配查找, 更适合查找前缀匹配的字符串, 比如各种自动补全, 比如输入法的联想输入, IDE的自动补全, 浏览器搜索的自动补全等</p>
<h3 id="AC自动机-Aho-Corasick">AC自动机(Aho-Corasick)</h3>
<p>AC自动机实际上就是在Trie树上加了类似KMP算法里的next数组, 把next数组构建在了树上, 即失败指针<br>
AC自动机可用于实现高效的敏感词过滤系统, 时间复杂度可近似于O(n), 性能非常高<br>
AC自动机的构建包含两个操作</p>
<ul>
<li>把多个模式串构建成Trie树</li>
<li>在Trie树上构建失败指针(具体原理和next数组十分相似)<br>
简单了解, 具体实现看代码示例(todo)</li>
</ul>
<h3 id="总结-v3">总结</h3>
<ul>
<li>BF算法, 简单易懂, 场景简单的情况下推荐使用</li>
<li>RK算法, 适用于字符集范围不大, 模式串不太长的情况</li>
<li>BM算法, 实现较复杂, 性能好, 编辑器中字符串查找应用较多, 据说最高效最常用</li>
<li>KMP算法, 最知名, 也很复杂, 和BM算法类似, 更稳定</li>
<li>Trie树, 因为树状结构, 适用于公共前缀较多场景, 比如自动补全, 浏览器预测输入等</li>
<li>AC自动机, 能做到大量文本中多模式精确匹配, 适用于敏感词过滤等</li>
</ul>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-常见算法思想 </title>
    <url>/2021/07/30/20210730193440/</url>
    <content><![CDATA[<h3 id="简介-v9">简介</h3>
<p>几种常见的算法思想, 用来指导我们设计具体的算法和编码, 有<br>
贪心算法, 分治算法, 回溯算法, 动态规划</p>
<h3 id="贪心算法-greedy-algorithm">贪心算法(greedy algorithm)</h3>
<p>经典应用, 霍夫曼编码, Prim和Kruskal最小生成树算法, Dijkstra单源最短路径算法<br>
经典问题, 背包问题, 固定容量下, 让背包里装的物品总价值最大, 贪心算法用法则是计算物品单价, 单价从高到低依次放入包中<br>
使用贪心算法解决问题的步骤</p>
<ul>
<li>第一步, 看到这类问题, 首先联想到贪心算法</li>
<li>尝试看下这个问题是否能用贪心算法解决</li>
<li>举例看下贪心算法产生的结果是否是最优解<br>
大部分能用贪心算法的问题, 结果都是正确的, 但也有解决不掉的问题, 比如前面的选择会影响后面的选择, 局部最优未必全局最优<br>
类似能用贪心算法解决的问题, 分糖果, 钱币找零, 区间覆盖等<br>
贪心算法最难的是如何将要解决的问题抽象成贪心算法模型, 后续的编码一般都很简单<br>
贪心算法解决问题的正确性虽然很多时候都很高, 但要严谨的证明算法能得到最优解, 并不容易</li>
</ul>
<h3 id="分治算法">分治算法</h3>
<p>分治算法核心思想就是四个字, 分而治之, 将原问题划分为n个规模较小, 并且结构与原问题相似的子问题, 递归的解决这些子问题, 然后再合并其结果, 就得到原问题的解<br>
有点类似递归, 分治算法是一种处理问题的思想, 递归是一种编程技巧, 分治算法一般都比较适合用递归来实现<br>
分治算法能解决的问题, 一般需要满足下面几个条件</p>
<ul>
<li>原问题与分解成的小问题具有相同的模式</li>
<li>原问题分解成的子问题可以独立求解, 子问题之前没有相关性(和动态规划的明显区别)</li>
<li>具有分解终止条件, 当问题足够小时, 可以直接求解</li>
<li>可以将子问题合并成原问题, 且合并操作复杂度不太高, 否则起不到减小算法总体复杂度的效果<br>
分治算法两种典型的应用场景</li>
<li>用来指导编码, 降低问题求解的时间复杂度</li>
<li>解决海量数据处理问题, 比如MapReduce</li>
</ul>
<h3 id="回溯算法">回溯算法</h3>
<p>之前的深度优先搜索算法利用的就是回溯思想, 这个算法思想简单却应用广泛<br>
比如正则表达式, 编译原理中的语法分析, 很多经典数学问题比如数独, 八皇后, 0-1背包, 图的着色, 旅行商问题, 全排列等等<br>
回溯的处理思想有点类似枚举搜索, 枚举出所有的解, 然后找到满足期望的解, 为了枚举所有可能的解, 避免遗漏和重复, 我们把问题求解的过程分为多个阶段<br>
每个阶段面对一个岔路口, 先随意选一条路走, 当发现这条路走不通, 就退回上一个岔路口, 选另一种走法继续走<br>
示例: 八皇后问题(todo), 0-1背包(todo)<br>
大部分情况下, 回溯算法都可以用来解决广义的搜索问题, 即从一组可能的解中, 选择一个满足要求的解<br>
回溯算法非常适合用递归来实现, 在实现的过程中, 剪枝操作是提高回溯效率的一种技巧</p>
<h3 id="动态规划">动态规划</h3>
<p><a href="http://www.wangdanpeng.com/2021/07/30/20210730193020/">单开一篇文章</a></p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-堆和堆排序</title>
    <url>/2021/03/02/20210302192117/</url>
    <content><![CDATA[<h2 id="堆和堆排序">堆和堆排序</h2>
<h3 id="简介-v10">简介</h3>
<p>堆, 是一种特殊的树<br>
经典的应用场景, 堆排序, 原地的时间复杂度为O(nlogn)的排序算法<br>
堆的两点定义:</p>
<ul>
<li>堆是一个完全二叉树</li>
<li>堆中每一个节点的值都必须大于等于/小于等于其子树中每个节点的值</li>
</ul>
<p>每个节点的值都大于等于子树中每个节点值的堆叫做大顶堆, 反之叫做小顶堆</p>
<h3 id="实现一个堆">实现一个堆</h3>
<p>之前说过完全二叉树适合用数组存储, 所以堆也用数组存储<br>
堆的核心操作有<strong>插入元素</strong>和<strong>删除堆顶元素</strong>, 以大顶堆为例</p>
<ol>
<li>插入元素(todo)<br>
把新插入的元素放到堆的最后, 并进行调整使其重新满足堆的特性的过程, 叫<strong>堆化(heapify)</strong><br>
堆化有两种, 从下往上和从上往下<br>
堆化非常简单, 就是顺着节点所在路径, 向上或者向下, 对比, 然后交换</li>
<li>删除堆顶元素(todo)<br>
为保证删除完还是一个完全二叉树, 把最后一个节点放到堆顶,<br>
然后利用同样的父子节点对比法, 对不满足父子节点大小关系的互换两个节点, 直到父子节点满足大小关系为止, 这就是从上往下的堆化</li>
</ol>
<p>一个包含n个节点的完全二叉树, 树的高度不会超过logn, 堆化的过程是顺着节点所在路径比较交换, 所以堆化的时间复杂度跟树的高度成正比, 也就是O(logn)<br>
插入数据和删除堆顶元素的主要逻辑就是堆化, 所以时间复杂度也是O(logn)</p>
<h3 id="堆排序">堆排序</h3>
<p>借助堆这种数据结构实现的排序算法, 叫做堆排序<br>
时间复杂度非常稳定, 是O(nlogn), 并且是原地排序<br>
堆排序的过程大致分为两个大步骤, <strong>建堆</strong>和<strong>排序</strong></p>
<ol>
<li>建堆<br>
建堆有两种思路:<br>
第一种, 借助插入元素的思路, 从下标2开始依次插入到堆中, 从前往后处理数据, 每个数据从下往上堆化, 代码示例(todo)<br>
第二种, 和第一种相反, 从后往前处理数组, 每个数据从上往下堆化, 代码示例(todo)</li>
<li>排序<br>
建堆结束后, 数组中的数据已经是按照大顶堆的特性来组织的, 第一个元素就是堆顶, 也是最大的元素<br>
然后采用类似删除堆顶元素的操作, 把堆顶元素和最后一个元素交换, 再堆化剩下n-1个元素, 然后重复交换, 堆化, 交换, 堆化…<br>
直到最后堆中只剩下一个元素, 排序工作就完成了, 代码示例(todo)</li>
</ol>
<p>整个排序过程中, 只需要极个别临时存储空间, 所以堆排序是原地排序算法<br>
堆排序包括建堆和排序两个操作, 建堆过程时间复杂度O(n), 排序过程时间复杂度O(nlogn), 所以堆排序整体时间复杂度是O(nlogn)<br>
堆排序不是稳定的排序算法, 因为排序过程中存在最后节点和堆顶节点交换操作, 可能会改变相同值的顺序</p>
<h3 id="堆排序和快排">堆排序和快排</h3>
<p>为什么快排比堆排序性能好</p>
<ol>
<li>堆排序数据访问方式是跳着访问, 对cpu缓存不友好, 快排数据是顺序访问</li>
<li>对于同样数据, 堆排序的数据交换次数比快排多, 建堆会打乱数据原有相对顺序</li>
</ol>
<h3 id="堆的应用">堆的应用</h3>
<ol>
<li><strong>优先级队列</strong><br>
在优先级队列中, 优先级最高的最先出队, 用堆来实现是最直接, 最高效的<br>
往优先级队列插入元素等于往堆中插入一个元素, 从优先级队列取出优先级最高元素, 等于取出堆顶元素<br>
优先级队列应用场景非常多, 比如赫夫曼编码, 图的最短路径, 最小生成树算法等</li>
<li><strong>求Top K</strong><br>
可以维护一个大小为k的小顶堆, 遍历数据, 依次和堆顶元素比较, 如果比堆顶元素大, 就把堆顶元素删除, 将新元素插入堆中<br>
如果比堆顶元素小, 就不作处理继续遍历, 等数据遍历完, 堆中就是前k大的数据</li>
<li><strong>求中位数</strong><br>
对于静态数据, 中位数是固定的, 可以先排序, 第n/2个数据就是中位数, 但对于动态数据集合, 每次排序效率就很低<br>
所以借助堆这种数据结构, 不用排序就可以非常高效的实现求中位数操作<br>
我们维护两个堆, 前半部分数据存储一个大顶堆, 后半部分数据存储一个小顶堆, 且小顶堆中的数据都大于大顶堆中的数据<br>
这样, 大顶堆的堆顶元素就是我们要的中位数<br>
每当新添加数据, 如果数据小于等于大顶堆的堆顶, 就插入到大顶堆, 反之插入到小顶堆, 且从这个堆向另一个堆移动数据, 维护两个堆的数据个数的平衡<br>
同理, 此方法可计算各个百分位数据, 比如80百分位数, 99百分位数等</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-散列表(Hash表)</title>
    <url>/2020/12/07/20201207185658/</url>
    <content><![CDATA[<h2 id="散列表-Hash表">散列表(Hash表)</h2>
<h3 id="简介-v11">简介</h3>
<p>散列表依赖的是数组支持按下标随机访问数据的特性<br>
所以散列表是数组的一种扩展, 由数组演化而来, 如果没有数组就没有散列表<br>
时间复杂度O(1), 通过散列函数把元素的key映射为下标, 将数据存储在数组中对应下标的位置<br>
当按key查询元素时, 用同样的散列函数, 将key转化为下标, 从对应的数组下标位置取数据</p>
<h3 id="设计散列表">设计散列表</h3>
<p>要可以应对各种异常情况的工业级</p>
<ol>
<li>散列函数的设计不能太复杂<br>
散列函数设计的好坏直接决定散列表的性能<br>
散列函数生成的值要尽可能随机且均匀分布<br>
散列函数计算结果是非负整数, 因为数组下标从0开始<br>
如果key1 = key2, 那么hash(key1)=hash(key2)</li>
<li>选择解决冲突的办法<br>
再好的散列函数也无法避免散列冲突, 所以常用的解决冲突方法有两类<br>
(1)开放寻址法<br>
核心思想就是, 如果出现了散列冲突, 就重新探测一个空闲位置, 那么如何探测<br>
线性探测, 当前位置被占用, 就依次向后查找, 直到找到为止<br>
二次探测, 类似线性探测, 不过步长每次移原来的二次方<br>
双重散列, 使用一组散列函数, 一个位置被占用, 再使用第二个散列函数, 直到找到空闲位置<br>
但问题是, 当散列表中空闲位置越少, 冲突概率就越大, 为保证效率, 一般会保证散列表中有一定比例的空闲位置, 用装载因子(填入元素个数/散列表长度)来表示<br>
当数据量小, 装载因子小的时候适合<br>
(2)链表法<br>
更常用的解决冲突办法, 而且简单<br>
数组每个下标里对应一条链表, 插入元素时, 通过散列函数, 确定链表, 将数据插入对应的链表中<br>
时间复杂度和链表的长度成正比, O(k)<br>
适合存储大对象, 大数据量的散列表, 支持更多的优化策略, 比如链表过长时用红黑树代替链表</li>
<li>定义转载因子阈值, 设计动态扩容策略<br>
避免低效扩容<br>
当装载因子达到阈值, 申请新的空间, 每当有新数据插入, 将新数据插入到新散列表, 并从老散列表拿一个数据插入新散列表, 就可以逐渐全部转移且感受不到特别慢的扩容过程<br>
当查询时, 先查新散列表, 没找到再查旧散列表</li>
</ol>
<h3 id="Java中的HashMap">Java中的HashMap</h3>
<p>初始大小16<br>
装载因子0.75, 每次扩容至两倍<br>
冲突解决方法为链表法, 当链表长度超过8转换为红黑树<br>
散列函数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> h = key.hashCode()； </span><br><span class="line">    <span class="keyword">return</span> (h ^ (h &gt;&gt;&gt; <span class="number">16</span>)) &amp; (capicity -<span class="number">1</span>); <span class="comment">//capicity表示散列表的大小</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="散列表碰撞攻击">散列表碰撞攻击</h3>
<p>通过精心构造的数据使得所有数据经过hash函数以后都散列到一个槽里, 如果使用的基于链表的冲突解决方案, 散列表就会退化为链表,<br>
数据里极大时会导致查询消耗大量cpu和线程资源, 造成系统无法响应其他请求</p>
<h3 id="散列表和链表常用组合场景">散列表和链表常用组合场景</h3>
<ul>
<li>LRU缓存淘汰算法<br>
使用双向链表存储数据, 链表中每个结点包含数据(data), 前驱指针(prev), 后继指针(next), 和hnext<br>
使用链表法解决的散列表, 包含两条链, 一条双向链表, 一条散列表的拉链<br>
可实现O(1)时间复杂度内完成插入删除查找操作</li>
<li>java LinkeHashMap<br>
支持按照插入顺序遍历数据, 和按照访问顺序遍历数据<br>
链表结合散列表, 原理和LRU一样, Linked指的是双向链表</li>
</ul>
<p>两者结合, 散列表提供快速的插入删除查找, 链表提供有序</p>
<h3 id="小结">小结</h3>
<p>工业级散列表应该具有哪些特性<br>
支持快速查询, 插入, 删除操作<br>
内存占用合理, 不浪费过多的内存空间<br>
性能稳定, 极端情况下散列表的性能也不会退化到无法接受的情况</p>
<h3 id="课后思考">课后思考</h3>
<p>10w条url访问日志, 按照访问次数排序 (todo)<br>
两个10w条字符串的数组, 快速找出两个数组中相同的字符串 (todo)</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>散列表</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-数组</title>
    <url>/2020/09/01/20200901160919/</url>
    <content><![CDATA[<h2 id="数组">数组</h2>
<p>基础数据结构</p>
<h3 id="定义">定义</h3>
<p>数组是一种<strong>线性表</strong>数据结构, 使用一组<strong>连续内存空间</strong>, 存贮一组具有<strong>相同类型的数据</strong>.<br>
提炼两组关键词:<br>
<em><strong>1. 线性表</strong></em><br>
线性表只有前后两个方向, 同样线性表还有链表, 队列, 栈.<br>
非线性表有二叉树, 堆, 图等, 数据并不是前后关系.<br>
<em><strong>2. 连续内存空间和相同类型的数据</strong></em><br>
因为这两个限制, 数组拥有了随机访问的特性, 但也有利有弊, 插入和删除操作变得低效.</p>
<p>数组插入操作平均时间复杂度O(n), 当数据无序时, 可将插入位置元素直接搬到末尾来优化执行速度.<br>
数组删除操作平均时间复杂度O(n), 当不追求数据连续性时, 可先记录已删除数据, 当数据没有空间时, 再出发真正的删除, 类似jvm的标记清除垃圾回收算法.</p>
<h3 id="链表和数组的区别">链表和数组的区别</h3>
<p>链表插入删除时间复杂度O(1), 数组根据下标随机访问时间复杂度O(1).</p>
<h3 id="选容器还是数组">选容器还是数组</h3>
<p>关于编程语言中包装好的容器, 比如java中的ArrayList, 该如何选择<br>
数组可存储基础数据类型, 且性能更好, 但容器更方便易用, 所以<br>
业务开发中可使用容器, 省时省力; 底层开发时, 如需要性能优化到极致, 可使用数组.</p>
<h3 id="为什么数组下标从0开始">为什么数组下标从0开始</h3>
<p>下标也是在内存上的偏移量, 寻址的时候可以直接首地址+偏移量*type_size, 如果下标从1开始, 则需要多做一次减法运算, 对于数组这种最基础的数据结构, 为了性能, 选择从0开始编号. (也可能不是, 无从求证)</p>
<h2 id="特别应用">特别应用</h2>
<h3 id="差分数组">差分数组</h3>
<p>给定一个数组a</p>
<table>
<thead>
<tr>
<th>下标</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
</tr>
</thead>
<tbody>
<tr>
<td>a(i)</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>4</td>
<td>9</td>
<td>7</td>
<td>9</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>要求从下标1到下标6, 每个数加1, 最傻瓜的办法就是遍历, 但如果数组有上千万个数, 且经常需要类似的区间修改, 遍历就有点费时费力了</p>
<p>所以就需要用到<strong>差分数组</strong>, 通过预处理原数组a, 得到一个新数组d, 大小和原数组相等, 每一个元素<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>(</mo><mi>i</mi><mo>)</mo><mo>=</mo><mi>a</mi><mo>(</mo><mi>i</mi><mo>)</mo><mo>−</mo><mi>a</mi><mo>(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo>)</mo><mo separator="true">,</mo><mo>(</mo><mi>i</mi><mo>!</mo><mo>=</mo><mn>0</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">d(i)=a(i)-a(i-1),(i!=0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">d</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">a</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span><span class="mbin">−</span><span class="mord mathit">a</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mbin">−</span><span class="mord mathrm">1</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">!</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mclose">)</span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>(</mo><mn>0</mn><mo>)</mo><mo>=</mo><mi>a</mi><mo>(</mo><mn>0</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">d(0)=a(0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">d</span><span class="mopen">(</span><span class="mord mathrm">0</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">a</span><span class="mopen">(</span><span class="mord mathrm">0</span><span class="mclose">)</span></span></span></span><br>
即每个位置上记录的是当前位置和前一位数据的差值</p>
<table>
<thead>
<tr>
<th>下标</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
</tr>
</thead>
<tbody>
<tr>
<td>a(i)</td>
<td>1</td>
<td>2</td>
<td>5</td>
<td>4</td>
<td>9</td>
<td>7</td>
<td>9</td>
<td>0</td>
</tr>
<tr>
<td>d(i)</td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>-1</td>
<td>5</td>
<td>-2</td>
<td>3</td>
<td>-9</td>
</tr>
</tbody>
</table>
<p>构造好以后, 再看从下标1到下标6加一, 不需要遍历, 只需要给d(1)+1, 再给d(7)-1, 中间的所有元素都自动加了1<br>
<strong>优点是</strong>: 适用于区间范围较大, 区间频繁修改<br>
<strong>缺点是</strong>: 查询数组a某个位置数据时, 需要根据差分数组从前向后求和</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-栈</title>
    <url>/2020/11/25/20201125150101/</url>
    <content><![CDATA[<h2 id="栈">栈</h2>
<h3 id="基本特性">基本特性</h3>
<p>后进者先出, 先进者后出, 这就是典型的栈结构<br>
栈是一种操作受限的线性表, 只允许在一端插入和删除数据<br>
栈是一种特定的数据结构,是对特定场景的抽象<br>
当某个数据集合只涉及在一端插入和删除数据, 并且满足后进先出, 先进后出的特性, 我们就应该首选栈这种数据结构</p>
<h3 id="实现一个栈">实现一个栈</h3>
<p>栈主要包含两个操作, 入栈和出栈<br>
<a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/struct/stack/ArrayStack.scala" target="_blank" rel="noopener">用数组实现的栈叫顺序栈</a><br>
用链表实现的栈叫链式栈 (todo)<br>
两种实现的空间复杂度和时间复杂度都为O(1)</p>
<h3 id="栈的应用">栈的应用</h3>
<ol>
<li>函数调用栈<br>
操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈</li>
<li>表达式求值<br>
一个保存操作数的栈，一个保存运算符的栈。从左向右遍历表达式，当遇到数字，就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较<br>
如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取两个操作数，然后进行计算，再把计算完的结果压入操作数栈</li>
<li>检测括号匹配<br>
扫描到左括号入栈, 扫描到右括号从栈顶取一个元素匹配</li>
<li>浏览器前进后退功能<br>
两个栈实现, 首次浏览页面压入后退栈, 点击后退按钮将后退栈元素出栈压入前进栈</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-排序</title>
    <url>/2020/12/01/20201201164903/</url>
    <content><![CDATA[<h2 id="排序">排序</h2>
<h3 id="简介-v12">简介</h3>
<p>排序算法有很多, 最经典最常用的有<br>
冒泡排序, 插入排序, 选择排序, 时间复杂度 O(n平方)<br>
快速排序, 归并排序, 时间复杂度O(nlogn)<br>
桶排序, 计数排序, 基数排序, 时间复杂度O(n)</p>
<h3 id="分析排序算法">分析排序算法</h3>
<ul>
<li>执行效率</li>
</ul>
<ol>
<li>最好情况, 最坏情况, 平时情况时间复杂度</li>
<li>时间复杂度的系数, 常数, 低阶</li>
<li>元素比较次数和移动次数</li>
</ol>
<ul>
<li>内存消耗<br>
可以通过空间复杂度来衡量</li>
<li>稳定性<br>
稳定排序算法可以保持数值相同的两个对象, 在排序之后的前后顺序不变<br>
真实开发中排序场景往往比较复杂, 有些问题借助稳定排序算法可以非常简洁的解决</li>
</ul>
<h3 id="冒泡排序"><a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/sort/bubble.scala" target="_blank" rel="noopener">冒泡排序</a></h3>
<p>冒泡过程只涉及相邻数据的交换操作, 所以空间复杂度为O(1), 是一个原地排序算法<br>
且当相邻的两个元素大小相等时不交换, 相同大小的数据在排序前后不会改变顺序, 所以冒泡排序是稳定的排序算法<br>
最好的情况数据有序, 时间复杂度O(n), 最坏的情况数据倒序, 时间复杂度O(n平方), 平均时间复杂度为O(n平方)</p>
<h3 id="插入排序"><a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/sort/insertion.scala" target="_blank" rel="noopener">插入排序</a></h3>
<p>将数组中的元素分为已排序区和未排序区, 取未排序区元素在已排序区找到合适的位置插入, 并保证已排序区数据一直有序, 直至未排序区为空<br>
插入排序运行也不需要额外的存储空间, 所以空间复杂度是O(1), 是一个原地排序算法<br>
排序时, 对于值相同的元素可以选择将后面出现的元素插入到前面出现的元素的后面, 所以是稳定的排序算法<br>
最好的情况数据有序, 时间复杂度O(n), 最坏的情况数据倒序, 时间复杂度O(n平方), 平均时间复杂度为O(n平方)</p>
<h3 id="选择排序-todo">选择排序 (todo)</h3>
<p>选择排序类似插入排序, 分已排序区和未排序区, 但每次会从未排序区找到最小元素, 交换位置放到已排序区末尾<br>
选择排序一样空间复杂度为O(1), 是一种原地排序算法<br>
最好最坏和平均时间复杂度都是O(n平方)<br>
因为存在交换位置, 所以选择排序不是一种稳定的排序算法,</p>
<blockquote>
<p>以上三种时间复杂度较高, 适合小规模数据排序<br>
选择排序不是稳定排序算法, 所以稍逊色于冒泡排序和插入排序, 而冒泡排序的数据交换要比插入排序的数据移动复杂, 所以这三种排序, 插入排序更为常用</p>
</blockquote>
<h3 id="归并排序-todo">归并排序 (todo)</h3>
<p>核心思想, 先把数组从中间分成两部分, 然后对前后两部分排序, 再将排好序的两部分合并, 就得到有序的完整数组<br>
归并排序使用的分治思想, 分治是一种解决问题的处理思想, 递归是一种编程技巧<br>
用递归代码来实现归并排序<br>
归并排序合并过程中, 值相同的元素可以自己掌握顺序, 所以是一个稳定的排序算法<br>
时间复杂度为O(nlogn), 且执行效率与原始数组有序度无关, 最好最坏平均情况都是O(nlogn)<br>
但不是原地排序算法, 空间复杂度为O(n)</p>
<h3 id="快速排序-todo">快速排序 (todo)</h3>
<p>也采用分治思想<br>
假如要排序的数组, 最左下标为’左’, 最右下标为’右’, 选中间任意一个点为分区点, 下标’中’<br>
遍历从左到右, 将小于’中’的放到左边, 大于’中’的放到右边, 数组就被分成了三部分, '左’到’中-1’的都是小于’中’下标的元素的, ‘中+1’到’右’都是大于’中’下标元素的<br>
根据分治思想, 用递归继续排序’左’到’中-1’和’中+1’到’右’, 直到区间缩小为1, 则所有数据有序, 具体实现方法看源码<br>
原地, 不稳定排序算法, 分区过程中有交换操作, 所以相同元素顺序会变<br>
时间复杂度O(nlogn), 但分区极其不均匀的情况会退化为O(n平方), 平均O(nlogn)<br>
常用选取分区点的算法</p>
<ol>
<li>三数取中法, 从头尾中取三个数, 对比大小取中间值作为分区点</li>
<li>随机法, 随机选择一个元素做为分区点</li>
</ol>
<blockquote>
<p>以上, 快排和归并很相似, 区别是归并排序是从下向上处理, 先处理子问题再合并, 快排是由上到下, 先分区, 再处理子问题<br>
归并时间复杂度稳定但空间复杂度高, 快排空间复杂度低, 且通过合理选择分区点可以避免时间复杂度退化为O(n平方), 所以快排应用更广泛</p>
</blockquote>
<h3 id="桶排序-todo">桶排序 (todo)</h3>
<p>核心思想把要排序的数据分到几个有序的桶里, 每个桶里的数据再单独排序, 之后按顺序依次取出<br>
桶排序对排序数据要求苛刻, 要能很容易划分成m个桶, 且桶之间有大小顺序, 其次各个桶之间的数据分布均匀<br>
桶排序比较适合用在外部排序中, 即数据存储在外部磁盘, 数据量大, 内存有限<br>
比如10G订单数据, 内存100MB排序问题, 可用桶排序划分订单数据, 每个桶生成一个文件, 如果桶间数据不均匀, 找到较大的文件, 继续分桶, 直到所有文件都能读入内存</p>
<h3 id="计数排序-todo">计数排序 (todo)</h3>
<p>计数排序是桶排序的一种特殊情况<br>
当数据范围不大时, 最大值为k, 就分k个桶, 省去桶内排序时间, 如果k要比排序的元素个数大得多, 则不适合用计数排序<br>
和桶排序非常相似, 只是桶的大小粒度不一样<br>
实现细节稍微复杂, 见代码<br>
计数排序只能给非负整数排序, 如有其它类型, 则想办法在不改变相对大小前提下转化为非负整数</p>
<h3 id="基数排序-todo">基数排序 (todo)</h3>
<p>基数排序对数据有要求, 需要可以分割出独立的位来比较, 且位之间有递进的关系, 从后向前一位一位进行线性排序<br>
另外, 每一位的数据范围不能太大, 要可以用线性排序算法来排序, 否则时间复杂度就大于O(n)了<br>
针对长度不一样的, 可以在前面或后面补0<br>
比较两个数只需要比较高位, 高位相同再比较低位</p>
<blockquote>
<p>以上三种都是线性时间复杂度的排序算法, 它们对要排序的数据有要求, 所以应用不是很广泛, 但如果数据特征匹配, 会非常高效, 时间复杂度可达O(n), 都是稳定非原地排序</p>
</blockquote>
<h3 id="总结-v4">总结</h3>
<p>以上都是理论知识, 生产环境中使用的排序函数通常都不是基于一种排序算法, 比如数据量小用归并排序, 数据量大用快排, 快排到区间内元素较少时改用插入排序<br>
为了尽可能提高性能, 通常会做很多优化</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-递归</title>
    <url>/2020/11/26/20201126191531/</url>
    <content><![CDATA[<h2 id="递归">递归</h2>
<h3 id="基本介绍">基本介绍</h3>
<p>递归是一种应用非常广泛的, 高效简洁的编程技巧, 很多数据结构和算法的编码实现都要用到递归</p>
<h3 id="递归需要满足的三个条件">递归需要满足的三个条件</h3>
<ol>
<li>一个问题的解可以分解为几个子问题的解</li>
<li>原问题和分解后的子问题求解思路完全一致</li>
<li>存在递归终止条件</li>
</ol>
<h3 id="写递归代码的关键">写递归代码的关键</h3>
<p>写递归代码的关键就是找如何将大问题分解成小问题的规律, 并且基于此写出<strong>递推公式</strong>, 然后推敲<strong>终止条件</strong>, 最后将递推公式和终止条件翻译成代码<br>
只要遇到递归, 就把他抽象成一个递推公式, 不用想一层层的调用关系, 不要试图用人脑去分析递归的每一个步骤</p>
<h3 id="递归常见问题">递归常见问题</h3>
<ol>
<li>
<p>堆栈溢出<br>
如果递归求解的数据规模很大, 调用层次很深, 一直将临时变量压入内存栈, 就会有堆栈溢出的风险<br>
解决办法就是限制最大的调用深度</p>
</li>
<li>
<p>重复计算<br>
为了避免重复计算, 可以通过一个比如散列表来保存已经求解过的f(n), 当调用到f(n)时, 查找是否已经求解过, 如果是则直接取值, 可避免重复计算</p>
</li>
<li>
<p>其他还有函数调用耗时高, 空间复杂度高等问题, 在编写代码时, 要控制好这些副作用</p>
</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-红黑树</title>
    <url>/2021/02/24/20210224155253/</url>
    <content><![CDATA[<h2 id="红黑树">红黑树</h2>
<p>一般讲到平衡二叉查找树, 都会拿红黑树作为例子, 工程中, 很多用到平衡二叉查找树的地方都会用到红黑树<br>
但凡用到动态插入, 删除, 查找数据的场景, 都可以用到它, 不过自己实现起来难度有点高</p>
<h3 id="什么是平衡二叉查找树">什么是平衡二叉查找树</h3>
<p>平衡二叉树定义: 二叉树中任意一个节点的左右子树的高度相差不能大于1.<br>
完全二叉树, 满二叉树, 都是平衡二叉树</p>
<p>平衡二叉查找树不仅满足上面定义, 还满足二叉查找树的特点<br>
最先被发明的平衡二叉查找树是AVL树</p>
<p>但很多平衡二叉查找树并没有严格符合上面的定义, 比如红黑树<br>
设计初衷是解决, 普通二叉查找树在频繁的插入, 删除等动态更新的情况下, 出现时间复杂度退化的问题<br>
平衡二叉查找树就是让整棵树左右看起来比较平衡, 不要出现左子树高右子树矮的情况, 这样能让整棵树的高度相对低一些, 相应的插入删除查找操作效率高一些.</p>
<h3 id="定义一棵红黑树">定义一棵红黑树</h3>
<p>红黑树(Red-Black Tree), 简称R-B Tree, 是一种不严格的平衡二叉查找树<br>
红黑树的节点, 一类被标记为黑色, 一类被标记为红色, 且要满足</p>
<ul>
<li>根节点是黑色的</li>
<li>每个叶子节点都是黑色的空节点, 即叶子节点不存储数据</li>
<li>任何相邻节点都不能同时为红色, 即红色节点是被黑色节点隔开的</li>
<li>每个节点, 从该节点到达其可到达叶子节点的所有路径, 都包含相同数目的黑色节点</li>
</ul>
<h3 id="为什么用红黑树">为什么用红黑树</h3>
<p>为什么用红黑树不用其他平衡二叉查找树<br>
Treap, Splay Tree无法避免极端情况下时间复杂度的退化<br>
AVL树查找效率非常高, 但为了维护这种高度平衡, 每次插入删除都要调整, 比较复杂耗时, 对于有频繁插入删除操作的数据集合, 使用AVL树代价有点高<br>
红黑树只做到了近似平衡, 在维护平衡成本上比AVL树要低, 且插入删除查找操作性能都比较稳定, 对于工程应用要面对各种异常情况, 所以更倾向于这种性能稳定的</p>
<h3 id="实现一棵红黑树-不是">实现一棵红黑树 (不是</h3>
<p>大可不必, 左右旋背个滚瓜烂熟过几天就忘<br>
红黑树的叶子节点都是黑色的空节点, 是为了方便代码实现, 方便套用平衡公式<br>
红黑树平衡过程类似魔方复原, 有几个公式, 在插入删除节点过程中, 会破坏红黑树定义的第三四条, 所以使用平衡公式来恢复<br>
插入操作平衡公式有三个, 删除操作平衡公式有七个, 插入操作的平衡调整比较简单, 但删除操作就比较复杂<br>
详细实现步骤, 用到以后再去搜, 对照着实现即可</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-跳表</title>
    <url>/2020/12/02/20201202170715/</url>
    <content><![CDATA[<h2 id="跳表-Skip-List">跳表(Skip List)</h2>
<h3 id="简介-v13">简介</h3>
<p>基于链表稍加改造的一种各方面性能都比较优秀的动态数据结构, 可支持快速插入, 删除, 查找操作, 甚至可以代替红黑树<br>
基于原链表每两个结点向上一级抽索引, 构建出一级索引层, 可构建多级索引, 这种链表加多级索引的结构, 就是跳表<br>
redis中的有序集合(sorted set)就是采用跳表实现</p>
<p>跳表中查询任意数据的时间复杂度都是O(logn), 但空间复杂度O(n), 每三到五个元素抽一个索引可以减少索引存储空间占用<br>
但实际开发中不必太在意索引占用的额外空间, 因为当原始链表中存储的为对象时, 索引中存储的指针和对象相比, 占用空间可以忽略</p>
<h3 id="插入删除">插入删除</h3>
<p>跳表还支持动态的插入和删除操作, 时间复杂度也是O(logn)<br>
但插入元素同时, 需要维护索引的平衡, 采用随机函数的方式, 将此结点同时插入到第一层到第k层索引中<br>
删除操作, 同样需要删除掉索引中的结点</p>
<h3 id="代码实现-todo">代码实现 (todo)</h3>
<h3 id="小结-v2">小结</h3>
<p>跳表采用空间换时间的设计思路, 通过多级索引提高查询效率, 实现了基于链表的二分查找<br>
跳表虽然本身不简单, 但相对红黑树的实现还是简单不少, 有时为了代码简单易读, 相比红黑树会使用跳表<br>
跳表更加灵活, 通过改变索引构建策略, 可以有效平衡执行效率和内存消耗</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>跳表</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-队列</title>
    <url>/2020/11/25/20201125170035/</url>
    <content><![CDATA[<h2 id="队列">队列</h2>
<h3 id="基本特性-v2">基本特性</h3>
<p>先进者先出, 这就是典型的队列<br>
和栈很相似, 队列的基本操作也是两个, 入队和出队<br>
和栈一样也是一种操作受限的线性表数据结构</p>
<h3 id="实现一个队列">实现一个队列</h3>
<p>用数组实现的队列叫顺序队列 (todo)<br>
用链表实现的队列叫链式队列 (todo)</p>
<h3 id="队列的应用">队列的应用</h3>
<ol>
<li>阻塞队列<br>
队列为空时取数据被阻塞, 队列满时, 插入数据被阻塞, 即生产者消费者模型</li>
<li>并发队列<br>
多线程的情况下, 线程安全的队列叫并发队列, 基于数组的循环队列, 利用CAS原子操作, 可实现非常高效的并发队列, 因此循环队列比链式队列应用更加广泛</li>
</ol>
<h3 id="小结-v3">小结</h3>
<p>队列可以应用在任何有限资源池中, 用于排队请求</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构学习笔记-链表</title>
    <url>/2020/09/03/20200903153417/</url>
    <content><![CDATA[<h2 id="链表">链表</h2>
<p>比数组稍微复杂一点的数据结构</p>
<h3 id="简介">简介</h3>
<p>不需要连续的内存空间, 通过指针将一组零散的内存块串联起来使用.<br>
链表结构五花八门, 三种最常见的链表结构, <strong>单链表</strong>, <strong>双向链表</strong>, <strong>循环链表</strong>.</p>
<h3 id="单链表">单链表</h3>
<p>被串联的内存块称为结点, 每个结点存有<strong>数据</strong>和记录<strong>下一个结点的地址</strong>, 叫做后继指针next<br>
第一个结点叫头结点, 最后一个结点叫尾结点, 尾结点指向一个空地址null.</p>
<p>链表也支持数据的查找, 插入和删除操作<br>
链表的插入和删除操作只需要考虑相邻接点的指针改变, 所以时间复杂度为O(1).<br>
但想要随机访问第k个元素, 就需要一个一个结点遍历, 需要O(n)的时间复杂度.</p>
<h3 id="循环链表和双向链表">循环链表和双向链表</h3>
<p>循环链表是一种特殊的单链表, <strong>尾结点指向链表的头结点</strong>.<br>
优点是从链尾到链头比较方便, 当要处理的数据有环形结构时, 就适合采用循环链表, 比如约瑟夫问题(todo)</p>
<p>双向链表支持两个方向, 每个结点不只有一个<strong>后继指针next</strong>, 还有一个<strong>前驱指针prev</strong>.<br>
双向链表需要额外的空间存储后继结点和前驱结点地址, 如果存储同样多的数据, 双向链表比单链表占用更多的内存空间.<br>
双向链表可以O(1)的时间复杂度找到前驱结点, 因此某些情况下, 双向链表的插入删除等操作比单链表更简单高效.</p>
<p>常见的删除操作有两种:</p>
<ol>
<li>删除结点中值等于给定值的结点</li>
<li>删除给顶指针指向的结点</li>
</ol>
<p>对于第一种, 单链表和双向链表的时间复杂度都是O(n), 但对于第二种, 双向链表的时间复杂度为O(1),<br>
同理, 在链表的某个指定结点前插入一个结点时, 双向链表的时间复杂度也是O(1).<br>
另外, 对于有序链表, 双向链表的按值查询效率也高一些.</p>
<p><strong>双向链表尽管比较费内存, 但比单链表应用更广泛, 比如java中的LinkedHashMap容器, 就用到了双向链表, 即空间换时间策略.</strong></p>
<h3 id="和数组的比较">和数组的比较</h3>
<p>插入, 删除, 随机访问的时间复杂度正好相反.<br>
数组简单易用, 可借助cpu缓存机制预读数组中的数据, 访问效率更高, 缺点是大小固定, 不能动态扩容.</p>
<h3 id="写链表代码技巧">写链表代码技巧</h3>
<ol>
<li>理解指针或引用含义<br>
将某个变量赋值给指针, 实际上是将这个变量的地址赋值给指针.</li>
<li>警惕指针丢失和内存泄漏<br>
插入节点时, 一定要注意操作顺序.</li>
<li>利用哨兵简化实现难度<br>
针对链表的插入删除操作, 需要对插入头结点和删除尾结点特殊处理, 所以可插入一个不带数据的哨兵结点, 这种链表被称为带头链表.</li>
<li>重点留意边界条件处理<br>
比如链表为空, 只有一个结点, 有两个结点, 处理头结点和尾结点时.</li>
<li>举例画图, 辅助思考<br>
画图法和举例法, 帮助理清思路</li>
<li>多写多练<br>
<a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/struct/link/ReverseSingleLink.scala" target="_blank" rel="noopener">单链表反转</a><br>
链表中环的检测 (todo)<br>
两个有序的链表合并 (todo)<br>
删除链表倒数第n个结点 (todo)<br>
求链表的中间结点 (todo)<br>
<a href="https://github.com/WangDanpeng/Vamos/blob/main/src/main/scala/wdp/struct/link/LRU.scala" target="_blank" rel="noopener">基于链表实现LRU缓存淘汰算法</a><br>
单链表字符串, 判断是一个回文串 (todo)</li>
</ol>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>算法题-海盗分赃</title>
    <url>/2018/11/27/20181127102854/</url>
    <content><![CDATA[<blockquote>
<p><strong>6个海盗要分赃300金币。规则是由资格最老的海盗提出各人分到的数量，然后全体投票。如方案得到至少半数同意票，则按该方案执行，否则提出方案的海盗被杀死，再由剩下人中资格最老的继续提出方案。海盗都很聪明，在能生存的前提下会追求获利最大化。问最后分赃结果是怎样的?</strong></p>
</blockquote>
<p>这道题详细的解题步骤一搜就有, 我只说一下我自己的理解.</p>
<h2 id="两个人">两个人?</h2>
<p>首先还是需要简化这道题, 假如只有两个人, 应该怎么分<br>
<img src="http://www.wangdanpeng.com/img/20181127102854-1.png" alt="two"><br>
因为只要投票得到半数就可通过, 只有两个人时, 老大不管怎么分, 只要自己同意, 就可以通过, 所以他一定会分给自己300金, 一毛都不给老二.</p>
<h2 id="三个人">三个人?</h2>
<p>那么假如有三个人呢?, 想要投票通过, 就必须有两个人同意才行, 那么现在来分析一下这三个人里有谁是利益相关的<br>
老大和老二 -&gt; 只要老大死了, 老二能得到全部的300金<br>
老二和老三 -&gt; 老二可以承诺给老三多少钱一起搞死老大, 但是老大如果死了, 老二做主, 自己可能一毛也拿不到<br>
老大和老三 -&gt; 老大和老三联手, 老三一定能拿到钱<br>
<img src="http://www.wangdanpeng.com/img/20181127102854-2.png" alt="three"><br>
这种情况下, 老大即使给老三1金, 老三也是愿意支持老大的, 最后结果就是老大299金, 老二0, 老三1金</p>
<h2 id="六个人">六个人?</h2>
<p>从上面三个人可以得出结论, 相邻的两个人是死敌关系, 想要半数票通过, 一定不能收买相邻的人, 那么老大只需要收买老三和老五, 他们就一定会同意, 最后老大298, 老二0, 老三1金, 老四0, 老五1金, 老六0</p>
]]></content>
      <categories>
        <category>算法题</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络系列笔记(五) - 数据链路层</title>
    <url>/2022/02/11/20220211102604/</url>
    <content><![CDATA[<h1 id="数据链路层服务">数据链路层服务</h1>
<p>主机和路由器称为结点, 连接相邻结点的通信信道称为链路, 有有线链路, 无线链路和局域网<br>
<strong>数据链路层负责通过一条链路从一个节点向另一个物理链路直接相连的相邻结点传送数据报</strong><br>
链路层服务包括</p>
<ul>
<li><strong>组帧</strong>, 封装数据报构成数据帧, 加首部和尾部; 帧同步</li>
<li><strong>链路接入</strong>, 共享介质需要解决信道接入; 帧首部中的MAC地址, 用于标识帧的源和目的</li>
<li><strong>相邻接点间可靠交付</strong>, 在低误码率的有线链路上很少采用; 无线链路误码率高,需要可靠交付</li>
<li><strong>流量控制</strong>, 协调相邻的发送结点和接收</li>
<li><strong>差错检测</strong>, 信号衰减和噪声会引起差错; 接收端检测到差错通知发送端重传或直接丢弃帧</li>
<li><strong>差错纠正</strong>, 接收端直接纠正比特差错</li>
<li><strong>全双工和半双工通信控制</strong>, 全双工, 链路两端结点<strong>同时</strong>双向传输; 半双工, 两端结点<strong>交替</strong>双向传输</li>
</ul>
<p>具体实现<br>
每个主机或路由器接口<br>
链路层在适配器(网络接口卡)中实现或者在一个芯片上实现(以太网网卡, 802.11网卡, 以太网芯片组)<br>
链接主机的系统总线<br>
由硬件, 软件与固件组成<br>
<strong>网卡间通信</strong><br>
发送端将数据报封装成帧, 增加差错检测比特, 实现可靠数据传输和流量控制<br>
接收端检测差错, 实现可靠数据传输和流量控制, 提取数据报, 交付上层协议实体</p>
<h1 id="差错编码">差错编码</h1>
<p>差错编码不能保证100%可靠<br>
基本原理: 在数据D上添加差错检测与纠正比特(冗余比特)R, 从D-&gt;DR<br>
差错编码可分为检错码和纠错码, 纠错码需要比检错码位数更多<br>
检测r位差错需要检错码的编码集的汉明距离为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>s</mi></msub><mo>=</mo><mi>r</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">d_s=r+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">s</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span><br>
纠正r位差错需要纠错码的编码集的汉明距离为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>s</mi></msub><mo>=</mo><mn>2</mn><mi>r</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">d_s=2r+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">s</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">2</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span></p>
<blockquote>
<p>汉明距离: 两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数</p>
</blockquote>
<p><strong>奇偶校验码</strong></p>
<ul>
<li>1比特校验位, 检测奇数位差错</li>
<li>二维奇偶校验, 检测奇数位差错, 部分偶数位差错, 纠正同一行/列的奇数位差错</li>
</ul>
<p><strong>internet校验和</strong><br>
发送端将数据划分为16位的二进制整数序列, 补码求和, 求和的反码加入分组的校验和字段, 接收端与发送端相同算法计算<br>
<strong>循环冗余校验码(CRC)</strong><br>
检错能力更强大的差错编码, 广泛应用于实际网络</p>
<h1 id="多路访问控制协议-MAC">多路访问控制协议(MAC)</h1>
<p>链路有两类</p>
<ul>
<li>点对点链路, 拨号接入的PPP, 以太网交换机与主机间的点对点链路</li>
<li>广播链路(共享介质), 早期的总线以太网, HFC的上行链路, 802.11无线局域网</li>
</ul>
<p>单一共享广播信道内, 两个或以上结点同时传输, 会产生冲突, 结点同时接收到多个信号则接收失败<br>
多路访问控制协议(multiple access control protocol) 采用分布式算法决定结点如何共享信道, 决策结点何时可以传输数据, 基于信道本身, 通信信道共享协调信息<br>
MAC协议三大类</p>
<ul>
<li><strong>信道化分MAC协议</strong>, 多路复用技术,时间, 频带, 码片划分, TDMA, FDMA, CDMA, WDMA等, 网络负载重时效率高,且公平, 网络负载轻时效率低</li>
<li><strong>随机访问MAC协议</strong>, 信道不划分, 允许冲突, 采用冲突恢复机制, 时隙ALOHA(信道成功利用时间占37%), ALOHA(信道成功利用时间占18%), CSMA, CSMA/CD(应用于以太网), CSMA/CA(应用于802.11无线局域网)等, 网络负载轻时效率高, 负载重时, 产生冲突开销</li>
<li><strong>轮转MAC协议</strong>, 结点轮流使用信道, 综合前两者优点, 主结点轮询, 令牌传递, 用于蓝牙, FDDI, 令牌环网</li>
</ul>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题-url结尾带不带斜杠的访问速度</title>
    <url>/2017/02/26/20170226142341/</url>
    <content><![CDATA[<p>之前有一次面试遇到一个问题(拿我的博客举例):</p>
<blockquote>
<p><a href="http://www.wangdanpeng.com/about%E5%92%8Cwww.wangdanpeng.com/about/%E5%93%AA%E7%A7%8D%E8%AE%BF%E9%97%AE%E6%96%B9%E5%BC%8F%E9%80%9F%E5%BA%A6%E6%9B%B4%E5%BF%AB">www.wangdanpeng.com/about和www.wangdanpeng.com/about/哪种访问方式速度更快</a>?</p>
</blockquote>
<p>之前也没考虑过这个, 遇到这个题还真是一脸懵逼,事后就在CSDN发了篇帖子, 没想到还被上了推荐,真是受宠若惊.<a href="http://bbs.csdn.net/topics/391942437" target="_blank" rel="noopener">一个高深莫测的面试题</a></p>
<p>在上面访问的url中:<br>
当请求第一个不带斜杠的url时, 服务器会优先查找根目录下有没有叫about的文件, 没有文件再把about当做目录处理, 再去加载about目录下的默认首页;<br>
但是当请求第二个带有斜杠的url则直接把about当做目录处理, 理论上会比第一种快那么一点点.</p>
<p>拿百度来说, <a href="http://xn--www-628dz49ktjtoe0a.baidu.xn--comwww-k02mh66y.baidu.com/%E4%BB%8E%E6%8E%A7%E5%88%B6%E5%8F%B0%E7%9C%8B%E5%88%B0%E7%9A%84request" target="_blank" rel="noopener">不管请求www.baidu.com还是www.baidu.com/从控制台看到的request</a> url都是https://www.baidu.com/, 所以在自己做开发的时候尽量都在url结尾带上斜杠,这也算是一种SEO优化.</p>
]]></content>
      <categories>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络系列笔记(二) - 网络应用层</title>
    <url>/2022/02/09/20220209110515/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p><strong>网络应用体系结构</strong>: 客户机/服务器, P2P, 混合结构<br>
<strong>网络应用的服务需求</strong>: 可靠性, 带宽, 时延<br>
<strong>internet传输层服务模型</strong>: TCP, UDP<br>
<strong>特定网络应用及协议</strong>: HTTP, SMTP, DNS, P2P<br>
<strong>Socket编程</strong>: TCP, UDP</p>
<h1 id="网络应用的基本原理">网络应用的基本原理</h1>
<p>网络应用的体系结构有三种<br>
<strong>客户机/服务器结构(Client-Server, C/S)</strong><br>
服务器特点: 7 × 24小时提供服务, 永久性访问地址, 利用大量服务器实现可扩展性<br>
客户机特点: 与服务器通信使用服务器提供的服务, 间歇性接入网络, 可能使用动态IP地址, 不会与其他客户机直接通信<br>
<strong>点对点结构(Peer-to-Peer, P2P)</strong>: 没有永远在线的服务器, 任意节点之间可直接通讯, 节点间歇性接入网络, 节点可能改变IP地址, 优点是高度可伸缩, 缺点是难于管理<br>
<strong>混合结构(Hybrid)</strong>: 例如Napster, 文件传输使用P2P结构, 文件搜索采用C/S结构</p>
<h2 id="进程间通信">进程间通信</h2>
<p>不同主机上的进程间通信需要消息交换, 发起通信的进程叫客户机进程, 等待通信请求的进程叫服务器进程<br>
<strong>套接字(Socket)</strong>: 进程间通信利用socket发送/接收消息实现, 传输基础设施向进程提供API<br>
进程的标识符: IP地址+端口号<br>
<strong>应用层协议</strong>: 网络应用需遵守应用层协议, 分为公开协议, 由RFC(Request For Comments)定义和私有协议<br>
应用层协议内容</p>
<ul>
<li>消息的类型 (请求消息, 相应消息)</li>
<li>消息的语法格式 (包含哪些字段)</li>
<li>字段的语义 (字段中信息的含义)</li>
<li>规则 (进程何时发送/相应消息, 进程如何发送/相应消息)</li>
</ul>
<h2 id="网络应用的需求">网络应用的需求</h2>
<p>网络应用对传输服务的需求</p>
<ul>
<li>可靠性 (网络电话能容忍一定数据丢失, 文件传输不行)</li>
<li>延迟 (网络游戏要求低延迟)</li>
<li>带宽 (网络视频对带宽有最低要求, email则没有)</li>
</ul>
<p>Internet提供的传输服务对比<br>
<strong>TCP服务</strong></p>
<ul>
<li>面向连接, 客户机/服务器进程间需要建立连接</li>
<li>可靠的传输</li>
<li>流量控制, 发送方不会发送速度过快而超过接收方处理能力</li>
<li>拥塞控制, 当网络负载过重时能够限制发送方的发送速度</li>
<li>不提供延迟保障</li>
<li>不提供最小带宽保障</li>
</ul>
<p><strong>UDP服务</strong></p>
<ul>
<li>无连接</li>
<li>不可靠数据传输</li>
<li>不提供可靠性保障, 流量控制, 拥塞控制, 延迟保障, 带宽保障</li>
</ul>
<h1 id="WEB应用">WEB应用</h1>
<blockquote>
<p>网页对象的寻址: URL(Uniform Resoure Locator)统一资源定位器</p>
</blockquote>
<p><strong>http协议概述</strong><br>
万维网遵循的协议, 超文本传输协议(HyperTexi Transfer Protocol), 使用TCP传输服务, 无状态, 服务器不维护任何有关客户端过去所发请求的信息<br>
http有两种连接方式, 非持久性连接, 每个TCP连接最多允许传输一个对象; 持久性连接, 每个TCP连接允许传输多个对象<br>
<strong>响应时间</strong><br>
RTT(Round Trip Time), 从客户端发送一个很小的数据包到服务器并返回所经历的时间<br>
发起, 建立TCP连接, 需要1个RTT, 发送http请求消息到http响应消息的前几个字节到达, 需要1个RTT, 再加响应中所含文件的传输时间<br>
响应时间总共 = 2RTT + 文件发送时间<br>
<strong>cookie技术</strong><br>
http协议无状态, 为了辨别用户身份, 进行session跟踪而储存在用户本地终端上的数据, 通常经过加密<br>
cookie的组件</p>
<ul>
<li>http响应消息的cookie头部行</li>
<li>http请求消息的头部行</li>
<li>保存在客户端主机上的cookie文件, 由浏览器管理</li>
<li>web服务器端的后台数据库</li>
</ul>
<p>可用于, 身份认证, 购物车, 推荐等<br>
<strong>web缓存/代理服务器技术</strong><br>
在不访问服务器的前提下满足客户端的http请求<br>
目的是: 缩短客户请求的相应时间, 减少机构/组织的流量, 在大范围内实现有效的内容分发<br>
缓存既充当客户端也充当服务器</p>
<h1 id="Email应用">Email应用</h1>
<p>构成组件: 邮件客户端, 邮件服务器, SMTP协议<br>
使用TCP进行email消息的可靠传输, 命令/响应交互模式, 使用持久性连接<br>
邮件访问协议, POP(Post Office Protocol), IMAP(Internet Mail Access Protocol), HTTP<br>
POP3是无状态的, IMAP支持跨会话的用户状态</p>
<h1 id="DNS-Domain-Name-System">DNS(Domain Name System)</h1>
<p>域名解析系统DNS: 多层命名服务器构成的分布式数据库, 应用层协议, 完成名字的解析<br>
<strong>DNS服务作用</strong>: 域名向IP地址的翻译, 主机别名, 邮件服务器别名, 负载均衡<br>
解析流程: <code>本地域名解析服务器 -&gt; 根域名服务器 -&gt;权威域名服务器 -&gt; 本地域名服务器</code></p>
<blockquote>
<ul>
<li>顶级域名服务器(TLD, top-level domain): 负责com,org,net,edu等顶级域名和国家顶级域名,如cn</li>
<li>权威域名服务器: 组织的域名解析服务器, 提供组织内部服务器的解析服务</li>
<li>本地域名解析服务器: 不严格属于层级体系, 每个ISP有一个本地域名服务器, 默认的, 当主机进行DNS查询时, 查询被发送到本地域名服务器, 作为代理将查询层级式转发给域名解析服务器系统</li>
</ul>
</blockquote>
<p><strong>全球有13个根域名服务器</strong></p>
<p>两种查询方式, 迭代查询, 递归查询<br>
<strong>DNS记录和消息格式</strong><br>
DNS记录是一个四元组, 资源记录(RR, resource records), <code>RR format: (name, value, type, ttl)</code></p>
<blockquote>
<p>type=A name是主机域名, value是ip地址<br>
type=NS name是域, value是该域权威域名解析服务器的主机域名<br>
type=CNAME name是某一真实域名的别名, value是真实域名<br>
type=MX value是name对应的邮件服务器</p>
</blockquote>
<p>依赖DNS协议</p>
<h1 id="P2P">P2P</h1>
<p><strong>P2P架构</strong>: 没有服务器, 任意端系统之间直接通信, 节点阶段性接入互联网, 节点可能更换ip地址<br>
文件分发比C/S模式效率高<br>
<strong>文件分发</strong><br>
采用BitTorrent协议, torrent负责交换同一个文件的文件块的节点组, tracker跟踪参与torrent的节点<br>
文件被划分为256KB的chunk, 节点加入torrent, 向tracker注册以获得节点清单, 与某些节点建立连接, 下载的同时, 节点需要向其他节点上传chunk<br>
获取chunk流程, 给定任一时刻, 不同节点持有文件的不同chunk集合, 当前节点定期查询每个邻居所拥有的chunk列表, 节点发送请求, 请求获取缺失的chunk, 稀缺优先<br>
发送chunk流程, tit-for-tat, 谁给我我给谁, 向正在给自己发送chunk且速率最快的四个邻居发送chunk, 每10s重新评估top4, 每30s随机选择一个其他节点<br>
<strong>P2P索引方式</strong></p>
<ul>
<li>集中式索引, 存在单点失效问题, 性能瓶颈, 版权问题</li>
<li>洪泛式查询, 完全分布式架构, 每个节点只对它共享的文件进行索引, 查询消息通过已有TCP连接发送, 节点继续转发查询, 查询像洪水泛滥</li>
<li>层次式覆盖网络, 集中式和洪泛式的结合, 节点和超级节点维持TCP连接, 超级节点之间维持TCP连接, 超级节点负责跟踪子节点内容, 查询到后节点直接直接通信, 不经过超级节点</li>
</ul>
<p>很常用的设计思路</p>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络系列笔记(一)-概述</title>
    <url>/2022/02/08/20220208185951/</url>
    <content><![CDATA[<h1 id="基本概念">基本概念</h1>
<h2 id="计算机网络">计算机网络</h2>
<p>计算机网络 = 通信技术 + 计算机技术, 计算机网络是通信技术与计算机技术紧密结合的产物, 是互连(互联互通)的, 自治(无主从关系)的计算机集合</p>
<blockquote>
<p>通信系统模型: 信源 -&gt; 发送设备 -&gt; 信道(伴有噪声源) -&gt; 接收设备 -&gt; 信宿</p>
</blockquote>
<p>计算机网络为网络应用提供通信服务的通信基础设施(网游, 社交), 为网络应用提供应用编程接口(api)(提供类似邮政系统的数据传输服务)<br>
计算机网络就是一种通信网络, 通过交换网络互连主机, 交换节点为路由器或交换机, internet是全球最大的互联网络, 数以百万计的互连的计算设备集合<br>
只有硬件连接, internet并不能顺畅运行, 还需要协议</p>
<h2 id="网络协议">网络协议</h2>
<p>协议是计算机网络有序运行的重要保证<br>
硬件(主机, 路由器, 通信链路等)是计算机网络的基础, 计算机网络中的数据交换必须遵守事先约定好的规则, 如同交通系统<br>
任何通信或信息交换过程都需要规则, 发送特定消息, 采取特定动作<br>
网络通信, 主体是机器不是人, 交换电子化或数据化消息, 计算机网络的所有通信过程都必须遵守某些规则, 这就是协议<br>
<strong>网络协议(network protocol)</strong>: 简称为协议, 是为进行网络中的数据交换而建立的规则, 标准或约定<br>
协议规定了通信实体之间所交换的消息的格式, 意义, 顺序以及针对收到信息或发生的事件所采取的动作(actions)<br>
<strong>协议的三要素</strong><br>
<strong>语法(Syntax)</strong>: 数据与控制信息的结构或格式, 信号电平<br>
<strong>语义(Semantics)</strong>: 需要发出何种控制信息, 完成何种动作以及做出何种响应, 差错控制<br>
<strong>时序(Timing)</strong>: 事件顺序, 速度匹配<br>
协议规范了网络中所有信息发送和接收过程, 例如TCP, IP, HTTP, Skype…<br>
协议是学习网络的重要内容之一, 是网络创新的表现形式之一<br>
Internet协议标准大部分都是RFC(Request for Comments)文档形式存在, 由IETF(Internet Engineering Task Force)互联网工程任务组进行管理</p>
<h1 id="计算机网络结构">计算机网络结构</h1>
<p>计算机网络结构分为网络边缘, 接入网络, 网络核心</p>
<h2 id="网络边缘">网络边缘</h2>
<p>包括主机, 网络应用<br>
通信方式主要有两类<br>
客户/服务器(client/server)应用模型: 客户发送请求, 接收服务器响应, 如web应用<br>
对等(peer-peer, P2P)应用模型: 无/不依赖专用服务器, 通信在对等实体之间直接进行, 如BT下载</p>
<h2 id="接入网络">接入网络</h2>
<p>属于物理介质, 有线或无线通信链路<br>
根据使用场景可划分为, 家庭接入网络, 机构接入网络(学校, 企业), 移动接入网络, 划分不严格<br>
用户关心的内容: 带宽(bandwidth/bps), 共享/独占<br>
<strong>具有代表性的接入网络</strong></p>
<ul>
<li>数字用户线路(DSL): 利用现有的电话线, 采用多路复用技术(多路信号共同使用一个物理介质)</li>
<li>ADSL: 非对称数字用户线路, 上行线路和下行线路速率不一样, 上传慢下载快</li>
</ul>
<p>两种都是采用频分多路复用技术, 把信号调整到不同频带上, 例如, 50kHz-1MHz用于下行, 4kHz-50kHz用于上行, 0kHz-4kHz用于传统电话</p>
<ul>
<li>电缆网络: 用的有线电视网络, 也是典型的频分多路复用技术, 在不同频带上传输不同频道</li>
</ul>
<p><strong>典型家庭网络的接入</strong>: 电话线或电缆通过调制解调器, 连接路由器, 通过有线以太网(局域网)/无线网wifi连接家里的设备<br>
<strong>机构接入网络</strong>: 利用局域网, 有线局域网最有名利用最广泛的以太网(Ethernet), 以太网交换机通过连接ISP的机构路由器接入链路<br>
<strong>无线接入网络</strong>: 通过共享的无线接入网络连接端系统与路由器, 通过基站(base station)或称为接入点(access point), 两类无线局域网(LANs)(wifi)和广域无限接入(蜂窝网)</p>
<h2 id="网络核心">网络核心</h2>
<p>由互联的路由器或分组转发设备组成, 互联的路由器网络<br>
网络核心关键功能: 路由+转发</p>
<blockquote>
<p>路由(routing): 确定分组从源到目的传输路径<br>
转发(forwarding): 将分组从路由器的输入端口交换至正确的输出端口</p>
</blockquote>
<p>网络核心收到一个数据包, 需要根据地址信息正确的送到目的地, 就需要用到一个本地转发表/路由表, 包含目的地址和输出链路, 运行路由协议计算得出</p>
<p>网络核心解决的基本问题是: <strong>数据交换</strong><br>
为什么需要数据交换? 设备直连需要n<sup>2</sup>条链路.<br>
为了保证连通性和适应不同网络规模, 交换设备互连在一起构成一个交换网络<br>
<strong>交换</strong>: 动态转接和动态分配传输资源<br>
数据交换的类型有: 电路交换, 报文交换, 分组交换</p>
<p>典型的<strong>电路交换</strong>网络有电话网络<br>
电路交换的三个阶段: 建立连接(呼叫/电路建立), 通信, 释放连接(拆除电路), 占用的电路资源独占, 但物理中继线共享, 涉及多路复用</p>
<p>分组交换需要报文的拆分与重组, 会产生额外的开销</p>
<blockquote>
<p>报文: 源发送信息整体, 比如一个文件, 分组: 报文拆分出来一系列相对较小的数据包, 包含数据头和数据</p>
</blockquote>
<p><strong>分组交换</strong>采用统计多路复用(Statistical multiplexing), 分组序列不确定, 按需共享链路<br>
<strong>报文交换</strong>与分组交换均采用存储-转发交换方式, 区别是报文交换以完整报文进行存储转发, 分组交换以较小的分组进行存储转发<br>
分组交换的报文交付时间: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mo>=</mo><mi>M</mi><mi mathvariant="normal">/</mi><mi>R</mi><mo>+</mo><mi>n</mi><mi>L</mi><mi mathvariant="normal">/</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">T = M/R+nL/R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.10903em;">M</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mbin">+</span><span class="mord mathit">n</span><span class="mord mathit">L</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.00773em;">R</span></span></span></span></p>
<blockquote>
<p>报文大小M bits, 链路带宽R bps, 分组长度L bits, 跳步数 h, 路由器数 n</p>
</blockquote>
<p>分组交换允许更多用户同时使用网络, 网络资源充分共享, 适用于突发数据传输网络, 资源充分共享, 简单, 无需呼叫建立, 但可能产生拥塞(congestion), 分组延迟和丢失, 需要协议处理可靠数据传输和拥塞控制<br>
分组交换是目前计算机网络中<strong>广泛采用</strong>的数据交换技术</p>
<blockquote>
<p><strong>多路复用(multiplexing)</strong>: 简称复用, 是通信技术中的基本概念<br>
链路/网络资源划分为资源片, 将资源片分配给各路呼叫(calls), 每路呼叫独占分配到的资源片进行通信, 资源片可能闲置(idle)<br>
<strong>典型多路复用方法</strong></p>
<ul>
<li>频分多路复用(frequency division multiplexing, FDM): 例有线电视, 各用户占用不同的频率带宽(Hz)资源, 用户在分配到一定的频带后, 在通信过程中自始至终都占用这个频带</li>
<li>时分多路复用(time division multiplexing, TDM): 将时间划分为一段段等长的时分复用帧(TDM帧), 每个用户在每个TDM帧中占用固定序号的时隙, 每用户所占用的时隙是周期性出现, 周期就是TDM帧的长度, 所有用户是在不同的时间占用相同的频带宽度</li>
<li>波分多路复用(wavelength division multiplexing, WDM): 就是光的频分复用</li>
<li>码分多路复用(code division multiplexing, CDM): 广泛应用于无线链路共享(蜂窝网, 卫星通信), 每个用户分配一个唯一的码片序列(chipping sequence), 各用户使用相同频率载波, 利用各自码片序列编码数据, 各用户码片序列相互正交(orthogonal), 解码则是码片序列与编码信号的内积</li>
</ul>
</blockquote>
<h1 id="计算机网络性能">计算机网络性能</h1>
<p><strong>速率</strong>: 数据率/数据传输速率/比特率, 单位时间传输信息量, b/s, kb/s, Mb/s, k=1000, 往往指额定速率或标称速率<br>
<strong>带宽</strong>: 这里指数字信道所能传送的最高数据率, 单位 b/s<br>
<strong>丢包</strong>: 分组在路由器缓存中排队, 如缓存已满, 到达分组会被丢弃<br>
队列缓存容量有限, 分组到达已满队列将被丢弃, 丢弃分组可能由前序节点或源重发, 也可能不重发<br>
丢包率 = 丢包数 ÷ 已发分组总数<br>
四种<strong>分组延迟</strong>: 结点处理延迟, 排队延迟, 传输延迟, 传播延迟<br>
时延带宽积 = 传播时延 × 带宽, 链路的时延带宽积又称为以比特为单位的链路长度<br>
<strong>吞吐量</strong>: 表示在发送端与接收端之间传送数据速率(b/s)<br>
<strong>瓶颈链路</strong>: 端到端路径上, 限制吞吐量的链路</p>
<h1 id="计算机网络体系结构">计算机网络体系结构</h1>
<p>为什么需要体系结构, 因为计算机网络是一个非常复杂的系统, 涉及许多组成部分, 所以用分层结构, 能有效描述网络<br>
每层完成一类特定功能, 每层依赖底层提供的服务, 通过层内动作完成相应功能<br>
计算机网络体系结构简称网络体系结构, 是从功能上描述计算机网络结构, 是分层结构, 每层遵循某些网络协议完成本层功能<br>
计算机网络体系结构是计算机网络的各层及其协议的集合, 体系结构是一个计算机网络的功能层次及其关系的定义, 是抽象的<br>
<strong>分层结构好处</strong><br>
结构清晰, 有利于识别复杂系统的部件及其关系, 模块化的分层易于系统更新维护, 有利于标准化</p>
<h2 id="OSI参考模型">OSI参考模型</h2>
<p><strong>开放系统互连(OSI)参考模型</strong>是由国际标准化组织(ISO)1984年提出的分层网络体系结构模型, 目的是支持异构网络系统的互联互通<br>
异构网络系统互连的国际标准, 理解网络通信的最佳理论模型, 但应用并不广泛, 共有七层:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">物理层(Physical): 接口特性(机械特性, 电气特性, 功能特性, 规程特性), 比特编码, 数据率, 比特同步, 传输模式(单工, 半双工, 全双工)</span><br><span class="line">数据链路层(Data link): 负责结点-结点数据传输, 组帧, 物理寻址, 在帧头中增加发送端和接收端的物理地址, 流量控制, 差错控制, 访问控制</span><br><span class="line">网络层(Network): 负责源主机到目的主机数据分组交付, 可能穿越多个网络, 逻辑寻址, 全局唯一逻辑地址, 确保数据分组被送达目的主机, 如IP地址, 路由, 分组转发 </span><br><span class="line">传输层(Transport): 负责源-目的地完整报文传输, 分段与重组, SAP寻址, 确保将完整报文提交给正确进程, 连接控制, 流量控制, 差错控制</span><br><span class="line">会话层(Session): 对话控制, 同步, 在数据流中插入同步点, 最薄的一层</span><br><span class="line">表示层(Presentation): 处理两个系统间交换信息的语法与语义问题, 数据表示转化, 转换为主机独立的编码, 加密&#x2F;解密, 压缩&#x2F;解压缩</span><br><span class="line">应用层(Application): 支持用户通过用户代理(如浏览器)或网络接口使用网络服务, 如FTP, SMTP, HTTP</span><br></pre></td></tr></table></figure>
<p><img src="https://www.wangdanpeng.com/img/20220208_1.png" alt="通信过程"></p>
<p><img src="https://www.wangdanpeng.com/img/20220208_2.png" alt="封装过程"></p>
<blockquote>
<p>为什么需要数据封装?<br>
增加控制信息, 构造协议数据单元(PDU).<br>
<strong>控制信息</strong>需要包括, 地址, 标识发送端/接收端, 差错检测编码, 用于差错检测或纠正, 协议控制, 实现协议功能的附加信息</p>
</blockquote>
<h2 id="TCP-IP参考模型">TCP/IP参考模型</h2>
<p><img src="https://www.wangdanpeng.com/img/20220208_3.png" alt="TCP/IP"><br>
应用层, 运输层, 网际层, 网络接口层</p>
<h2 id="五层参考模型">五层参考模型</h2>
<p><strong>综合OSI和TCP/IP的优点</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">应用层, 支持各种网络应用, FTP, SMTP, HTTP</span><br><span class="line">传输层, 进程-进程的数据传输, TCP, UDP</span><br><span class="line">网络层, 源主机到目的主机的数据分组路由与转发, IP协议, 路由协议等</span><br><span class="line">链路层, 相邻网络元素的数据传输(主机, 交换机, 路由器)</span><br><span class="line">物理层, 比特传输</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>计算机网络</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络系列笔记(四) - 网络层</title>
    <url>/2022/02/10/20220210171858/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p>网络层从发送主机向接收主机传送数据段(segment)<br>
发送主机:将数据段封装到数据报(datagram)中<br>
接收主机:向传输层交付数据段<br>
每个主机和路由器都运行网络层协议, 路由器检验所有穿越它的ip数据报的头部域决策如何处理ip数据报<br>
<strong>网络层的核心功能是转发(forwarding)和路由(routing), 连接建立</strong></p>
<ul>
<li><strong>转发</strong>: 将分组从路由器的输入端口转移到合适的输出端口</li>
<li><strong>路由</strong>: 确定分组从源到目的经过的路径, 依赖路由算法</li>
<li><strong>连接建立</strong>: 某些网路的重要功能, 比如ATM,帧中继, X.25, 数据分组传输之前两端主机需要首先建立虚拟/逻辑连接</li>
</ul>
<blockquote>
<p>网络层连接与传输层连接对比: 网络层连接<strong>两个主机</strong>之间, 路径上的路由器等网络设备都参与其中, 传输层连接, <strong>两个应用进程</strong>之间, 对中间网络设备透明</p>
</blockquote>
<p>网络层为发送端主机到接收端主机的数据报传送通道提供的<strong>服务模型:</strong></p>
<ul>
<li><strong>无连接服务(connection-less service)</strong>: 不事先为系列分组的传输确定路径, 每个分组独立确定传输路径, 不同分组可能传输路径不同, 例如数据报网络</li>
<li><strong>连接服务(connection service)</strong>: 首先为系列分组的传输确定从源到目的经过的路径(建立连接), 然后沿该路径传输系列分组, 系列分组传输路径相同, 传输结束后拆除连接, 例如虚电路网络</li>
</ul>
<h1 id="虚电路和数据报">虚电路和数据报</h1>
<p>类似于传输层的无连接服务(UDP)和面向连接服务(TCP), 但网络层服务是主机到主机服务, 网络核心实现</p>
<h2 id="虚电路网络-Virtual-Circuits">虚电路网络(Virtual Circuits)</h2>
<p><strong>虚电路</strong>: 一条从源主机到目的主机, 类似于电路的路径(逻辑连接), 使用分组交换, 每个分组的传输利用链路的全部带宽, 源到目的的路径经过的网络层设备共同完成虚电路功能<br>
<strong>通信过程</strong>: 呼叫建立, 数据传输, 呼叫拆除<br>
每个分组携带虚电路标识(VC id), 而不是目的主机地址, 虚电路经过的每个网络设备, 维护每条经过它的虚电路连接状态, 链路/网络设备资源可以面向VC进行预分配<br>
每条虚电路包括从源主机到目的主机的一条路径, 虚电路号, 沿路每个网络层设备, 利用转发表记录经过的每条虚电路<br>
同一条VC, 在每段链路上的VC id通常不同, 路由器转发分组时依据转发表改写虚电路号<br>
虚电路信令协议(signaling protocols), 用于VC的建立,维护和拆除, 目前的internet不采用</p>
<h2 id="数据报网络">数据报网络</h2>
<p>网络层无连接, 每个分组携带目的地址, 路由器根据分组的目的地址转发分组, 基于路由协议构建转发表, 检索转发表, 每个分组独立选路<br>
路由算法确定通过网络的端到端路径, 转发表确定在本路由器如何转发分组, 转发表聚合地址范围减小数据量, <strong>检索转发表时优先选择与分组目的地址匹配前缀最长的入口</strong></p>
<blockquote>
<p>数据报网络, 计算机之间的数据交换, 没有严格时间需求, 链路类型众多, 智能端系统, 简化网络, 复杂边缘<br>
虚电路网络, 电话网络演化而来, 核心业务是实时对话, 严格的时间, 可靠性需求, 需要有保障的服务, 哑端系统, 电话机传真机, 简化边缘, 复杂网络</p>
</blockquote>
<h1 id="IP协议">IP协议</h1>
<p>主机,路由器网络层主要功能:<br>
<strong>路由协议(路径选择)-&gt;转发表-&gt;ip协议(寻址规约,数据报格式,分组处理规约),icmp协议(差错报告,路由器信令)</strong></p>
<h2 id="IP数据报格式">IP数据报格式</h2>
<p><img src="http://www.wangdanpeng.com/img/20220210_1.png" alt="IP数据报格式"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">版本号: 4位, IP协议版本号, IPv4或IPv6</span><br><span class="line">首部长度: 4位, IP分组首部长度, 以4字节为单位</span><br><span class="line">服务类型: 8位, 期望获得哪种类型服务, 一般情况下不使用, 只有在网络提供区分服务时使用</span><br><span class="line">总长度: 16位, IP分组的总字节数(首部+数据)</span><br><span class="line">标识: 16位, 标识一个IP分组, IP协议利用一个计数器, 每产生IP分组计数器加1, 作为该IP分组的标识</span><br><span class="line">标志位: 3位, 保留位|DF|MF, DF(dont fragment),1禁止分片,0允许分片, MF(more fragment),1非最后一片,0最后一片&#x2F;未分片</span><br><span class="line">片偏移: 13位, 一个IP分组分片封装原IP分组数据的相对偏移量, 片偏移以8字节为单位</span><br><span class="line">生存时间: 8位, IP分组在网络中可以通过的路由器数&#x2F;跳步数, 路由器转发一次分组, ttl减1, 如果ttl&#x3D;0则路由器丢弃该IP分组</span><br><span class="line">协议: 8位, IP分组封装的是哪个协议的数据报, 6为TCP, 17为UDP</span><br><span class="line">首部校验和: 16位, 实现对IP分组首部的差错检测</span><br><span class="line">源IP地址,目的IP地址: 各32位, 分别标识发送分组的源主机&#x2F;路由器和接受分组的目的主机&#x2F;路由器的IP地址</span><br><span class="line">选项字段: 长度可变, 范围在1-40B之间, 很少被使用, 携带安全,源选路径, 时间戳和路由记录等内容</span><br><span class="line">填充字段: 长度可变, 范围在0-3B之间, 目的是补齐整个首部, 符合32位对齐, 保证首部长度是4字节的倍数</span><br></pre></td></tr></table></figure>
<h2 id="IP分片与重组">IP分片与重组</h2>
<p>网络链路存在MTU(最大传输单元), 链路层数据帧可封装数据的上限, 不同链路的MTU不同<br>
大IP分组向较小MTU链路转发时, 可以被分片, 一个IP分组分为多片IP分组, IP分片到达目的主机后进行重组, <strong>路由器只拆分不重组</strong>,避免重组后又需要拆分<br>
IP首部的相关字段用于标识分片以及确定分片的相对顺序, 总长度, 标识, 标志位和片偏移</p>
<h2 id="IP编址和子网">IP编址和子网</h2>
<p>IP分组: 源地址(SA), 目的地址(DA)<br>
接口: 主机/路由器与物理链路的连接, 路由器通常有多个接口, 主机通常只有一个或两个接口(有线以太网和无线的802.11接口)<br>
IPv4版本IP地址32比特, 每8位换算10进制, 标识主机, 路由器的接口<br>
IP地址高位比特作为网络号, 低位比特作为主机号<br>
<strong>IP子网</strong>: IP地址具有相同网络号的设备接口, 不跨越路由器可以彼此物理联通的接口<br>
IP地址被分为5类, ABCDEF<br>
<img src="http://www.wangdanpeng.com/img/20220210_2.png" alt="IP地址"><br>
还有特殊地址和私有地址<br>
<img src="http://www.wangdanpeng.com/img/20220210_3.png" alt="特殊地址"><br>
<img src="http://www.wangdanpeng.com/img/20220210_4.png" alt="私有地址"></p>
<h2 id="子网划分">子网划分</h2>
<p>子网划分, 区分一个比IP子网更小范围的网络<br>
高比特位网络号, 原网络主机号部分比特作为子网号, 低位比特主机号<br>
子网掩码, 形如IP地址32位, 点分十进制形式, 子网地址+子网掩码确定子网大小, 网络号子网号全取1, 主机号全取0<br>
A网默认子网掩码, 255.0.0.0, b网, 255.255.0.0<br>
借用3比特划分子网的b网子网掩码255.255.224.0<br>
子网掩码的应用, 将IP分组的目的IP地址与子网掩码按位与运算, 得出子网地址</p>
<h1 id="CIDR与路由聚集">CIDR与路由聚集</h1>
<p>无类域间路由(CIDR, Classless Interdomain Routing)<br>
消除传统A类,B类地址界限, 融合子网地址与子网掩码, 方便子网划分, 无类地址格式, <code>a.b.c.d/x</code>, x为前缀长度<br>
例如<code>201.2.3.64, 255.255.255.192</code> -&gt; <code>201.2.3.64/26</code><br>
优点, 提高IPv4地址空间分配效率, 提高路由效率, 将多个子网聚合为一个较大的子网 称为路由聚合, 可简化路由转发表</p>
<h1 id="DHCP协议">DHCP协议</h1>
<p>主机获取IP两种方式</p>
<ul>
<li>静态配置</li>
<li>动态主机配置协议(DHCP, Dynamic Host Configuration Protocol)</li>
</ul>
<p>从服务器动态获取IP地址, 子网掩码, 默认网关, DNS服务器, 即插即用, 允许地址重用, 支持在用地址续租, 支持移动用户加入网络<br>
DHCP工作工程:</p>
<ul>
<li>主机广播<code>DHCP discover</code>报文</li>
<li>DHCP服务器利用<code>DHCP offer</code>报文进行相应</li>
<li>主机请求IP地址, <code>DHCP request</code>报文</li>
<li>DHCP服务器分配IP地址, <code>DHCP ack</code>报文</li>
</ul>
<p>DHCP协议在应用层实现, DHCP服务器内建于路由器中<br>
主机通过广播和DHCP服务器通信, 其他主机也能收到, 但不响应</p>
<h1 id="网络地址转换-NAT">网络地址转换(NAT)</h1>
<p>一个本地网络, 公用一个NAT IP地址, 所有离开本地网络去往Internet的数据报的源IP地址替换为相同的NAT IP地址以及不同的端口号<br>
动机: 只需从ISP申请一个IP地址, 本地网络设备IP地址的变更, 无需通告外界网络, 变更ISP时, 无需修改内部网络设备IP地址, 内部网络设备对外界网络不可见, 安全<br>
实现方法</p>
<ul>
<li>替换, 利用NAT IP地址和新端口号, 替换每个外出IP数据报的源IP地址, 源端口号</li>
<li>记录, 将每对替换信息存储到NAT转换表中</li>
<li>替换, 根据NAT转换表, 再把进入内网的数据报替换回来</li>
</ul>
<p>端口号字段16比特, 最多同时支持6w多并行连接<br>
NAT争议, 路由器应该只处理第三层功能, 违背端到端通信原则, 地址短缺问题应该由IPv6解决<br>
NAT穿透方案</p>
<ol>
<li>静态配置NAT, 将特定端口请求转发给服务器</li>
<li>利用UPnP互联网网关设备协议自动配置</li>
<li>中继服务器, 内部客户与中级服务器建立连接, 外部客户也与中继服务器建立连接</li>
</ol>
<h1 id="互联网控制报文协议-ICMP">互联网控制报文协议(ICMP)</h1>
<p>ICMP, Internet Control Message Protocol<br>
ICMP支持主机/路由器进行差错报告, 网络探询, 所以ICMP报文分两类</p>
<ul>
<li>差错报告报文(5种): 目的不可达,源抑制,超时,参数问题,重定向</li>
<li>网络探询报文(2组): 回声请求与应答报文, 时间戳请求与应答报文</li>
</ul>
<p>ICMP报文封装到IP数据报中传输</p>
<h1 id="IPv6">IPv6</h1>
<p>改进了首部格式, 固定长度的40字节基本首部, 可选的扩展首部, 不允许分片, 只能源主机分片<br>
<strong>校验和</strong>彻底移除, 以减少每跳处理时间<br>
一般形式, 8个16进制, 全是零可压缩成<code>::</code>, <code>FF01:0:0:0:0:0:0:43</code> -&gt; <code>FF01::43</code><br>
嵌入IPv4格式, <code>0:0:0:0:0:FFFF:13.1.68.3</code> 或 <code>::FFFF:13.1.68.3</code><br>
取消了子网掩码, 采用斜杠的地址前缀, url里需要把ip用中括号扩起来<br>
地址类型分为, 单播, 多播和任意播<br>
v4向v6过渡采用隧道进行兼容, v6数据报作为v4的载荷进行封装, 穿越v4网络</p>
<h1 id="路由算法">路由算法</h1>
<p>路由算法需要确定去往目的网络的最佳路径<br>
网络通常被抽象成图G, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo>=</mo><mo>(</mo><mi>N</mi><mo separator="true">,</mo><mi>E</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">G=(N, E)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mclose">)</span></span></span></span>, N是路由器集合, E是链路集合<br>
每段链路都有费用, 可能是1, 或者带宽的倒数, 拥塞程度等, 所以路由算法负责寻找最小费用路径<br>
<strong>路由算法分类</strong></p>
<ul>
<li>静态路由, 手工配置, 路由更新慢, 优先级高</li>
<li>动态路由, 更新快, 及时响应链路费用变化</li>
<li>全局信息, 所有路由器掌握完整网络拓扑和链路费用信息, 例如链路状态路由算法(LS)</li>
<li>分散信息, 路由器只掌握物理相连的邻居以及链路费用, 邻居间信息交换, 运算的迭代过程, 例如距离向量路由算法(DV, Distance Vector)</li>
</ul>
<h2 id="链路状态路由算法-LS">链路状态路由算法(LS)</h2>
<p>Dijkstra算法</p>
<ul>
<li>所有路由器掌握网络拓扑和链路费用, 通过链路状态广播, 所有结点拥有相同信息</li>
<li>计算从一个结点到达所有其他结点的最短路径</li>
<li>迭代n次后, 得到到达n个目标的结点的最短路径</li>
</ul>
<p>细节略, 时间复杂度<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span>, 可优化到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(nlogn)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathit">n</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">n</span><span class="mclose">)</span></span></span></span>, 存在震荡可能</p>
<h2 id="距离向量路由算法">距离向量路由算法</h2>
<p>Bellman-Ford方程(动态规划)<br>
每个结点不定时的将自身的DV估计发送给其邻居, 当x接收到邻居的新DV估计时, 依据BF更新其自身的距离向量估计, x到y的距离<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi>x</mi><mo>(</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">Dx(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>最终收敛于实际的最小费用<br>
好消息传播快, 坏消息传播慢</p>
<h2 id="层次路由">层次路由</h2>
<p>将任意规模网络抽象为一个图计算路由, 过于理想化, 实际网络规模过大<br>
聚合路由器为一个区域, 称为<strong>自治系统AS(autonomous systems)</strong><br>
同一AS内的路由器运行相同的路由协议, 自治系统内部路由协议<br>
<strong>网关路由器</strong>: 位于AS边缘, 通过链路连接其他AS<br>
AS互连: 由AS内部路由算法与AS间路由算法共同配置转发表</p>
<h1 id="路由协议">路由协议</h1>
<ul>
<li>RIP协议</li>
<li>OSPF协议</li>
<li>BGP协议</li>
</ul>
<p>略了</p>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>IP</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络系列笔记(三) - 传输层</title>
    <url>/2022/02/09/20220209153707/</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<p><strong>传输层的基本理论和基本机制</strong></p>
<ul>
<li>复用/分用</li>
<li>可靠数据传输机制</li>
<li>流量控制机制</li>
<li>拥塞控制机制</li>
</ul>
<p>掌握Internet的传输层协议: UDP, TCP, TCP拥塞控制<br>
<strong>传输层协议为运行在不同host上的进程提供了一种逻辑通信机制</strong><br>
网络层提供主机之间的逻辑通信机制, 传输层提供应用进程之间的逻辑通信机制, 位于网络层之上, 依赖于网络层服务, 对网络层服务进行增强<br>
<strong>TCP</strong>: 可靠, 按序的交付服务, 拥塞控制, 流量控制, 连接建立<br>
<strong>UDP</strong>: 不可靠的交付服务, 基于尽力而为的网络层, 没有做可靠性方面的扩展<br>
两种服务均不保证 延迟和带宽</p>
<h1 id="多路复用和多路分用">多路复用和多路分用</h1>
<p>如果某层的一个协议对应直接上层的多个协议/实体, 则需要复用/分用<br>
<strong>接收端进行多路分用</strong>, 传输层依据头部信息将收到的Segment交给正确的socket, 即不同的进程<br>
<strong>发送端进行多路复用</strong>, 从多个socket接受数据, 为每块数据封装上头部信息, 生成segment交给网络层<br>
<strong>分用</strong>: 主机接收到ip数据报(datagram), 每个数据报携带源ip地址, 目的ip地址, 携带一个传输层的段(Segment), 每个段携带源端口号和目的端口号, 主机收到segment之后, 传输层协议提取ip地址和端口号信息, 将segment导向相应的socket<br>
<strong>UDP的无连接分用</strong>, 利用端口号创建Socket, UDP的socket用二元组标识(目的IP地址, 目的端口号), 主机收到UDP段后, 检查段中的目的端口号, 将UDP段导向绑定在该端口号的socket, 来自不同源ip地址和源端口号的ip数据报被导向同一个socket<br>
<strong>TCP的面向连接的分用</strong>, TCP的socket用四元组标识, (源ip地址, 源端口号, 目的ip地址, 目的端口号), 接收端利用所有的四个值, 将segment导向合适的socket, 服务器可能同时支持多个tcp socket 每个socket用自己的四元组标识, web服务器为每个客户端开不同的socket</p>
<h1 id="UDP-User-Datagram-Protocol">UDP(User Datagram Protocol)</h1>
<ul>
<li>基于internet IP协议, 复用/分用, 简单的错误校验</li>
<li>best effort服务, UDP段可能丢失或非按序到达</li>
<li>无连接, UDP发送方和接收方之间不需要握手, 每个UDP段的处理独立于其他段</li>
</ul>
<p><strong>优点</strong>: 无需建立连接, 减少延迟, 实现简单, 无需维护连接状态, 头部开销少, 没有拥塞控制应用可更好的控制发送时间和速率<br>
常用于流媒体应用, 容忍丢失, 速率敏感, 还用于DNS, SNMP<br>
想在UDP上实现可靠数据传输, 需要在应用层增加可靠性机制, 或应用特定的错误恢复机制<br>
UDP的校验和(checksum), 检测UDP段在传输中是否发生错误</p>
<h1 id="可靠数据传输的基本原理">可靠数据传输的基本原理</h1>
<p><strong>什么是可靠</strong>: 不错, 不丢, 不乱<br>
<strong>可靠数据传输协议(rdt)</strong>, 对应用层, 传输层, 链路层都很重要, <strong>网络top10问题</strong>, 信道的不可靠特性决定了rdt的复杂性<br>
渐进的设计可靠数据传输协议的发送方和接收方, 只考虑单向数据传输, 但控制信息双向流动, 利用状态机(Finite State Machine, FSM)刻画传输协议</p>
<h2 id="Rdt1-0-可靠信道上的可靠数据传输">Rdt1.0, 可靠信道上的可靠数据传输</h2>
<p>底层信道完全可靠, 不会发生错误, 不会丢弃分组<br>
发送方和接收方的FSM独立, 一个发送, 一个接收, 没有其他交集</p>
<h2 id="Rdt2-0-产生位错误的信道">Rdt2.0, 产生位错误的信道</h2>
<p>底层信道可能翻转分组中的位, 利用校验和检测位错误<br>
恢复机制<br>
<strong>确认机制(Acknowledgements, ACK)</strong>, 接收方显式的告知发送方分组已正确接收<br>
<strong>NAK</strong>, 显式的告知分组有错误, 发送方收到NAK后重传分组<br>
基于这种重传机制的rdt协议称为ARQ协议(Automatic Repeat reQuest)<br>
该版本中引入的新机制, 差错检测, 接收方反馈控制消息, ACK/NAK, 重传<br>
FSM使用停-等协议</p>
<h2 id="Rdt2-1">Rdt2.1</h2>
<p>上一个版本有缺陷, 如果ACK/NAK消息发生错误, 会死循环<br>
所以, <strong>为ACK/NAK增加校验和</strong>, 检错并纠错, 如果被破坏, 发送方重传, 发送方给每个分组添加序列号, 解决重复分组, 接收方丢弃重复分组</p>
<h2 id="Rdt2-2-无NAK消息协议">Rdt2.2 无NAK消息协议</h2>
<p>其他与2.1相同, <strong>只使用ACK</strong>, 在ACK消息中加入被确认分组的序列号, 发送方收到不符合预期的序列号, 则重传当前分组</p>
<h2 id="Rdt3-0-信道既可能发生错误-也可能分组丢失">Rdt3.0 信道既可能发生错误, 也可能分组丢失</h2>
<p>发送方<strong>等待合理时间</strong>, 未收到ACK则重传, 如果ACK消息没丢但延迟到达, 序列号机制能解决重复, 需要定时器<br>
Rdt3.0能正确工作, 保证可靠, 但性能很差, 因为网络协议而限制了物力资源的利用, 因为有停等操作</p>
<h1 id="滑动窗口协议">滑动窗口协议</h1>
<p>流水线机制, 提高资源利用率<br>
<strong>流水线协议</strong>, 允许发送方在收到ACK之前连续发送多个分组, 需要更大的序列号范围, 发送方和接收方需要更大的存储空间以缓存分组<br>
<strong>滑动窗口协议(Sliding-window protocol)</strong><br>
窗口: 允许使用的序列号范围, 窗口尺寸为N表示最多有N个等待确认的消息<br>
滑动窗口:随着协议的运行, 窗口在序列号空间内向前滑动<br>
滑动窗口协议有GBN和SR</p>
<ul>
<li>GBN协议(Go-Back-N), 分组头部包含k-bit序列号, 窗口尺寸为N, 最多允许N个分组未确认, ACK(n), 确认到序列号n的分组均已被正确接收, 为空中的分组设置计时器, 超时后重传序列号大于等于n, 还未收到ACK的所有分组</li>
<li>SE协议(Selective Repeat), 接收方对每个分组单独进行确认, 设置缓存机制, 缓存乱序到达分组, 发送方只重传那些没收到ACK的分组, 为每个分组设置定时器, 发送方窗口, N个连续的序列号, 限制已发送且未确认的分组</li>
</ul>
<h1 id="TCP概述">TCP概述</h1>
<ul>
<li>点对点, 一个发送方, 一个接收方</li>
<li>可靠的, 按序的字节流</li>
<li>采用流水线机制, TCP拥塞控制和流量控制设置窗口尺寸</li>
<li>发送方和接收方都有缓存</li>
<li>全双工, 同一连接中能够传输双向数据流</li>
<li>面向连接, 通信双方在发送数据之前必须建立连接, 连接状态只在连接的两端中维护, 沿途节点上并不维护状态, TCP连接包括两台主机上的缓存, 连接状态变量, socket等</li>
<li>流量控制机制</li>
</ul>
<h2 id="TCP段结构">TCP段结构</h2>
<p><img src="https://www.wangdanpeng.com/img/20220209_1.png" alt="TCP段结构"></p>
<blockquote>
<p>U: URG,urgent data紧急数据, 一般不使用<br>
A: ACK, 标志位, 标识ACK是不是有效<br>
P: PSH,push data now,一般没用<br>
R: RST, S: SYN, F: FIN这三个连接建立拆除时使用</p>
</blockquote>
<p><img src="https://www.wangdanpeng.com/img/20220217_1.png" alt="telnet"></p>
<blockquote>
<p>序列号(seq), 是segment中第一个字节的编号, 而不是segment的编号, 建立TCP连接时, 双方随机选择序列号<br>
ACKs, 希望收到的下一个字节的序列号, 累计确认机制, 表示该序列号之前的所有字节均已被正确接收到</p>
</blockquote>
<p>乱序到达问题, TCP规范中没有规定, 由实现者自己决策</p>
<h2 id="TCP的可靠数据传输">TCP的可靠数据传输</h2>
<p>在IP层提供的不可靠服务基础上实现可靠数据传输</p>
<ul>
<li>流水线机制</li>
<li>累计确认</li>
<li>使用单一重传定时器</li>
</ul>
<p><strong>定时器的设置</strong>: 测量多个抽样RTT求平均, 并且对后续的值做加权平均, 超时时间同理<br>
触发重传的事件有<strong>超时</strong>和<strong>收到重复ACK</strong><br>
<strong>快速重传机制</strong>: 如果收到同一数据的3个ACK, 则假定该数据之后的段已经丢失, 立即重传</p>
<h2 id="TCP流量控制">TCP流量控制</h2>
<p><strong>目的: 发送方不会传输的太多太快以至于淹没接收方(buffer溢出)</strong><br>
接收方为TCP连接分配buffer<br>
接收方通过在Segment的头部字段将可用buffer告诉发送方, 发送方限制自己已发送的但还未收到ACK的数据不超过接收方的空闲buffer尺寸</p>
<h2 id="TCP连接管理">TCP连接管理</h2>
<p><strong>三次握手</strong></p>
<ul>
<li>第一次, 客户端向服务器发送TCP SYNsegment</li>
<li>第二次服务器接收SYN, 回复SYNACK</li>
<li>第三次, 客户端接收SYNACK, 再回复ACK</li>
</ul>
<p>关闭连接</p>
<ul>
<li>客户端向服务器发送TCP FIN控制segment</li>
<li>服务器收到FIN, 回复ACK, 关闭连接, 发送FIN</li>
<li>客户端收到FIN回复ACK</li>
<li>服务器收到ACK, 连接关闭</li>
</ul>
<h1 id="拥塞控制原理">拥塞控制原理</h1>
<p><strong>同样是top10问题</strong>, 核心是太多主机发送太多数据以至于网络无法处理, 表现是分组丢失(路由器缓存溢出), 分组延迟过大(在路由器缓存中排队)<br>
<strong>两种控制方法</strong></p>
<ul>
<li>端到端拥塞控制: 网络层不需要显式的提供支持, 端系统通过观察loss和delay等网络行为判断是否发生拥塞, TCP采用这种</li>
<li>网络辅助的拥塞控制: 路由器向发送方显式的反馈网络拥塞信息, 指示发送方应该采取何种速率, ATM采用这种</li>
</ul>
<p><strong>ATM的实现</strong><br>
发送方发送RM(resource management) cells, 交换机设置RM的标志位, 接收方再把RM cell返回给发送方,<br>
在RM cell中有显式的速率字段ER, 两个字节, 拥塞的交换机可以将ER置为更低的值, 发送方就能得知路径所能支持的最小速率</p>
<p><strong>TCP拥塞控制的基本原理</strong><br>
Sender限制发送速率</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>≈</mo><mfrac><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>g</mi><mi>W</mi><mi>i</mi><mi>n</mi></mrow><mrow><mi>R</mi><mi>T</mi><mi>T</mi></mrow></mfrac><mi>B</mi><mi>y</mi><mi>t</mi><mi>e</mi><mi>s</mi><mi mathvariant="normal">/</mi><mi>s</mi><mi>e</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">rate\approx \frac{CongWin}{RTT}Bytes/sec
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.36033em;"></span><span class="strut bottom" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">e</span><span class="mrel">≈</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mord mathit">i</span><span class="mord mathit">n</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit">t</span><span class="mord mathit">e</span><span class="mord mathit">s</span><span class="mord mathrm">/</span><span class="mord mathit">s</span><span class="mord mathit">e</span><span class="mord mathit">c</span></span></span></span></span></p>
<blockquote>
<p>CongWin动态调整以改变发送速率, 并能反映所感知到的网络拥塞</p>
</blockquote>
<p><strong>速率调整</strong><br>
通过加性增-乘性减和慢启动能合理的调整发送速率</p>
<ul>
<li><strong>加性增-乘性减(AIMD)</strong>: 逐渐增加发送速率, 谨慎探测可用带宽, 直到发生loss, 发生loss后CongWin直接减半</li>
<li><strong>慢启动</strong>: TCP连接建立时, 可用带宽可能远高于初始速率, 所以当连接开始时, 指数性增长, 每个RTT将CongWin翻倍</li>
</ul>
<p><strong>拥塞避免</strong><br>
设置变量Threshold, 当发送loss, 设置为loss事件前congWin值的一半, 当congWin到达threshold, 指数性增长切换为线性增长</p>
<p><strong>loss事件处理</strong><br>
当3个重复ACKs, Congwin切到一半然后线性<br>
timeout事件, CongWin直接设为1然后指数, 达到threshold后再线性增长<br>
3个重复ACKs表示网络还能传输一些segments, timeout表示拥堵更为严重</p>
<p><strong>性能分析</strong><br>
TCP的平均吞吐率是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>W</mi><mi mathvariant="normal">/</mi><mi>R</mi><mi>T</mi><mi>T</mi><mo>+</mo><mi>W</mi><mi mathvariant="normal">/</mi><mn>2</mn><mi>R</mi><mi>T</mi><mi>T</mi><mo>)</mo><mi mathvariant="normal">/</mi><mn>2</mn><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn><mn>5</mn><mi>W</mi><mi mathvariant="normal">/</mi><mi>R</mi><mi>T</mi><mi>T</mi></mrow><annotation encoding="application/x-tex">(W/RTT+W/2RTT)/2=0.75W/RTT</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mord mathrm">/</span><span class="mord mathrm">2</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mclose">)</span><span class="mord mathrm">/</span><span class="mord mathrm">2</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">7</span><span class="mord mathrm">5</span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span></span><br>
TCP是公平的, 多个tcp session共享带宽<br>
多媒体通常不使用TCP, 以免被拥塞控制机制限制速率, 使用UDP以恒定速率发送, 能够容忍丢失, 但产生了不公平</p>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络系列笔记(六) - 物理层</title>
    <url>/2022/02/25/20220225155352/</url>
    <content><![CDATA[<h1 id="数据通信基础">数据通信基础</h1>
<p>常见数据通信术语</p>
<blockquote>
<p><strong>信源</strong>: 将消息转换为信号的设备<br>
<strong>发送设备</strong>: 将信源产生的信号进行适当的变换装置, 使之适合于在信道中传输, 主要包括编码和调制<br>
<strong>信道</strong>: 信号传输通道, 如物理介质<br>
<strong>噪声</strong>: 自然界和通信设备中所产生的干扰<br>
<strong>接收设备</strong>: 完成发送设备反变换, 还原原始发送信号<br>
<strong>信宿</strong>: 信号终点, 将信号转换为供人们能识别的消息<br>
<strong>数据</strong>: 传送消息的实体<br>
<strong>信号</strong>: 数据的电气的或电磁的表示<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>(</mo><mi>t</mi><mo>)</mo><mo>=</mo><mi>A</mi><mi>s</mi><mi>i</mi><mi>n</mi><mo>(</mo><mi>ω</mi><mi>t</mi><mo>+</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">y(t)=Asin(\omega t+\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathit">t</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">A</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">ω</span><span class="mord mathit">t</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><br>
<strong>模拟的</strong>: 参数的取值是连续的<br>
<strong>数字的</strong>: 参数的取值是离散的<br>
<strong>码元</strong>: 信号基本波形, 信号的基本单元<br>
<strong>频带</strong>: 信号频率范围<br>
<strong>带宽</strong>: 有效带宽<br>
<strong>数据通信方式</strong>: 单工, 半双工, 全双工</p>
</blockquote>
<p><strong>信源编码</strong><br>
使信源产生的模拟数据在数字通信系统中传输<br>
典型新原编码: <strong>PCM</strong><br>
PCM三个步骤:</p>
<ul>
<li>采样: 目的就是要用一系列在时间上离散的采样值, 代替时间上连续的模拟数据, 即实现时间上的离散化</li>
<li>量化: 就是使采样值在取值上离散化</li>
<li>编码: 就是将量化后的采样值用一定位数的二进制数码来表示</li>
</ul>
<h1 id="物理介质">物理介质</h1>
<p><strong>导引型传输介质</strong></p>
<ul>
<li>架空明线, 易受天气和外界电磁干扰, 对外界噪声敏感, 带宽有限</li>
<li>双绞线, 主要用于基带传输</li>
<li>同轴电缆, 主要用于频带传输</li>
<li>光纤, 基本原理光的全反射, 分为多模光纤和单模光纤两类</li>
</ul>
<p><strong>非导引型传输介质</strong></p>
<ul>
<li>自由空间, 无线电传输途径, 不同频段具有不同传播特性</li>
<li>地波传播, 频率较低的电磁波趋于沿地球表面传播, 有一定的绕射能力, 在低频和甚低频段, 地波传播距离可超过数百米或数千公里</li>
<li>天波传播, 电离层, 频率较高的电磁波会被电离层反射, 电离层的密度和厚度随时间随机变化, 电磁波可以传播一万千米以上, 随参信道</li>
<li>视线传播, 频率高于30MHz的电磁波将穿透电离层, 不会被反射回来, 沿地面绕射能力也很弱, 通常采用视线无障碍的点对点直线传播, 可以设立地面中继站或卫星中继站进行接力传输</li>
</ul>
<h1 id="信道与信道容量">信道与信道容量</h1>
<p>狭义上的信道: 信号传输介质<br>
广义上的信道: 包括信号传播介质和通信系统的一些变换装置, 比如发送设备, 接收设备, 天线, 调制器等<br>
<strong>恒参信道传输特性</strong></p>
<ul>
<li>各种有线信道和部分无线信道, 如微波视线传播链路和卫星链路等</li>
<li>理想的恒参信道是一个理想的无失真传输信道</li>
<li>对信号幅值产生固定的衰减</li>
<li>对信号输出产生固定的时延</li>
</ul>
<p><strong>随参信道传输特性</strong></p>
<ul>
<li>许多无线信道都是随参信道</li>
<li>信号的传输衰减随时间随机变化</li>
<li>信号的传输时延随时间随机变化</li>
<li>存在多径传播现象</li>
</ul>
<p>信道容量: 信道无差错传输信息的最大平均信息速率<br>
<strong>奈奎斯特(Nyquist)信道容量公式</strong>: 理想无噪声信道的信道极限容量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><mn>2</mn><mi>B</mi><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>M</mi></mrow><annotation encoding="application/x-tex">C=2Blog_2M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mrel">=</span><span class="mord mathrm">2</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.10903em;">M</span></span></span></span></p>
<blockquote>
<p>C为信道容量, 单位b/s; B为信道带宽, 单位为Hz; M为进制数, 即信号状态数</p>
</blockquote>
<p><strong>香农(Shannon)信道容量公式</strong>: 有噪声信道的信道容量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><mi>B</mi><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo>(</mo><mn>1</mn><mo>+</mo><mi>S</mi><mi mathvariant="normal">/</mi><mi>N</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">C=Blog_2(1+S/N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathrm">/</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span></p>
<blockquote>
<p>S/N为信噪比, 即信号能量与噪声能量之比, 单位分贝(dB)</p>
</blockquote>
<h1 id="基带传输基础">基带传输基础</h1>
<p>基带信号: 信源发出的原始电信号, 往往包含有较多的低频成分, 甚至有直流成分<br>
<strong>基带传输</strong>: 直接在信道中传送基带信号<br>
基带信号比较适合在具有低通特性的有线信道中传输, 通常不适合在无线信道中直接传输<br>
典型数字基带信号码型</p>
<ul>
<li>单极不归零码, 易于产生, 不适合长距离传输</li>
<li>双极不归零码</li>
<li>单极归零码</li>
<li>双极归零码</li>
<li>差分码, 又称相对码</li>
<li>AMI码, 信号交替反转码</li>
<li>双相码, 又称曼彻斯特码</li>
<li>nBmB码</li>
</ul>
<h1 id="频带传输基础">频带传输基础</h1>
<p>许多带通信道(如无线信道)不具有低通特性, 因此不能在这些信道中直接传输基带信号, 只能利用基带信号去调制与对应信道传播特性相匹配的载波信号<br>
利用模拟基带信号调制载波, 称为模拟调制, 利用数字基带信号调制载波, 称为数字调制<br>
频带传输系统通常选择正弦波信号作为载波<br>
<strong>二进制数字调制</strong></p>
<ul>
<li>二进制幅移键控(2ASK)</li>
<li>二进制频移键控(2FSK)</li>
<li>二进制相移键控(2PSK)</li>
<li>二进制差分相移键控(2DPSK)</li>
</ul>
<p><strong>频带利用率</strong>: 2ASK, 2PSK及2DPSK的频带利用率相同, 2FSK的频带利用率最低<br>
<strong>误码率</strong>: 相同信噪比下, 2PSK最低, 2ASK最高<br>
<strong>对信道特性的敏感性</strong>: 2ASK对信道特性变化比较敏感, 性能最差, 2FSK与2PSK不敏感</p>
<h1 id="物理层接口规程">物理层接口规程</h1>
<p>机械特性: 指明接口所用接线器的形状和尺寸, 引线数目和排列, 固定和锁定装置等等<br>
电气特性: 指明在接口电缆的各条线上出现的电压的范围<br>
功能特性: 指明某条线上出现的某一电平的电压表示何种意义<br>
过程特性: 指明对于不同功能的各种可能事件的出现顺序</p>
]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机基础 - 位运算</title>
    <url>/2022/03/09/20220309150604/</url>
    <content><![CDATA[<h1 id="与运算">与运算</h1>
<p><code>&amp;</code>, 与, 两位都为1, 结果才为1, (都真才真)</p>
<h2 id="与的用途">与的用途</h2>
<p><strong>清零</strong><br>
如果想将一个单元清零, 只要与一个各位都为零的数相与, 结果就为零<br>
<strong>取一个数的指定位</strong><br>
比如取x的低四位, 只需要找另一个数y, 令y的低4位为1, 其余位为0, 然后x和y按位与运算, 即可得到x的指定位<br>
<strong>判断奇偶</strong><br>
二进制末位是0就是偶数, 1就是奇数, 可以用a&amp;1==0判断a是不是偶数</p>
<h1 id="或运算">或运算</h1>
<p><code>|</code>, 或, 两位都为0, 结果才为0, (都假才假)</p>
<h2 id="或的用途">或的用途</h2>
<p><strong>对一个数据的某些位设置为1</strong><br>
比如将x的低四位设置为1, 只需要找另一个数y, 令y的低4位为1, 其余位为0, 然后x和y按位与运算, 即可得到</p>
<h1 id="异或运算">异或运算</h1>
<p><code>^</code>, 异或, 两位相同为0, 两位不同为1, (不同才真)</p>
<h2 id="异或特性">异或特性</h2>
<ul>
<li>交换律</li>
<li>结合律</li>
<li>对任何数x, 异或自身等于0, 异或0等于自身</li>
<li><strong>自反性</strong>, a^b^b=a^0=a, 即任何数a用任何数b连续做两次异或, 仍得到a本身, 异或最重要的性质</li>
</ul>
<h2 id="异或的应用">异或的应用</h2>
<p><strong>两数交换</strong><br>
例如交换两个变量的值且不引入中间变量, 可用如下表达式:<br>
假设A的值为a, B的值为b<br>
A = A^B (a^b)<br>
B = A^B (a^b ^ b)<br>
A = A^B (a^b ^ a)<br>
即运用了异或的自反性, 类似的该运算还可以应用在加密, 数据传输, 校验等许多领域<br>
<strong>找到出现奇数次的数</strong><br>
一个数组有若干整数, 一个数出现奇数次, 其余均出现偶数次, 找到这个出现奇数次的数, 就可以把所有数异或, 最后结果就是要找的数, 同样是应用异或的自反性<br>
<strong>反转指定位</strong><br>
比如将x的低四位进行反转, 只需要找另一个数y, 令y的低4位为1, 其余位为0, 然后x和y进行异或, 即可得到</p>
<h1 id="取反运算">取反运算</h1>
<p><code>~</code>, 取反, 0变1, 1变0</p>
<h2 id="用途">用途</h2>
<p>使一个数的最低位置零, 可以使用a &amp; ~1, 1取反的值为最低位是0其余位都是1, 再和a与运算, 得到最低位为0, 其余位不变</p>
<p><em>~运算符优先级比算术运算符(加减乘除), 关系运算符(大小等于), 逻辑运算符(与或非)和其他运算符(三目运算符)都高</em></p>
<h1 id="左移">左移</h1>
<p><code>&lt;&lt;</code>, 左移, 各个二进制位全部向左移动若干位, 高位丢弃, 低位补0</p>
<p>若左移时舍弃的高位不包含1, 则每左移一位相当于该数乘以2</p>
<h1 id="右移">右移</h1>
<p><code>&gt;&gt;</code>, 右移, 各个二进制位全部向右移动若干位, 对无符号的数, 高位补0, 对有符号数, 各编译器处理方法不一, 有的补符号位, 有的补0</p>
<p>操作数每右移一位, 相当于该数除以2</p>
<h1 id="运算规则">运算规则</h1>
<p>不同长度的数据进行位运算, 如果两个不同长度的数据进行位运算时, 系统会将二者按<strong>右端对齐</strong>, 然后进行位运算<br>
右端对齐后, 左边不足的位</p>
<ul>
<li>如果整型数据为正数, 左边补0</li>
<li>如果整型数据为负数, 左边补1</li>
<li>如果整型数据为无符号数, 左边也补0</li>
</ul>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式 - 数据一致性的部分指导理论(CAP, BASE, 2PC, 3PC)</title>
    <url>/2022/04/24/20220424172338/</url>
    <content><![CDATA[<p>分布式 - 数据一致性的部分指导理论(CAP, BASE, 2PC, 3PC)</p>
<h1 id="CAP理论">CAP理论</h1>
<h2 id="概述">概述</h2>
<p>分布式系统最大的难点, 就是各个节点的状态如何保持一致, CAP理论是在设计分布式系统的过程中, 处理数据一致性问题时必须考虑的理论.<br>
CAP理论的本质很简单, 它就是一种分布式系统设计的不同理念概括.</p>
<p><img src="http://www.wangdanpeng.com/img/20220424172338.png" alt="CAP"></p>
<p>CAP理论说, 一个分布式系统, 不能同时满足以下三个特性:</p>
<ul>
<li><strong>一致性(Consistency)</strong>: 对于客户端的每次读操作, 要么读到最新数据, 要么读取失败, 强调数据正确</li>
<li><strong>可用性(Availability)</strong>: 任何客户端的请求都能得到返回数据, 不会出现失败(返回时间必须合理, 过长也不行), 不保证数据最新, 但强调不出错</li>
<li><strong>分区容忍性(Partition tolerance)</strong>: 当发生网络分区时, 系统能正常运行</li>
</ul>
<blockquote>
<p>网络分区: 一个分布式系统里, 节点组成的网络本来是连通的, 然而可能因为一些网络或设备故障, 使得有些节点之间不连通了, 整个网络就分成了几块区域,<br>
数据就散步在这些不连通的区域中, 这就叫分区</p>
</blockquote>
<p>对分布式系统而言, P是前提必须保证, 因为只要有网络交互, 分区错误是必然发生的, 所以只能考虑当发生分区错误时, 如何选择一致性和可用性.<br>
而根据选择不同, 开源的分布式系统往往被分为CP系统和AP系统</p>
<ul>
<li>当一套系统发生分区故障后, 客户端的请求会被卡死或者超时, 但系统每个节点总是返回一致的数据, 那么这套系统就是CP系统, 例如Zookeeper</li>
<li>当一套系统发生分区故障后, 客户端依然能访问系统, 但获取的数据有新有旧, 那么这套系统就是AP系统, 例如Eureka</li>
</ul>
<h2 id="注意">注意</h2>
<p>有两点容易存在误区</p>
<ul>
<li>CAP理论并非是在所有时候都只能选择两个特性, 分区错误发生概率很低, 在不存在网络失败情况下, c和a是能同时保证的, 只有当网络发生分区或失败时, 才会在c和a之间做出选择</li>
<li>对C和A的选择不必是针对整个系统的, 可以对不同子系统有不同的抉择</li>
</ul>
<h2 id="CAP的不足">CAP的不足</h2>
<ol>
<li>CAP理论本身是没有考虑网络延迟问题的, 它认为一致性是立即生效的, 但是要保持一致性, 是需要时间成本的</li>
<li>实践中一致性和可用性并不仅仅是二选一的关系, 只是一些重要性的区别, 往往选择一方的同时, 也会采用一些技术手段去保证另一项</li>
<li>CAP理论只是一种对状态的描述, 但对状态间如何转换, 如何修补, 如何恢复并没有提供方向</li>
</ol>
<p>针对CAP的不足, 延伸出了BASE理论, 弥补了CAP理论过于抽象的问题</p>
<h1 id="BASE理论">BASE理论</h1>
<h2 id="理论">理论</h2>
<p>BASE理论是一种处理分布式事务的思想, 没有具体的操作步骤, 要理解BASE理论需要结合具体的例子.</p>
<p>BASE理论是对CAP中一致性和可用性权衡的结果, 来源于对大规模互联网分布式系统实践的总结, 基于CAP理论演化而来<br>
<strong>核心思想</strong>是即使无法做到强一致性, 但每个应用都可以根据自身业务特点, 采用适当的方式来使系统达到最终一致性.</p>
<p>实际上, 网络分区出现情况很少, CAP在大多时间能够同时满足C和A, 对于分区错误出现的情况下, 需要提供一种预备策略做处理:</p>
<ul>
<li>探知网络分区的发生</li>
<li>进入显式的分区模式, 限制某些操作</li>
<li>启动恢复过程, 恢复数据一致性, 补偿分区发生期间的错误</li>
</ul>
<h2 id="定义">定义</h2>
<p>BASE理论核心</p>
<ul>
<li><strong>Basically Available(基本可用)</strong><br>
出现了不可预知的故障, 但还能用, 相比较正常的系统, 可能有响应上的损失或者功能上的损失<br>
在架构设计中, 把以前可能影响全平台的严重问题, 变成只会影响平台的一部分数据或者功能的非严重问题</li>
<li><strong>Soft State(软状态)</strong><br>
允许系统中的数据存在中间状态, 并认为该状态不影响系统的整体可用性, 即允许系统在多个不同节点的数据副本存在数据延时<br>
对实时性不高的数据可以延后处理</li>
<li><strong>Eventually Consistent(最终一致性)</strong><br>
软状态不能一直持续, 在一定时间期限过后, 应当保证所有副本保持数据一致性, 从而达到最终一致性, 这个时间期限取决于网络延时, 系统负载, 数据复制方案等等因素<br>
对于不符合业务需求的软状态, 通过一些后续内部的自动化操作把数据状态补充完整从而最终满足业务需求.</li>
</ul>
<p>总体来说BASE理论面向的是大型高可用, 可扩展的分布式系统, 与传统ACID特性相反, 不同于ACID的强一致性模型, BASE提出通过牺牲强一致性来获得可用性<br>
并允许数据段时间内的不一致, 但是最终达到一致状态.</p>
<blockquote>
<p>ACID<br>
<strong>Atomicity(原子性)</strong>: 不管事务里执行多少命令, 对外它们是一体的, 要么都执行, 要么都不执行<br>
<strong>Consistency(一致性)</strong>: 事务执行前后, 数据从一个状态到另一个状态必须是一致的<br>
<strong>Isolation(隔离性)</strong>: 多个并发事务之间相互隔离，不能互相干扰<br>
<strong>Durability(持久性)</strong>: 事务完成后，对数据库的更改是永久保存的，不能回滚</p>
</blockquote>
<h1 id="2PC">2PC</h1>
<p>两阶段提交协议, 又称2PC(two-phase commit protocol), X/Open XA协议的经典实现, 是一个非常经典的强一致, 中心化的原子提交协议<br>
协议中有两类节点, 一个<strong>中心化协调者</strong>节点(cordinator)和N个<strong>参与者</strong>节点(partcipant)</p>
<p><strong>两阶段提交是指, 整个过程中存在两个阶段的处理流程</strong></p>
<ul>
<li>第一阶段, 请求阶段<br>
当分布式事务的发起方向协调者发送请求时, 协调者分别向参与者发送事务预处理请求, 称之为Prepare<br>
参与者开始执行本地事务, 但执行完成后并不提交事务, 而是先向协调者报告自己能否执行成功<br>
当所有参与者都向协调者做出反馈, 此时流程进入第二阶段</li>
<li>第二阶段, 提交阶段<br>
如果所有参与者都报告能执行成功, 那么协调者会向所有参与者发送Commit请求, 参与者就会完成自身事务的提交, 并将最终提交结果回复给协调者, 协调者再向调用方返回分布式事务处理完成的结果<br>
–<br>
相反如果有参与者报告执行会失败, 此时协调者就会向所有参与者发送Rollback请求, 参与者回滚本地事务释放资源, 并向协调者发送ack消息, 协调者再向调用方返回分布式事务处理失败的结果</li>
</ul>
<p>但2PC也存在一些问题:</p>
<ul>
<li>性能问题, 在1,2阶段的执行过程中, 所有参与者的事务操作都是处于阻塞状态</li>
<li>单点故障, 协调者是单点, 如果协调者出现问题, 整个流程就会锁住无法执行, 参与者也没有超时机制</li>
<li>数据不一致, 二阶段协调者向参与者发送提交通知, 如果网络抖动, 部分参与者收到了部分参与者没收到, 则会出现数据不一致现象</li>
</ul>
<h1 id="3PC">3PC</h1>
<p>三阶段提交协议, 是2PC的改进版, 将请求阶段一分为二, 变成canCommit, preCommit和doCommit三个阶段组成的事务处理协议, 并且引入了超时机制</p>
<ul>
<li>第一阶段 canCommit<br>
协调者向所有参与者发送canCommit请求, 询问是否可以执行事务提交操作, 然后开始等待参与者响应<br>
参与者收到请求后, 检查自身状态及资源, 确认可以顺利执行事务则返回yes, 否则返回no</li>
<li>第二阶段 preCommit<br>
如果所有参与者反馈yes, 则协调者向参与者发送preCommit请求, 参与者收到请求, 执行事务操作, 但不提交事务, 如果参与者成功执行了事务, 则返回ack确认响应, 同时等待最终命令<br>
–<br>
如果有参与者反馈no或者等待超时, 协调者向所有参与者发送abort请求或参与者超时未收到协调者请求, 参与者执行事务中断</li>
<li>第三阶段 doCommit<br>
协调者收到参与者发送的ack响应后<br>
如果参与者都能执行成功, 向所有参与者发送doCommit请求, 参与者收到请求后, 执行正式的事务提交, 并在完成之后释放事务资源, 向协调者发送ack响应, 协调者收到所有ack后完成事务<br>
–<br>
当有参与者在二阶段未完成反馈或者反馈超时, 则协调者向所有参与者发送abort请求, 参与者收到请求后, 回滚事务, 并释放所有事务的资源, 然后向协调者发送ack响应, 协调者收到所有ack后, 执行事务的中断</li>
</ul>
<p><strong>但3PC依旧存在单点故障和数据不一致问题</strong></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>一致性</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机基础-浮点数</title>
    <url>/2022/06/15/20220615190759/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>想要理解浮点数为什么叫浮点数, 浮点是什么意思, 先告诉你它有个兄弟叫定点数</p>
<h1 id="定点数">定点数</h1>
<p>一个32位计算机想要存储小数, 最简单的方法是什么<br>
<strong>把32位分成三部分, 一位表示正负, 8位表示整数部分, 23位表示小数部分</strong><br>
<img src="http://www.wangdanpeng.com/img/20220615190759_1.png" alt="1"></p>
<p>由于小数点固定在了第23位和第24位之间, 这种方式可以称为“定点数”<br>
<strong>但小数点固定在哪个位置呢</strong><br>
整数部分小了, 表示的数据范围就很小<br>
整数部分大了, 小数的精度又会降低<br>
所以用定点数表示法, 范围和精度相互矛盾, 并不是一种完美的解决方案</p>
<h1 id="浮点数">浮点数</h1>
<p>那么怎么弥补定点数的短板, 就可以用到类似科学计数法, 利用指数, 可以达到小数点浮动的效果<br>
IEEE 754标准中, 浮点数有单精度(32位)和双精度(64位), 以单精度为例<br>
<img src="http://www.wangdanpeng.com/img/20220615190759_2.png" alt="2"></p>
<p>科学计数法表示为</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>=</mo><mo>(</mo><mo>−</mo><mn>1</mn><msup><mo>)</mo><mi>s</mi></msup><mo>∗</mo><mn>1</mn><mi mathvariant="normal">.</mi><mo>(</mo><mi>m</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>s</mi><mi>a</mi><mo>)</mo><mo>∗</mo><msup><mn>2</mn><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">n = (-1)^s * 1.(mantissa) * 2 ^{exponent}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.843556em;"></span><span class="strut bottom" style="height:1.093556em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">n</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathrm">1</span><span class="mclose"><span class="mclose">)</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">s</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">∗</span><span class="mord mathrm">1</span><span class="mord mathrm">.</span><span class="mopen">(</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">s</span><span class="mord mathit">s</span><span class="mord mathit">a</span><span class="mclose">)</span><span class="mbin">∗</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.41300000000000003em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">e</span><span class="mord mathit">x</span><span class="mord mathit">p</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mord mathit">e</span><span class="mord mathit">n</span><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p>
<p>那么例如 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mi mathvariant="normal">.</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">5.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">5</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span></span></span></span> 就可以转换为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mi mathvariant="normal">.</mi><mn>4</mn><mn>5</mn><mo>∗</mo><msup><mn>2</mn><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">1.45*2^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">.</span><span class="mord mathrm">4</span><span class="mord mathrm">5</span><span class="mbin">∗</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> (原数一直除2, 直到整数部分为1)</p>
<blockquote>
<p>注意: 指数也分正负, 此处有一个偏置值<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo>=</mo><msup><mn>2</mn><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">bias=2^{k-1}-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:0.932438em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span><span class="mrel">=</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span> , k为exponent的位数<br>
单精度浮点数bias则为127, 从0到127 表示负数， 从128到255表示正数</p>
</blockquote>
<p>那么 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mi mathvariant="normal">.</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">5.8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">5</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mi>o</mi><mi>n</mi><mi>e</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>1</mn><mn>2</mn><mn>7</mn><mo>+</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">exponent=127+2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">e</span><span class="mord mathit">x</span><span class="mord mathit">p</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mord mathit">e</span><span class="mord mathit">n</span><span class="mord mathit">t</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">2</span><span class="mord mathrm">7</span><span class="mbin">+</span><span class="mord mathrm">2</span></span></span></span><br>
尾数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">.</mi><mn>4</mn><mn>5</mn></mrow><annotation encoding="application/x-tex">0.45</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">4</span><span class="mord mathrm">5</span></span></span></span> 转化为二进制就是不断地乘2, 取结果的整数部分, 无限循环的话取够23位为止, 此处会有忽略, 所以<strong>浮点数不是精确的数值类型</strong></p>
<p>通过上面的过程, 基本了解了浮点数如何表示一般的小数, 那么浮点数怎么表示0呢</p>
<h1 id="规格化和非规格化">规格化和非规格化</h1>
<p>指数部分有三种取值:</p>
<ul>
<li>当exponent的二进制位不全为0或1时, 表达的数字是规格化形式, 即一般的小数</li>
<li>当exponent的二进制位都为0时, 此时为非规格化, 用来表示一些非常接近0的小数,包括0<br>
此时表达式为</li>
</ul>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>=</mo><mo>(</mo><mo>−</mo><mn>1</mn><msup><mo>)</mo><mi>s</mi></msup><mo>∗</mo><mn>0</mn><mi mathvariant="normal">.</mi><mo>(</mo><mi>m</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>s</mi><mi>a</mi><mo>)</mo><mo>∗</mo><msup><mn>2</mn><mrow><mn>1</mn><mo>−</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi></mrow></msup></mrow><annotation encoding="application/x-tex">n = (-1)^s * 0.(mantissa) * 2^{1-bias}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.899108em;"></span><span class="strut bottom" style="height:1.149108em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">n</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathrm">1</span><span class="mclose"><span class="mclose">)</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">s</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">∗</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mopen">(</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">s</span><span class="mord mathit">s</span><span class="mord mathit">a</span><span class="mclose">)</span><span class="mbin">∗</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.41300000000000003em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit">b</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit">s</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p>
<p>当所有二进制位都为0, 即可表示0.0</p>
<ul>
<li>当exponent的二进制位全为1时, 表示特殊值<br>
当mantissa全为0时, s为0表示正无穷, s为1表示负无穷<br>
当mantissa不全为0, 则表示NaN(Not a Number)，不是一个合法实数或无穷，或者该数未经初始化</li>
</ul>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark - Spark SQL中RBO, CBO与AQE简单介绍</title>
    <url>/2023/02/10/20230210154146/</url>
    <content><![CDATA[<p>Spark SQL核心是Catalyst, Catalyst执行流程主要分4个阶段, 语句解析, 逻辑计划与优化, 物理计划与优化, 代码生成<br>
前三个阶段都由Catalyst负责, 其中, 逻辑计划的优化采用RBO思路, 物理计划的优化采用CBO思路</p>
<h1 id="RBO-Rule-Based-Optimization">RBO (Rule Based Optimization)</h1>
<p>基于规则优化, 通过一系列预定好的规则(Rule)对逻辑计划进行等价转换, 以提高查询效率<br>
<strong>两个主要思路</strong></p>
<ul>
<li>减少参与计算的数据量</li>
<li>降低重复计算的代价</li>
</ul>
<p>常用的规则都基于经验指定, 可覆盖大部分查询场景, 且方便扩展, 缺点是不够灵活<br>
常用规则例如</p>
<ul>
<li>
<p><strong>常量折叠(ConstantFolding)</strong><br>
把纯常量运算表达式预先转化, 比如把1+2转化为3.0, 消除不必要的重复计算</p>
</li>
<li>
<p><strong>谓词下推(PushdownPredicate)</strong><br>
最常见的用于减少参与计算的数据量的方法<br>
谓词, where条件, join on中的过滤条件<br>
将SQL语句中的谓词逻辑尽量提前执行, 参与join的数据量大大减少, 使得join操作速度大大提高</p>
</li>
<li>
<p><strong>列裁剪(ColumnPruning)</strong><br>
在扫描表时, 只筛选出符合后续逻辑计划的最小列集合, 节省掉扫描全部列的资源<br>
如果使用的Parquet,ORC等列式存储格式持久化的, 效率会更高</p>
</li>
</ul>
<h1 id="CBO-Cost-Based-Optimization">CBO (Cost Based Optimization)</h1>
<p>基于代价优化<br>
CBO优化主要在物理计划层, 原理是计算所有可能的物理计划的代价, 并挑选出代价最小的计划<br>
充分考虑了数据本身的特点(大小, 分布)以及操作算子的特点(中间结果集的分布及大小)及代价, 从而更好的选择执行代价最小的计划</p>
<p>物理执行计划是一个树状结构, 其代价等于每个执行节点的代价总和<br>
每个执行节点的代价, 分为两个部分</p>
<ol>
<li>该执行节点对数据集的影响, 即该节点输出数据集的大小与分布, 又分为两个部分
<ul>
<li>初始数据集, 其大小与分布可直接通过统计得到</li>
<li>中间节点输出数据集的大小与分布, 可由其输入数据集的信息与操作本身的特点推算</li>
</ul>
</li>
<li>该执行节点操作算子的代价, 相对固定, 可用规则来描述</li>
</ol>
<p>CBO优化有, <strong>Build侧选择</strong>, <strong>优化Join类型</strong>, <strong>优化多表Join顺序</strong>等</p>
<p>CBO的问题<br>
数据统计信息普遍缺失, 统计信息的收集代价较高<br>
储存计算分离的架构, 使得收集到的统计信息可能不再准确<br>
Spark部署在某个单一硬件架构上, cost很难被估计<br>
Spark的UDF简单易用, 种类繁多, 但是对于CBO来说是黑盒, 无法估计cost</p>
<h1 id="AQE-Adaptive-Query-Execution">AQE (Adaptive Query Execution)</h1>
<p>CBO是一种静态优化策略, 一旦执行计划交付运行, 就不能再对物理计划进行修改<br>
在分布式系统中使用CBO是一个极其复杂的问题, 在Spark中收集和维护一组准确和最新的统计数据是昂贵的</p>
<p>AQE是Spark SQL的一种动态优化机制, 在运行时, 每当Shuffle Map阶段执行完毕, AQE都会<br>
结合这个阶段的统计信息, 基于既定的规则动态的调整, 修正尚未执行的逻辑计划和物理计划, 来<br>
完成对原始查询语句的运行时优化</p>
<p>AQE的统计信息与CBO不同, 不是关于表, 而是Shuffle Map阶段输出的中间文件<br>
AQE从运行时获取统计信息, 在条件允许的情况下, 优化决策会分别作用到逻辑计划和物理计划</p>
<p>AQE三大特性</p>
<ul>
<li>
<p><strong>自动分区合并</strong><br>
在Shuffle过后, Reduce Task数据分布参差不齐, AQE将自动合并过小的数据分区</p>
</li>
<li>
<p><strong>Join策略调整</strong><br>
如果某张表在过滤后, 尺寸小于广播变量阈值, 这张表参与的Join就会从Shuffle Sort<br>
Merge Join 降级为执行效率更高的Broadcast Hash Join</p>
</li>
<li>
<p><strong>自动倾斜处理</strong><br>
结合配置项, AQE自动拆分Reduce阶段过大的数据分区, 降低单个Reduce Task的工作负载</p>
</li>
</ul>
<p>参考文献</p>
<p><a href="https://www.e-learn.cn/topic/3721574" target="_blank" rel="noopener">CBO探究</a><br>
<a href="https://zhuanlan.zhihu.com/p/533982903" target="_blank" rel="noopener">Spark AQE新特性</a><br>
<a href="http://www.jasongj.com/spark/cbo/" target="_blank" rel="noopener">CBO 基于代价的优化</a><br>
<a href="http://www.jasongj.com/spark/rbo/" target="_blank" rel="noopener">Catalyst 内部原理 与 RBO</a></p>
]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>数学相关 - HyperLogLog算法原理</title>
    <url>/2023/02/15/20230215171913/</url>
    <content><![CDATA[<h2 id="应用场景">应用场景</h2>
<p>当需要对大量数据做去重计数, 例如统计一个页面的UV(Unique Visitor, 独立访客), 或者用户搜索的关键词数量, 比较容易想到的方案有</p>
<ul>
<li>存储到数据库表, 使用distinct count计算</li>
<li>使用Redis的set, bitmap等数据结构</li>
</ul>
<p>但都存在一些问题, 随着数据量增加, 存储空间占用越来越大; 统计速度慢, 性能并不理想</p>
<p>数据分析, 网络监控及数据库优化等领域都会涉及到基数计数的需求.</p>
<blockquote>
<p>基数, 一个集合中不重复元素的个数.</p>
</blockquote>
<p>目前还没有在大数据场景中准确计算基数的高效算法, 因此在允许一定误差的情况下, 使用<strong>概率算法</strong>是一个不错的选择</p>
<h2 id="概率算法">概率算法</h2>
<p>概率算法不直接存储数据本身, 而通过一定的概率统计方法预估基数值, 这种方法可以大大节省内存, 同时保证误差控制在一定范围内<br>
目前用于基数计数的概率算法有</p>
<ul>
<li><strong>LC(Linear Counting)</strong>: 早期的基数估计算法, 在空间复杂度方面不算优秀, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><msub><mi>N</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">O(N_{max})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.10903em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></li>
<li><strong>LLC(LogLog Counting)</strong>: 相比于LC更加节省内存, 空间复杂度只有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo>(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo>(</mo><msub><mi>N</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>)</mo><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">O(log_2(log_2(N_{max})))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.10903em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></li>
<li><strong>HLL(HyperLogLog Counting)</strong>: HLL基于LLC的优化和改进, 在同样空间复杂度情况下, 能够比LLC的基数估计误差更小, 例如Redia中HLL只占12KB, 可以计算接近 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mrow><mn>6</mn><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">2^{64}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathrm">6</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>个不同基数, 标准误差为0.81%</li>
</ul>
<h2 id="极大似然估计">极大似然估计</h2>
<p>极大似然估计是建立在极大似然原理的基础上的一个统计方法, 是概率论在统计学中的应用<br>
极大似然估计提供了一种给定观察数据来评估模型参数的方法, 即: <strong>模型已定, 参数未知</strong><br>
通过若干次试验, 观察其结果, 利用试验结果得到某个参数值能够使样本出现的概率为最大, 则称为极大似然估计</p>
<p>目的就是: 利用已知的样本结果, 反推最有可能/最大概率导致这样结果的参数值</p>
<p>例如有两个箱子, 甲箱有99白球1个黑球, 乙箱有99黑球1白球, 现在取出了一个黑球<br>
问黑球是从哪个箱子取出的<br>
你的第一印象就是黑球最像是从乙箱取出的, 这个推断符合人们的经验事实, 最像就是最大似然之意, 这种想法常称为极大似然原理</p>
<h2 id="伯努利试验">伯努利试验</h2>
<p>伯努利试验(Bernoulli experiment), 是<strong>在同样的条件下重复地, 相互独立地进行的一种随机试验</strong><br>
其特点是该随机试验只有两种可能结果: 发生或者不发生<br>
我们假设该项试验独立重复地进行了n次, 那么就称这一系列重复独立的随机试验为n重伯努利试验<br>
单个伯努利试验是没有多大意义的, 然而当我们反复进行伯努利试验, 去观察这些试验有多少是成功的多少是失败的, 事情就变得有意义了, 这些累计记录包含了很多潜在的非常有用的信息</p>
<p>以抛硬币为例, 每次抛硬币出现正面的概率都是50%, 假设一直抛硬币, 直到出现正面, 则一个伯努利试验结束<br>
假设第1次伯努利试验抛硬币的次数为k<sub>1</sub>, 第n次伯努利试验抛硬币的次数为k<sub>n</sub><br>
我们记录这n次伯努利试验的最大抛硬币次数为k<sub>max</sub><br>
那么重点来了<br>
<strong>在某次伯努利试验中, k<sub>max</sub>出现的概率, 就是投掷了k<sub>max-1</sub>次反面, 和1次正面, 概率就是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><msup><mn>2</mn><mrow><msub><mi>k</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">1/2^{k_{max}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:1.099108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.03148em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><br>
也就是说需要进行<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mrow><msub><mi>k</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">2^{k_{max}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:0.849108em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.03148em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>次试验可能会出现一次k<sub>max</sub>, 那么根据极大似然估算法, 我们就粗略估计本次进行的n次伯努利试验的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>=</mo><msup><mn>2</mn><mrow><msub><mi>k</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">n=2^{k_{max}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:0.849108em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span><span class="mrel">=</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.03148em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></strong></p>
<p>同理, 应用到基数统计中就是, 把集合中每个元素都经过hash后表示为二进制数串, 一个数串类比成一次抛硬币试验, 1是抛到正面, 0是反面<br>
二进制串中从低位开始第一个1出现的位置, 理解为抛硬币中第一次出现正面的抛掷次数k, 依旧通过<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mrow><msub><mi>k</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">2^{k_{max}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:0.849108em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.03148em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>来估算集合中一共有多少不同的数字<br>
因为重复的值hash后二进制数串一致, 得到的k值不会变化, 所以是天然去重的, 重复数据不会对估算值产生任何影响</p>
<h2 id="后续优化">后续优化</h2>
<p>很显然这个估算关系是不准确的<br>
关于估值偏差较大的问题, 可以采用如下方式结合来缩小误差</p>
<h3 id="均匀随机化">均匀随机化</h3>
<p>选取的哈希函数必须满足以下条件, 优秀的哈希函数是后续概率分析的基础</p>
<ol>
<li>哈希结果有很好的均匀性, 无论原始集合元素的值分布如何, 哈希结果都几乎服从均匀分布</li>
<li>哈希的碰撞几乎可以忽略不计</li>
<li>哈希结果的长度是固定的</li>
</ol>
<h3 id="分桶平均">分桶平均</h3>
<p>以上直接采用单一估计量会由于偶然性存在较大误差, 因此采用分桶平均的思想来消除误差<br>
以Redis为例, 哈希结果64位, 前14位来分桶, 共16384个桶, 后50位作为真正用于基数估计的比特串<br>
桶编号相同的元素分配到一个桶, 先分别统计每个桶各自的k<sub>max</sub>, 然后进行平均<br>
相当于物理试验中多次试验取平均的做法, 可以有效消减因偶然性带来的误差</p>
<h3 id="调和平均">调和平均</h3>
<p>分桶取平均是LLC的算法实现, HLL区别在于采用了调和平均数,<br>
调和平均数指的是倒数的平均数, 相比平均数能有效抵抗离群值对平均值的扰动<br>
比如我和马云的平均资产, 我有两万, 他有两千亿, 平均一下我有一千亿<br>
但是调和平均数, 平均一下我有2/(1/20000 + 1/200000000000)=40000<br>
就和我的资产偏差不是很大</p>
<h3 id="偏差修正">偏差修正</h3>
<p>经过上述系列优化后的估计量看似已经不错了, 但通过数学分析可以知道这并不是基数n的无偏估计<br>
因此需要修正成无偏估计, 此处涉及一系列数学公式<br>
简单来说就是, 增加修正因子, 是一个不固定的值, 会根据实际情况来进行值的调整<br>
详细可参考<a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf" target="_blank" rel="noopener">论文</a></p>
<h2 id="Redis中HyperLogLog结构">Redis中HyperLogLog结构</h2>
<p>具体数据结构, 密集存储结构, 稀疏存储结构及其转换, 可参考一下文章<br>
<a href="https://blog.csdn.net/u010887744/article/details/108041280" target="_blank" rel="noopener">玩转Redis-HyperLogLog原理探索</a></p>
<p>ps: 另附一个<a href="http://content.research.neustar.biz/blog/hll.html" target="_blank" rel="noopener">演示工具</a>, 在明白以上原理以后, 可以直观的看到HLL的工作过程及误差变化情况</p>
]]></content>
      <categories>
        <category>数学相关</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数学</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析两件套ClickHouse+Metabase(一)</title>
    <url>/2023/08/11/20230811154946/</url>
    <content><![CDATA[<h1 id="ClickHouse篇">ClickHouse篇</h1>
<h2 id="安装ClickHouse">安装ClickHouse</h2>
<p>ClickHouse有中文文档, 安装简单 -&gt; <a href="https://clickhouse.com/docs/zh" target="_blank" rel="noopener">文档</a><br>
官方提供了四种包的安装方式, <code>deb/rpm/tgz/docker</code>, 自行选择适合自己操作系统的安装方式<br>
这里我们选deb的方式, 其他方式看文档</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install -y apt-transport-https ca-certificates dirmngr</span><br><span class="line">sudo apt-key adv --keyserver hkp:&#x2F;&#x2F;keyserver.ubuntu.com:80 --recv 8919F6BD2B48D754</span><br><span class="line"></span><br><span class="line">echo &quot;deb https:&#x2F;&#x2F;packages.clickhouse.com&#x2F;deb stable main&quot; | sudo tee \</span><br><span class="line">    &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;clickhouse.list</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">sudo apt-get install -y clickhouse-server clickhouse-client</span><br></pre></td></tr></table></figure>
<p>到这里先不慌着启动, 改一波配置<br>
服务端配置默认地址在<code>/etc/clickhouse-server</code><br>
尽量不要直接修改config.xml, 而是在config.d子目录中新建配置文件, 易于维护和升级, 文件名随意但会按字母顺序生效<br>
<strong>一些简单配置:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;clickhouse&gt;</span><br><span class="line">  &lt;listen_host&gt;::&lt;&#x2F;listen_host&gt; # 打开远程访问</span><br><span class="line">  &lt;path&gt;xxx&lt;&#x2F;path&gt; # 表数据存储路径</span><br><span class="line">  &lt;tmp_path&gt;xxxx&lt;&#x2F;tmp_path&gt; # 一些临时数据</span><br><span class="line">  &lt;max_server_memory_usage&gt;21474836480&lt;&#x2F;max_server_memory_usage&gt; # 服务器进程的最大内存使用量, 根据自己情况设置</span><br><span class="line">  &lt;logger&gt;</span><br><span class="line">      &lt;level&gt;warning&lt;&#x2F;level&gt; # 日志级别</span><br><span class="line">      &lt;log&gt;xxx&lt;&#x2F;log&gt; # 日志路径</span><br><span class="line">      &lt;errorlog&gt;xxx&lt;&#x2F;errorlog&gt; # 错误日志路径</span><br><span class="line">  &lt;&#x2F;logger&gt;</span><br><span class="line">&lt;&#x2F;clickhouse&gt;</span><br></pre></td></tr></table></figure>
<p>配置完, 启动服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service clickhouse-server start</span><br><span class="line">clickhouse-client # or &quot;clickhouse-client --password&quot; if you&#39;ve set up a password.</span><br></pre></td></tr></table></figure>
<h2 id="建表">建表</h2>
<p>大部分操作和mysql差不多<br>
不过ClickHouse有一套自己的字段类型, 简单建一个表</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test</span><br><span class="line">(</span><br><span class="line">    &#96;column1&#96; Date, # 日期类型</span><br><span class="line">    &#96;column2&#96; FixedString(7), # 固定长度字符串</span><br><span class="line">    &#96;column3&#96; UInt32, # 无符号int类型</span><br><span class="line">    &#96;column4&#96; Nullable(String), # 可为空字符串</span><br><span class="line">    &#96;column5&#96; Float64 # 浮点数</span><br><span class="line">)</span><br><span class="line">ENGINE &#x3D; MergeTree()</span><br><span class="line">order by column1</span><br></pre></td></tr></table></figure>
<p>更多字段类型以及不同engine的作用详见文档</p>
<h2 id="PySpark写入ClickHouse">PySpark写入ClickHouse</h2>
<p>spark写入ClickHouse还是很方便的<br>
需要下载一个新的驱动包, 放到每个worker节点的jars目录下 -&gt; <a href="https://github.com/ClickHouse/clickhouse-java" target="_blank" rel="noopener">官方jdbc驱动</a><br>
目前是 <code>clickhouse-jdbc-0.4.6.jar</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">properties &#x3D; &#123;&#39;driver&#39;: &#39;com.clickhouse.jdbc.ClickHouseDriver&#39;,</span><br><span class="line">                  &quot;socket_timeout&quot;: &quot;300000&quot;,</span><br><span class="line">                  &quot;rewriteBatchedStatements&quot;: &quot;true&quot;,</span><br><span class="line">                  &quot;batchsize&quot;: &quot;1000000&quot;,</span><br><span class="line">                  &quot;numPartitions&quot;: &quot;8&quot;,</span><br><span class="line">                  &#39;user&#39;: &#39;default&#39;,</span><br><span class="line">                  &#39;password&#39;: &#39;123456&#39;, # 配置自己的用户名密码</span><br><span class="line">                  &#39;isolationLevel&#39;: &#39;NONE&#39;</span><br><span class="line">                  &#125;</span><br><span class="line"></span><br><span class="line">df &#x3D; spark.read.parquet(&#39;xx&#39;) # 读一个df, 注意schema和表结构一致</span><br><span class="line">df.write.jdbc(url&#x3D;&#39;jdbc:clickhouse:&#x2F;&#x2F;服务器ip:8123&#x2F;数据库名&#39;, table&#x3D;&#39;表名&#39;, mode&#x3D;&#39;append&#39;, properties&#x3D;properties)</span><br></pre></td></tr></table></figure>
<p>不想要监控可以省略以下步骤, 本篇到此结束</p>
<h2 id="监控">监控</h2>
<p>ClickHouse自带各种统计表都存在system库里, 我们需要一个可视化平台接入一下比如Grafana</p>
<p>选择适合自己的版本下载 -&gt; <a href="https://grafana.com/grafana/download?pg=get&amp;platform=linux&amp;plcmt=selfmanaged-box1-cta1" target="_blank" rel="noopener">官网下载地址</a><br>
以及有其他问题可以翻阅文档 -&gt; <a href="https://grafana.com/docs/grafana/latest/" target="_blank" rel="noopener">官方文档</a><br>
下载后解压, Grafana中默认数据源是没有ClickHouse的, 需要装一个扩展 -&gt; <a href="https://grafana.com/grafana/plugins/vertamedia-clickhouse-datasource/?tab=installation" target="_blank" rel="noopener">地址</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grafana-cli --pluginsDir&#x3D;可指定安装路径 plugins install vertamedia-clickhouse-datasource</span><br></pre></td></tr></table></figure>
<p>不需要什么配置直接<code>./bin/grafana server</code>即可启动, 不过建议改一下web页面的端口, 默认是3000, 会和后面的metabase冲突<br>
配置文件在<code>conf/defaults.ini</code>, 比如修改<code>http_port=2999</code><br>
然后在浏览器访问页面, 默认账户密码<strong>admin, admin</strong></p>
<p>进来以后选Data source<br>
<img src="http://www.wangdanpeng.com/img/20230811154946_1.png" alt="1"></p>
<p>添加数据源, 搜ClickHouse, 然后按图改名字, 填ip, 填账号密码, 然后保存即可<br>
<img src="http://www.wangdanpeng.com/img/20230811154946_2.png" alt="2"></p>
<p>下一步直接导入一个现成的ClickHouse仪表盘 -&gt; <a href="https://grafana.com/grafana/dashboards/13606-clickhouse-performance-monitor-xm-uat/" target="_blank" rel="noopener">地址</a><br>
<strong>省流, DashboardID: 13606</strong></p>
<p>页面右上角点击 import dashboard<br>
<img src="http://www.wangdanpeng.com/img/20230811154946_3.png" alt="3"></p>
<p>填入dashboardID, 点击右侧load<br>
<img src="http://www.wangdanpeng.com/img/20230811154946_4.png" alt="4"></p>
<p>然后选择刚添加的数据源, 导入即可</p>
<p>图表很多, 不一一展示了, 至此监控安装完毕<br>
<img src="http://www.wangdanpeng.com/img/20230811154946_5.png" alt="5"></p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>ClickHouse</tag>
        <tag>Metabase</tag>
      </tags>
  </entry>
</search>
